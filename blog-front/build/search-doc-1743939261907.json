{"searchDocs":[{"title":"权限模型分析","type":0,"sectionRef":"#","url":"/article/access-control-model","content":"","keywords":"code","version":null},{"title":"前言​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#前言","content":" 之前为团队设计一个权限功能对权限模型做了些调研。  ","version":null,"tagName":"h2"},{"title":"ACL(Access Control list)​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#aclaccess-control-list","content":" ACL是对一个对象附加一系列的权限（permission），比较常见。例如：Zookeeper的节点（Node）ACL属性    ","version":null,"tagName":"h2"},{"title":"BLP(Bell-LaPadula Model)​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#blpbell-lapadula-model","content":" BLP是严密的信息安全模型。 定义： * 主体--人、对象 * 客体--数据    我认为BLP是缺乏灵活性的，该模型能满足军事组织（模型设计初衷）的由低到高的数据传递，但对于同级访问描述、自由授权等是比较僵化的。  ","version":null,"tagName":"h2"},{"title":"Biba模型​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#biba模型","content":" Biba模型的规则是类似于BLP模型。    就是将BLP上下级的读写互换。因为Biba模型主要针对外部威胁，所以模型中上级也即外部。  ","version":null,"tagName":"h2"},{"title":"DAC（Discretionary Access Control）​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#dacdiscretionary-access-control","content":" 自主控制模型是通过维护访问控制矩阵和访问控制列表完成的。 模型如下：  用户subject\\目标object\t1\t2a\tOwn、write、read b\tread\twrite、read  自主访问控制通常假定所有客体都有属主，并且属主能够修改访问该客体的权限，这可能因为大部分系统的确通过属主的概念来实现的。 但是Evaluation Criteria中并没有关于属主的说明，所以技术上访问控制系统并非必须拥有属主。 基于这种实现下，用户（属主）能够修改安全属性。一个直接的例子是 Unix 的文件模式。  ","version":null,"tagName":"h2"},{"title":"MAC（Mandatory Access Control）强制访问控制​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#macmandatory-access-control强制访问控制","content":" 简单来说，系统将用户和文件赋予不同的访问级别，基于一些标记去决定访问模式。  强制访问控制（英语：mandatory access control，缩写MAC）在计算机安全领域指一种由操作系统约束的访问控制，目标是限制主体或发起者访问或对对象或目标执行某种操作的能力。 在实践中，主体通常是一个进程或线程，对象可能是文件、目录、TCP/UDP端口、共享内存段、I/O设备等。主体和对象各自具有一组安全属性。每当主体尝试访问对象时，都会由操作系统内核强制施行授权规则——检查安全属性并决定是否可进行访问。 任何主体对任何对象的任何操作都将根据一组授权规则（也称策略）进行测试，决定操作是否允许。在数据库管理系统中也存在访问控制机制，因而也可以应用强制访问控制；在此环境下，对象为表、视图、过程等。 通过强制访问控制，安全策略由安全策略管理员集中控制；用户无权覆盖策略，例如不能给被否决而受到限制的文件授予访问权限。 相比而言，自主访问控制（DAC）也控制主体访问对象的能力，但允许用户进行策略决策和/或分配安全属性。（传统Unix系统的用户、组和读-写-执行就是一种DAC。）启用MAC的系统允许策略管理员实现组织范围的安全策略。 在MAC（不同于DAC）下，用户不能覆盖或修改策略，无论为意外或故意。这使安全管理员定义的中央策略得以在原则上保证向所有用户强制实施。  类似DAC,但是授权的比较强制。  ","version":null,"tagName":"h2"},{"title":"RBAC（Role Base Access Control）​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#rbacrole-base-access-control","content":" 以角色为基础的访问控制（英语：Role-based access control，RBAC），是资讯安全领域中， 一种较新且广为使用的访问控制机制，其不同于强制访问控制以及自由选定访问控制直接赋予使用者权限，而是将权限赋予角色。1996年，莱威·桑度（Ravi Sandhu）等人在前人的理论基础上，提出以角色为基础的访问控制模型，故该模型又被称为RBAC96。 之后，美国国家标准局重新定义了以角色为基础的访问控制模型，并将之纳为一种标准，称之为NIST RBAC。  以角色为基础的访问控制模型是一套较强制访问控制以及自由选定访问控制更为中性且更具灵活性的访问控制技术。  RBAC的发展过程中有几个：  RBAC0 RBAC1模型，基于RBAC0上增加了多层次角色，比如，有些系统增加子角色，子角色可以继承父角色的所有权限。 RBAC2模型，基于RBAC0的基础上，增加了静态和动态职责，举例来说，静态职责可以是规定一个用户只能有3个以内的角色。动态职责可以是同一角色同一时间下只能有三个用户登录系统。 RBAC3模型，基于RBAC0的基础上加上RBAC1和RBAC2的特性。   ","version":null,"tagName":"h2"},{"title":"最终设计​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#最终设计","content":" 我们最终采用了RBAC0的模型，设计并开发了权限系统供内部系统使用。  结构图如下：  注：其中，页面和API的权限分开治理，二者关联点在于多页面持有的相同API，多个页面的展示权限都没有了，才会关闭API权限。  ","version":null,"tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"权限模型分析","url":"/article/access-control-model#reference","content":" [1]CISSP Certification All-in-One Exam Guide|Chapter 5 [2]有赞权限系统(SAM) [3]Department of Defense Trusted Computer System Evaluation Criteria [4]基于角色的访问控制 ","version":null,"tagName":"h2"},{"title":"设计模式学习笔记","type":0,"sectionRef":"#","url":"/article/design-pattern","content":"","keywords":"design-pattern","version":null},{"title":"模式列表​","type":1,"pageTitle":"设计模式学习笔记","url":"/article/design-pattern#模式列表","content":" 我主要是按《深入浅出设计模式》的顺序来写的，书中说到目前还受欢迎的设计模式也是我目前所写到的10多个，当然以后有空还会将GoF那本书余下的模式一个个补上。  创建型： 单例模式 工厂方法模式 抽象工厂模式 建造者模式 原型模式 结构型： 代理模式 适配器模式 装饰模式 桥接模式 组合模式 享元模式 外观模式 行为型： 观察者模式 模板方法模式 命令模式 状态模式 职责链模式 解释器模式 中介者模式 访问者模式 策略模式 备忘录模式 迭代器模式 ","version":null,"tagName":"h2"},{"title":"欧洲旅游疑问集","type":0,"sectionRef":"#","url":"/article/europe","content":"","keywords":"travel","version":null},{"title":"前言​","type":1,"pageTitle":"欧洲旅游疑问集","url":"/article/europe#前言","content":" 该从哪个角度探讨欧洲建筑史呢？本人打算从时间线和时期去铺开。 而对筷子的历史，我将从三个问题搜集资料，并从中试着回答为什么筷子最终登上舞台中央。 至于为何混搭两个不同的知识，后记我们再谈谈。  ","version":null,"tagName":"h2"},{"title":"途径的代表性建筑​","type":1,"pageTitle":"欧洲旅游疑问集","url":"/article/europe#途径的代表性建筑","content":" 最终整理如图：  ","version":null,"tagName":"h2"},{"title":"总结​","type":1,"pageTitle":"欧洲旅游疑问集","url":"/article/europe#总结","content":" 我途径的法意算是涵盖了建筑史上很多的代表性作品，在图片有标注一些风格特点。 需要说明，建筑风格并不按图中时间如此分界明显， 图中是列举它们的出现和繁盛时间。  一般分为古希腊时期、罗马时期、中世纪（哥特式、拜占庭式）、文艺复兴、巴洛克和洛可可风格、 18世纪的古典复兴、新艺术风格、现年的未来主义。因为一些建筑我没有途径或者现实较常见， 所以在图中没有提及一些重要分支：工艺风格、现代主义等。  ","version":null,"tagName":"h3"},{"title":"筷子成为主流的历史​","type":1,"pageTitle":"欧洲旅游疑问集","url":"/article/europe#筷子成为主流的历史","content":" 搜集资料时，我重点关注回答这三个问题  筷子餐具文化圈的分布范围。筷子起源，据查最早出现时间。为何成为餐具中的主流。  首先当今三大饮食文化圈分别是：  东亚的筷子取食圈 大致与儒家文化的影响范围相同。欧美的刀叉取食圈 基本代表了西方基督教文明。中东、南亚、东南亚的手指取食圈 主要受到伊斯兰教的影响。  那么筷子最早有什么历史？ 距今7000年前，挖掘出来的新石器时代的骨箸。为发掘的最早的筷子原型。  中国古人用手指取食，这一习俗延续到公元前5世纪或4世纪，也就是孔子很可能是用手进食的。我们至今仍称呼一个手指为食指。 在中国作为饮食工具，匕勺（类似于勺子，略尖且凹的浅些）比筷子更早，且一段时间作为主流。而在1世纪左右，筷子不断挑战匕勺的主流地位，直到7世纪取而代之。 注：韩国现在是勺加筷为主流。  锋利边缘的匕勺在唐代基本消失，取而代之是有弧度的勺箸。  筷子成为主流，我认为是饮食食物变化和文化演进的共同影响造成。  饮食习惯：中国人喜热食，且崇尚“食不厌精”。 古代中国人最初用勺来取用谷物食品，从上古到唐代，主要粮食是小米，小米更常煮成粥，吃粥用勺子更方便，相比之下，用筷子拾取汤里的菜肴。 但后来，用小麦粉制成的食物越发受欢迎，比如面条、饺子、煎饼。自然更方便饮食的筷子成为主流。而南方因为食用稻米多些，所以这个转变据记载应该更早些。儒家文化，认为刀等厨具不带进餐桌上更符合君子之风。  ","version":null,"tagName":"h2"},{"title":"后记​","type":1,"pageTitle":"欧洲旅游疑问集","url":"/article/europe#后记","content":" 以往外出玩了解过木构建筑和园林的一些历史，这一次也选择本人感兴趣的建筑相关。  为什么会混搭一个筷子的问题呢？看到国外的刀叉，除了思念起美味的中餐。更勾起我起一个以往的问题。 马东说过：“中国人还在用筷子和汉语，文化组成结构就不变”。想着那就了解下为什么咱们是用筷子而不是刀叉吧。  ","version":null,"tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"欧洲旅游疑问集","url":"/article/europe#reference","content":" [1]密小斯.建筑也可以很好玩：欧洲篇：从古希腊到文艺复兴[M].中国:机械工业出版社 [2]密小斯.建筑也可以很好玩：欧洲篇：从古典主义到近现代[M].中国:机械工业出版社 [3]意大利风情 [4]王晴佳.筷子：饮食与文化[M].中国:三联书店 ","version":null,"tagName":"h2"},{"title":"中国的房市是怎么运转的？","type":0,"sectionRef":"#","url":"/article/house-market","content":"","keywords":"travel","version":null},{"title":"简介​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#简介","content":" 看本书之前，我想探讨的问题是：中国的房子怎么来的？如何衡量房价高低？ 第一个问题可以凭理解和以往知识输出。而第二个问题，我查了查网上资料，发现世上顶尖的房地产投资者们没有准确答案（难怪曼昆老师不怎么写）。  ","version":null,"tagName":"h2"},{"title":"中国房地产市场图解​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#中国房地产市场图解","content":" 按照我的理解，大致画了下。  从左往右看，这就是土地从收编、出让、走入百姓家和影响经济的全过程。从上往下看，就是各权衡方的操作。整体看，这就“土地财政”的 资本闭环。  ","version":null,"tagName":"h2"},{"title":"房价​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#房价","content":" ","version":null,"tagName":"h2"},{"title":"房地产市场特点​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#房地产市场特点","content":" 刚需：人们的基本需求，比如稳定居住点、结婚、落户、孩子上学等。投资品信用：前两个因素共同决定了房产是一个占经济GDP比重高的一个产业，我国住房消费占居民消费支出比重长期维持在20%以上。那么其关联的借贷信用体系（见第一节图）可谓庞大。关联产业多：上中下游产业，“七通一平”，钢筋水泥，施工装备，软硬装，日常家具设施。  ","version":null,"tagName":"h3"},{"title":"因素分析​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#因素分析","content":" 人口 从供需角度，人口影响着土地需求。经济（收入）经济好坏影响收入多少和人们购房期望。政策 利率土地供应及建设准入  以上三点是我认为影响房产的因素，但只抛砖引玉，暂无法证伪。  ","version":null,"tagName":"h3"},{"title":"额外后记​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#额外后记","content":" 1、 这本书当然不仅说了土地财政。我认为重点有两个：  中央政府与地方政府：汇报关系与权力划分、大小权衡、分税制。这是百年前钱穆先生放在首位分析的事情，钱穆的方法论是分析这几方面：政府组织，科举，赋税，经济，国防兵役。中国以往推动经济模式。经济结构重投资、重生产、轻消费。  2、 之前在网上看到一篇这样的博客文章https://houbb.github.io/2025/02/09/5min-read-books-014-zhishenshinei，发现有公众号作者通过一个统一的框架，生成了《置身事内》的总结。说实话有点小触动，倒不是为可能以上我写的都能够AI生成而感，而是发现如果不在乎输入，现在通过这种生成方式经营自媒体的成本确实低，估计只要每天15分钟（5分钟生成10分钟润饰）就能经营一个自媒体号了。  3、查资料时想到deepseek这服务器资源问题都几周了，联想到一个有意思的事，服务可用性这一被研发工程师奉之圭臬的红线问题，某个时刻真的这么重要么？ 每个时代每个时刻变量如牛毛，只能稍稍筛选以为重要的。或许到最后又只得出结论，但建好事，莫问前程了。  ","version":null,"tagName":"h2"},{"title":"reference​","type":1,"pageTitle":"中国的房市是怎么运转的？","url":"/article/house-market#reference","content":" [1]兰小欢.置身事内[M].中国:上海人民出版社, 2021 ","version":null,"tagName":"h2"},{"title":"魅族魅蓝2拆机","type":0,"sectionRef":"#","url":"/article/phone-arch","content":"","keywords":"phone","version":null},{"title":"前言​","type":1,"pageTitle":"魅族魅蓝2拆机","url":"/article/phone-arch#前言","content":" 魅蓝2这台手机是我参加工作后买的第一台手机， 换机后中间有一段时间我用它作为测试和体验APP的机子，到后来闲置在箱子里一段时间了。 前些天我突然好奇起来：我用了手机这么些年了，我真的了解手机的组成吗。遂拆之，并把它装裱在框里挂在家里墙上。  ","version":null,"tagName":"h2"},{"title":"各部分分析​","type":1,"pageTitle":"魅族魅蓝2拆机","url":"/article/phone-arch#各部分分析","content":" 下图是我拆机并装裱起来的最终效果图。    各部分分别是：  手机后盖麦克风防尘塞电池及电池排线背板螺丝左边是2GB的SD卡，右边是固定外壳的螺丝（其中一颗遗失了）SIM卡槽左边蓝条是声音调节按键，右边是主板螺丝主板（我没把遮蔽罩拆掉） MT6735四核1.3GHz处理器16GB三星的eMMC存储芯片2GB LPDDR3 内存1300万像素后置摄像头和500万像素前置摄像头 背板主板上感光元件的一个软塞3.5mm耳机孔及固定螺丝扬声器单元副板HOME键铝镁合金框架射频线5英寸720p、296PPI的屏幕集成 ","version":null,"tagName":"h2"},{"title":"茅台2023财报速读","type":0,"sectionRef":"#","url":"/article/maotai2023sudu","content":"","keywords":"finance","version":null},{"title":"资料来源​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#资料来源","content":" 巨潮资讯：http://www.cninfo.com.cn/官网  ","version":null,"tagName":"h2"},{"title":"公司和行业现状体感​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#公司和行业现状体感","content":" 首先，白酒行业的利润应该都不错，我记忆中（以前哪个采访说到）净利润率50%以上，可算得上暴利。  其次，茅台如何制作呢？茅台酒一般经过：制曲、制酒、贮存、勾兑、检验、包装。 九次蒸煮、八次发酵、七次取酒。每轮次基酒会有不同风味。  茅台年分红有上升，且对比同行业（五粮液）高。  茅台股价近3年处于阴跌状态。  ","version":null,"tagName":"h2"},{"title":"综合阅读​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#综合阅读","content":" 自己的投资理念(principle)。 基于如下分析：保守，容忍度低，倾向于清算价值估算法（我一般算每股清算价值）。看重管理能力下的现金流情况。  分五步骤看看。  ","version":null,"tagName":"h2"},{"title":"零、重要事项提示和董事会分析​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#零重要事项提示和董事会分析","content":" 第2页，会计事务所出具的“标准无保留意见”的审计。ok可以继续往下看。 重要提示没啥毛病。  看董事会报告：  首先，我看眼期末库存量上升了6%，销售额也上涨了。对比起来去库存周期没什么变化。  然后我翻查了董事会的行业趋势分析，看看管理者如何看优劣势和机会的。 我认为有点过于积极了(两页乐观，最后说风险20字谈及了宏观经济风险等)，尤其我翻阅对比2014年的茅台财报，个人认为缺少审慎和危机意识。  ","version":null,"tagName":"h3"},{"title":"NBA的球队战绩是否与城市经济挂钩","type":0,"sectionRef":"#","url":"/article/nba-team-achievement-related-to-economic","content":"","keywords":"basketball","version":null},{"title":"计划​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#计划","content":" 问题是，nba的球队战绩是否和经济有关。那么  收集战绩数据，经济数据用GDP衡量数据分析  分析公式：分别将球队战绩、球队所在城市GDP做两个排名，做一个线性回归分析。  第二问题，NBA是否西强东弱（顺带分析）  收集战绩数据数据分析  分析公式： 首先，NBA有些球队不是一个赛季只碰面两次的。 一般同分区的球队，一个赛季可能有四次碰面。 而一支球队与不同分区的球队一个赛季只会碰2次（主客场）。  那问题就是，怎么抵消同分区的战绩干扰，分析不同分区球队的对战战绩。 最后想到用胜场系数来评判，即是用同分区的胜场数减去同分区的负场数，那么就得出了该分区对战另一分区的总战绩了。 然后逐年的总战绩拉一个趋势出来就可以看出是不是有西强或者东强的痕迹了。  ","version":null,"tagName":"h2"},{"title":"遇到的情况​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#遇到的情况","content":" 数据获取  数据获取用了两个月时间。球队战绩容易些。 而球队所在城市GDP是则是意料之外的难找到。找不到旧数据，GDP很多没有以市单位的。我尝试了google、quora等，在虎扑、知乎寻求了些 在国外城市数据有相关回答经验的大佬也没有找到。  最终在google公共数据库里，找到了2001-2016的美国各市GDP数据。所以，分析会局限在这个时间区间。  球队改城市、改名字、变分区、2011-2012为缩水赛季  主要影响数据库表结构，和数据爬取程序出错。  ","version":null,"tagName":"h2"},{"title":"结果分析​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#结果分析","content":" ","version":null,"tagName":"h2"},{"title":"nba的球队战绩是否和经济有关​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#nba的球队战绩是否和经济有关","content":" 好，脚本拉去整理数据，排序然后seaborn线性回归分析。如下图，    额，脸好疼，谁打我脸。。我一直以为是成正相关的。 可是咋一看图，点乱麻麻的分布在各处，这貌似显示战绩和经济没有关系。  为什么我觉得和经济相关呢？ 事实上，从总冠军数据来看，整个历史长河，赢得大于两个总冠军的球队，除了圣安东尼奥，其余都是GDP名列前茅的。 从个体来看，拿湖人来说，贾巴尔（天勾，历史得分榜第一名），奥尼尔（我认为是历史第一中锋），勒布朗詹姆斯（算历史第一大前锋）都选择了转会湖人， 并且对湖人夺冠起了直接作用。 大城市对于球星的吸引力，看每年的交易期可容易看到。 大城市的人口，消费水平，影响力，曝光，辐射力都是小城市不能比拟的。  综上，我认为，经济和战绩没有必然关系，只是影响战绩的其中一个因素。 为什么呢，因为影响战绩的因素还有，每年的乐透选秀（我认为算是小球市球队夺冠的较重要事件）， 球队的教练团队水平（比如，五冠马刺），球队总经理的运营能力，球队老板的考量，甚至还有地理因素、城市关注度（因为会有NFL等职业比赛分流了）等较外围因素。btw, 联盟不断保证竞技的公平性，这正是竞技体育的魅力所在。  如果要严谨的测算的话，需要控制好其他变量的影响。  ","version":null,"tagName":"h3"},{"title":"千禧年后东西强弱分析​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#千禧年后东西强弱分析","content":" 这是附带分析，想着既然把战绩找来了，正好可以分析下西强东弱究竟是感官上的错觉，还是确有其事呢。  结果如图，可知，在千禧年后，西部整体对阵东部球队除2009年外都是领先的，而且不少年份还大幅领先（大于50场）。  结论，千禧年后，整体来看联盟实力西强东弱。  ","version":null,"tagName":"h3"},{"title":"回顾​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#回顾","content":" 对于数据，我获取的时间线还不够长。时间线拉的不够长会导致不利于观察和分析规律。 另一方面来讲，数据挺重要的。找数据用了两个多月，编码（爬数据入库、数据分析、图表生成）加上写文章大约1个星期。  对于结果后续， 可以尝试把教练团队水平，乐透秀，总经理交易水平，球迷人数考虑进去。 这样能相对抹平其他变量对于这个问题的干扰。 不过那些因素其实很难衡量，没有一个绝对的衡量标准， 我认为可以通过建立一个自己的打分系统去做（将教练水平打分，球员潜力兑现打分，每笔交易打分）。  对于经济， 看到GDP数据比较，感叹洛杉矶和纽约的辐射能力，也从明尼苏达中感到了城市群里分工明确， 我个人以为在进入城镇化晚期的我国，估计最终也会呈现这个局面。  ","version":null,"tagName":"h2"},{"title":"后记​","type":1,"pageTitle":"NBA的球队战绩是否与城市经济挂钩","url":"/article/nba-team-achievement-related-to-economic#后记","content":" 在写之前，我问过自己一些问题：为什么写这篇文，我希望写成什么样子呢？我想，大概要从前几年说起。  读书时期，身边总有些看NBA的朋友，我或多或少看了些，出名的球星可以叫出来些。 大概到毕业出来工作16年那会，才开始大规模看球。也得益于移动互联网，看球方便多了。  大概到18年赛季结束，我想着也看了一段时间了，心里有个念想，想起码输出点东西作为我看球的记忆点也好正反馈也好。  好，那么问题就到了我希望写成什么样子呢？  18年那会看了《约翰·伍登的UCLA大学进攻战术体系》，会有时看下basketball reference等数据网站。 恰逢刚看完总决赛，就觉得勇士太厉害了，想着就分析勇士的战术吧。  可是，分析战术在文章里截出大堆比赛截图，我总觉得有点别扭。 更重要的是，我希望结合我自己的专业去解决些问题会有意思些。 另外看NBA的朋友大概会有东部强还西部强的探讨，其实争论从NBA远古时代就有。 记得小时候零几年时，从全明星，我们喜欢的科比、奥尼尔、甜瓜、马刺以及很多国人关注的火箭大概总围绕西部，当然东部也有答案、真理、詹姆斯。 但是体感上西部每年赛季末争抢季后赛的名额总比较激烈。不过，网上却众说纷纭。我当时就想，可不可能和经济有关系呢，于是，想从这个角度做一些自己的阐述。 ","version":null,"tagName":"h2"},{"title":"一、先看三大表，各个科目有没异常​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#一先看三大表各个科目有没异常","content":" 简单说我的理解：  资产负债表 反映企业财务状况。 看各类项目的漏洞：货币呀、经营资产、生产资产、投资资产等的情况。利润表 反映企业近期的营业成果。 看收入、毛利率、净利率、费用率、营业利润率等情况。现金流量表 反映展示企业筹资能力。反映一段时间内企业的偿还债务能力，反映是否能够健康经营。  一般都是各类目翻看，然后google查。  资产负债表看四个要点：（从三个角度看，结构、历史、同行）  生产资产/总资产应收/总资产货币资金/有息负债非主业/总资产  一般资产负债表要重点看（因为复式记账下明细多且搞外账和搞经历多个部门的凭证单据，搞起来成本大）， 而利润表容易造假。现金流量表一般ERP软件是自动生成。  现金流量表的“经营现金流净额” / 利润表的“净利润” = 0.923，这个比值越大越稳定越好。  ","version":null,"tagName":"h3"},{"title":"二、财务指标的分析​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#二财务指标的分析","content":" 安全性指标：  流动比率=流动资产/流动负债=4.6 &gt; 2速动比率=速动资产/流动负债=4.6 &gt; 1现金及现金等价物/有息负债=现金及现金等价物/(短期借款+一年内到期的非流动负债+长期借款+应付债券)=4463.24 &gt; 1  可以看出比率比较高，流动资产没有充分使用。 不得不说，茅台很少烧钱借钱。  营业能力指标：  营业利润率=（营业收入-营业成本-三费）/营业收入 （147,693,604,994.14-11,867,273,851.78-4,648,613,585.82-9,729,389,252.31-157,371,873.01）/147,693,604,994.14 = 0.821233637 净资产收益率=净利润/平均净资产= 64,786,396,951.58*2 /(171,584,366,864.08 + 161,880,997,981.23 - 14,681,509,236.35 - 13,214,280,942.48) = 0.424对比隔壁五粮液 = 0.394  ROE是衡量企业盈利能力的非常重要指标。（巴菲特钟爱这个指标）  成长性分析  营业利润增长率=(本期营业利润-上期营业利润)/上期营业利润 = −0.0982 净资产增长率=(本期净资产-上期净资产)/上期净资产 = 2.055  利润率同比去年有所降低，然后看起来茅台也降本增效了  管理层能力分析  应收账款周转率=营业收入/平均应收账款 = 81,415,570,788.59/((17,178,545,925.65+20,670,923,010.62)/2) = 4.302 平均应收账款=(期初应收账款总额+期末应收账款总额)/2 存货周转率=营业成本/存货平均余额 = 1.149 存货平均余额=（期初存货总额+期末存货总额）/2 固定资产周转率=营业收入/固定资产净值 = 4.18  这几个指标都是越大，说明管理者运作能力越好。  ","version":null,"tagName":"h3"},{"title":"三、比对利润和现金流的变化趋势​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#三比对利润和现金流的变化趋势","content":"   ","version":null,"tagName":"h3"},{"title":"四、和竞争对手比一比​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#四和竞争对手比一比","content":" 上面有对2023年五粮液财报的一些比对，这里略。  ","version":null,"tagName":"h3"},{"title":"总结​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#总结","content":" 总体来看，贵州茅台2023年财报显示，尽管面临市场价格波动和行业竞争压力，公司依然实现了稳健增长。 年营收达到1505.6亿元，净利润775.2亿元，增速均超过18%。 值得注意的是，直销渠道收入显著增长，达到672亿元，占比接近50%。尽管净现比低于1，主要受高税费影响，但公司保持强劲的现金流和高毛利率（91.96%）。 整体来看，茅台在高端市场的地位依旧稳固，未来潜力仍然可观。我认为茅台的经营策略算是太保受了。  本文结合《手把手教你读财报》和一些理解写下，权当炒股的方法论。 再深入的话，可结合一些财务书籍和杜邦体系去做分析。  ","version":null,"tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"茅台2023财报速读","url":"/article/maotai2023sudu#reference","content":" [1]茅台2023年、2014年财报 [2]茅台酒制作|百度百科 [3]五粮液2023年财报 [4]唐朝.手把手教你读财报.中国经济出版社 ","version":null,"tagName":"h2"},{"title":"茶饮和酒饮的分类","type":0,"sectionRef":"#","url":"/article/tea-and-wink","content":"","keywords":"drink","version":null},{"title":"茶饮​","type":1,"pageTitle":"茶饮和酒饮的分类","url":"/article/tea-and-wink#茶饮","content":"   ","version":null,"tagName":"h2"},{"title":"酒饮​","type":1,"pageTitle":"茶饮和酒饮的分类","url":"/article/tea-and-wink#酒饮","content":"   ","version":null,"tagName":"h2"},{"title":"鸡尾酒​","type":1,"pageTitle":"茶饮和酒饮的分类","url":"/article/tea-and-wink#鸡尾酒","content":" 自由古巴 配方  2.5份 朗姆酒0.5份 柠檬汁6份 可乐冰块  202311调，成品味道我挺喜欢。  莫吉托 配方  2份 朗姆酒2茶勺 糖浆1.5份 柠檬汁3份 苏打水6片 薄荷叶冰  202401调，成品可能是自榨汁的青柠檬汁的缘故，有点混浊，而且整体味道很酸。 ","version":null,"tagName":"h2"},{"title":"是枝裕和--镜头渗透着人文情怀","type":0,"sectionRef":"#","url":"/article/shi-zhi-yu-he","content":"","keywords":"film","version":null},{"title":"ending​","type":1,"pageTitle":"是枝裕和--镜头渗透着人文情怀","url":"/article/shi-zhi-yu-he#ending","content":" 之前有朋友跟我说看电影写点评很废，且很多人过分解读，但我觉得看电影写文章就像翻译，由电影创作者去创作，而由观众去审视、解读。已故文学工作者曾希邦先生发过一条微博来形容翻译：  我几乎天天接触翻译，所以，我的微博话题，总离不开翻译。我一再强调，翻译是不可能的，翻译只是从不可能中，寻求可能，如此而已。我相信，我这几句话，是可以传世的诤言，因为，它包含了真理。翻译永远无法超越原文。翻译，充其量只能重现原文的意境。一个真正懂得翻译的人，决不敢轻易批评他人翻译。  所以，文章不可能超过电影本身，我写影评更多是为了再理解，和实践。  一口气看了七部是枝裕和的作品，不想写得空泛，又因为我看了些电影的书，所以希望写篇文章实践下，就找了个摄影的角度入手（额，貌似也有点空）。  其实，是枝裕和的作品还有不少给我留下深刻印象的东西： 柳乐优弥的表演，树木希林大神级接地气的演技，还有如上稍微提及的对比，符号，打光等等。主题里的人文关怀，是枝当然不止以上的所说的镜头，还有，其实日本文化里对食十分讲究，是枝的这几部电影都有不止一个关于食的镜头，对原生家庭的问题，传承都有提及。  很多时候，他影片中，或许一声孩子的嬉笑声，或许一位电车乘务员的一个手势，或许一罐淡淡的梅子酒，或许一个微不足道的角色朝镜头的一个驻足观望就已经征服观众了。以上，在我看来，是枝裕和是个严谨，注重细节，充满人文气息的导演。《第三次的杀人》要来了，期待吗？ ","version":null,"tagName":"h2"},{"title":"技术支撑团队的指标评估和实施","type":0,"sectionRef":"#","url":"/article/teamwork-measure","content":"","keywords":"work measure","version":null},{"title":"背景​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#背景","content":" 从业务研发团队又转到技术平台型团队（算法架构），在日常迭代和碰撞中，一个问题时不时在我脑海浮现。 在业务团队，我们可以很轻松的将技术人员的开发优先级和效率，通过业务北极星指标等业务大盘指标和项目需求数去量化和理性判断。 但是，技术平台型团队呢？（比如我们团队主业是提供技术组件、性能和稳定性解决方案给算法工程师等使用，其次是前沿探索）  技术支撑 如何判断优先级(双刃剑)？假设在满工作量运转下，大概根据大业务部门的业务目标和重点能够区分任务的优先程度。 但另一个，怎么判断整体效率和效益呢？ 我的答案是指标量化。我会在实施方向一节谈谈。前沿探索 不再本文谈论范围。一句话带过，我认为是需要发挥能动性，但要探索收敛 --- 1. 可输出的成果。（落地或者外界影响力）2. 将部门或者大部门的探索收编。  ","version":null,"tagName":"h2"},{"title":"现状​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#现状","content":" 据我了解目前有各项服务稳定性指标，但是工具和服务效率无机制。 所以我下面正篇讨论会围绕工具和服务效率展开。  ","version":null,"tagName":"h2"},{"title":"实施方向​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#实施方向","content":" ","version":null,"tagName":"h2"},{"title":"谈谈指标量化​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#谈谈指标量化","content":" 在日常业务和工作中，我们每天面对一大堆的带有指标的图表和文档，各式各样玩出花的监控看板，同时我们总有一些被量化误导的经历，有时候我们对于量化会有抵触和迷思，因为大概想着量化会骗人和会失去自由度等等，我想回答两个问题。  到底应不应该量化？如何量化？  到底应不应该量化？ 首先我们是在商业世界的科技行业里，从商业角度，卖出了多少，这个月赚了多少，扣除成本、三费啥的剩多少。自上而下来说，天然就是有数字的。 从科技角度，简单来说，在创意阶段某些可能要些直觉和感性，但会越来越少。在实施阶段/实施团队中，比如我的一些方案，看似是直觉，但是很多回过头看不过是用脚投票的选择。 其次，有量化的团队，比起没有的团队，我认为容易把握范围、方向和成绩。 最后，往底层聊，人除了不断用理性去“度量”事情，不断量化，没有其他方法能够推进一些事情。 现阶段问题点： 数据是会“骗人”，因为目前来说，我们不可能参数化所有变量。 数据量化过多，过于重视数据量化，可能杀死创造空间。 所以，我认为针对技术平台团队的量化只可发挥同环比指导意义，并且需要因应发展阶段不断改造和细化。  如何量化呢，  基于团队服务目标去量化。用什么量化？数字/数据作为一个公平的，可细化到最小粒度去指代现实客体的手段，是最适合用来量化的。量化的尺度？基于团队服务目标，在迭代收口位置做好数据记录。  ","version":null,"tagName":"h3"},{"title":"方向细化​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#方向细化","content":" 这节对项目迭代中的技术支撑及其评估做了细化：  工具、框架、平台支持 -&gt; 工具覆盖范围的效率点指标 + 问卷人力支持 分两部分 涉及业务数据流的，如开发、测试、质量 -&gt; 和业务指标绑定不涉及业务流的，例如排查技术问题 -&gt; 问卷  ","version":null,"tagName":"h3"},{"title":"收益​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#收益","content":" 通过实施本方案  对于技术工具和支撑型团队，能够有一个正循环指标，指导迭代方案对于服务目标团队 能够评估工具给研发提高的效率能够激发技术工具团队的积极性，有调研证明，当工作体验提升了也能激发业务研发的主观能动性[6]，间接为业务贡献能够用于评估业务研发团队的技术需求效率，例如评估重构效率提升和引入静态代码平台等的效用。  ","version":null,"tagName":"h3"},{"title":"愿景​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#愿景","content":" 希望在算法架构团队或者质量团队所负责的流程中实施，最后经过完善后，推广到整个互部的平台部门。  ","version":null,"tagName":"h3"},{"title":"指标备选​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#指标备选","content":" 业界有不少公司在做这个事情。比如，google有专门的工程生产力团队，很多公司也有用到一些指标去衡量平台化团队的生产力。  ","version":null,"tagName":"h2"},{"title":"DORA​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#dora","content":" https://dora.dev/research/?view=summary  指标\t部署频率\t将服务更改部署到生产环境的频率 更改的前置时间\t从第一个提交到部署所需的时间 恢复服务的时间\t由于生产事故、或者异常中断后重新部署的时间 更改失败率\t导致失败或需要修复的生产部署的百分比  经典的微服务设计的度量指标，比较适合短平快的成熟团队去使用。目前Netflix公司的技术平台团队使用。 不足是，我认为更改度量时间，应该改为从分支创建到最终部署所需时间。  ","version":null,"tagName":"h3"},{"title":"DevEx​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#devex","content":" DevEx: What Actually Drives Productivity - ACM Queue  DevEx指标称为开发者体验指标。作者是 Abi Noda、Margaret-Anne Storey 博士、Nicole Forsgren 博士、和 Michaela Greiler 博士。Spotify公司会用到这个指标框架去改进技术团队。DevEx重视这三点，反馈回路，流式状态，认知负载。  反馈回路：有研究表明，技术团队更频繁的交付效率，业务的脱颖而出可能性更高。认知负载：软件开发本身是很复杂的，简单一个接口或页面功能下面可能依赖了一些服务。所以要想办法减少开发者上下游认知成本。流式状态：研究表明，开发者处于热爱工作的状态，能够交付更高质量的产品。  基于上面，DevEx提出了这些衡量指标：  总结：DevEx会注重到人的体验，除了迭代，加入了开发者体验的选项。  ","version":null,"tagName":"h3"},{"title":"PMP metrics​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#pmp-metrics","content":" PMP项目管理指标  首先PMP涵盖很多东西，PMP涵盖的方面包括但不限于：  完成项目所需的章程、范围管理如何交付及准时交付成本控制-成本预算、过程中计算挣值和折旧质量把控团队配置和沟通  我认为呢，PMP是一套完整的项目管理方法论，但对于仅希望明确技术团队的效率和效益来说，显得太多了。  ","version":null,"tagName":"h3"},{"title":"内部调研​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#内部调研","content":" 调研了公司信息技术部的做法，这里不放出来。  ","version":null,"tagName":"h3"},{"title":"指标决策​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#指标决策","content":" \tDORA\tDevEx\tPMP metric\t内部调研\t汇总开发成本\t低\t中\t高\t低\t1、4 可维护性\t偏高\t偏高\t低\t高\t1、2、3、4 业务适配度\t高\t偏高\t低\t中\t1 迁移成本\t低\t中\t巨大\t中\t1、4  看中业务适配度、迁移成本、开发成本。 方案考虑1、4。 可考虑融合1、4方案。  ","version":null,"tagName":"h2"},{"title":"实施​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#实施","content":" 基于Dora指标体系去做，按照每个Q去统计，并且同环比对比。数据记录在Iceberg，最终通过内部大数据看板展示。  ","version":null,"tagName":"h2"},{"title":"指标的解释和完善​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#指标的解释和完善","content":" 指标\t阐释部署频率\t将服务更改部署到生产环境的频率 更改的前置时间\t从第一个提交到部署所需的时间 恢复服务的时间\t由于生产事故、或者异常中断后重新部署的时间 更改失败率\t导致失败或需要修复的生产部署的百分比  如何收集：    部署频率（次数） 收集服务的上下线的数据。（Matrix可能在数据工场有数据，部署平台需要看下） 更改的前置时间 时间 = 通过merge request时间点 - git命令获取分支创建的时间 服务恢复时间 收集事故复盘收集回滚后，第二次上线的时间间隔 更改失败率 收集回滚次数  One more thing：调研AI报告，生成AI监控看板（https://www.toolify.ai/zh/category/ai-monitor-report-builder）  ","version":null,"tagName":"h3"},{"title":"问卷​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#问卷","content":" 这里不放出来。  ","version":null,"tagName":"h2"},{"title":"Referecne​","type":1,"pageTitle":"技术支撑团队的指标评估和实施","url":"/article/teamwork-measure#referecne","content":" [1]https://landing.google.com/engprod/ google工程生产力团队 [2]https://dora.dev/research/?view=summary DORA模型 [3]https://microservices.io/articles/glossary [4]Andrew Stellman.深入浅出PMP[M].中国:东南大学出版社 线上阅读 [5]https://queue.acm.org/detail.cfm?id=3595878&amp;utm_source=the+new+stack&amp;utm_medium=referral&amp;utm_content=inline-mention&amp;utm_campaign=tns+platform [6]https://www.sciencedirect.com/science/article/pii/S0164121218300323?via%3Dihub ","version":null,"tagName":"h2"},{"title":"Java模块化","type":0,"sectionRef":"#","url":"/article/java-modular","content":"","keywords":"java","version":null},{"title":"一个java文件的执行周期​","type":1,"pageTitle":"Java模块化","url":"/article/java-modular#一个java文件的执行周期","content":" 在设计模块化时，JDK的开发者们为Java在编译期和运行期之间引入了一个新的phase--链接期。这是一个可选的phase。    ","version":null,"tagName":"h3"},{"title":"模块化的使用​","type":1,"pageTitle":"Java模块化","url":"/article/java-modular#模块化的使用","content":" 先跟随一个简单的模块化demo来直观感受一下模块化。  目录如下：   java9/module-system-demo$ tree . ├── moduleA │ ├── moduleA.iml │ ├── module-info.java │ └── net │ └── teaho │ └── demo │ └── java9 │ └── modular │ └── a │ └── Invoker.java ├── moduleB │ ├── moduleB.iml │ ├── module-info.java │ └── net │ └── teaho │ └── demo │ └── java9 │ └── modular │ └── b │ └── EchoService.java ├── build_module.sh ├── link_module.sh ├── package_module.sh ├── README.md └── run_module.sh   编译​  rm -rf build javac -d build --module-source-path . $(find . -name '*.java')   --module-source-path 制定寻找模块源文件（.java）的目录。  运行​  java --module-path build -m moduleA/net.teaho.demo.java9.modular.a.Invoker output: echo: Invoke from module A   打包​   bash ./build_module.sh mkdir build/jar jar --create --file=build/jar/moduleB.jar --module-version=1.0 -C build/moduleB . jar --create --file=build/jar/moduleA.jar --module-version=1.0 --main-class=net.teaho.demo.java9.modular.a.Invoker -C build/moduleA . mkdir build/jmod jmod create --class-path build/moduleB build/jmod/moduleB.jmod jmod create --class-path build/moduleA build/jmod/moduleA.jmod   上面命令分别打了jar包和jmod包。分别打了如下包：  ├── build │ ├── jar │ │ ├── moduleA.jar │ │ └── moduleB.jar │ ├── jmod │ │ ├── moduleA.jmod │ │ └── moduleB.jmod   jmod包的特点：  新的jmod文件格式是在jar文件格式之上，囊括上native代码，配置文件和其他数据文件等一些不适合放在先有JAR文件格式的资源。jmod文件可用在编译期、链接期，但不能用于运行时。  链接​   jlink --verbose --module-path build --add-modules moduleB,java.base --output build/moduleApp   我们执行jlink命令，输出了如下文件：  │ ├── moduleApp │ │ ├── bin │ │ │ ├── java │ │ │ └── keytool │ │ ├── conf │ │ │ ├── net.properties │ │ │ └── security │ │ │ ├── java.policy │ │ │ ├── java.security │ │ │ └── policy │ │ │ ├── limited │ │ │ │ ├── default_local.policy │ │ │ │ ├── default_US_export.policy │ │ │ │ └── exempt_local.policy │ │ │ ├── README.txt │ │ │ └── unlimited │ │ │ ├── default_local.policy │ │ │ └── default_US_export.policy │ │ ├── include │ │ │ ├── classfile_constants.h │ │ │ ├── jni.h │ │ │ ├── jvmticmlr.h │ │ │ ├── jvmti.h │ │ │ └── linux │ │ │ └── jni_md.h │ │ ├── legal │ │ │ └── java.base │ │ │ ├── ADDITIONAL_LICENSE_INFO │ │ │ ├── aes.md │ │ │ ├── asm.md │ │ │ ├── ASSEMBLY_EXCEPTION │ │ │ ├── cldr.md │ │ │ ├── c-libutl.md │ │ │ ├── icu.md │ │ │ ├── LICENSE │ │ │ ├── public_suffix.md │ │ │ └── unicode.md │ │ ├── lib │ │ │ ├── classlist │ │ │ ├── jexec │ │ │ ├── jli │ │ │ │ └── libjli.so │ │ │ ├── jrt-fs.jar │ │ │ ├── jvm.cfg │ │ │ ├── libjava.so │ │ │ ├── libjimage.so │ │ │ ├── libjsig.so │ │ │ ├── libnet.so │ │ │ ├── libnio.so │ │ │ ├── libverify.so │ │ │ ├── libzip.so │ │ │ ├── modules │ │ │ ├── security │ │ │ │ ├── blacklisted.certs │ │ │ │ ├── cacerts │ │ │ │ ├── default.policy │ │ │ │ └── public_suffix_list.dat │ │ │ ├── server │ │ │ │ ├── libjsig.so │ │ │ │ ├── libjvm.so │ │ │ │ └── Xusage.txt │ │ │ └── tzdb.dat │ │ └── release   输出了一个小型jre（Java Runtime Environment）。 我们来看看这个jre有什么特别。  大小  $ du -sh moduleApp/ 48M moduleApp/ $ du -sh ~/Env/jdk-11/ 297M /home/teaho/Env/jdk-11/ $ du -sh /usr/lib/jvm/java-8-openjdk-amd64/jre/ 119M /usr/lib/jvm/java-8-openjdk-amd64/jre/   我们打包出来的jre才48M而一般jre有119M，更别说jdk了。 我们看看有哪些模块：  $ ./build/moduleApp/bin/java --list-modules java.base@11 moduleB   有Java11的java.base和我们编写的moduleB。  只有java、keytool两个工具，我们用这个小型jre运行下代码  $ ./build/moduleApp/bin/java --module-path build -m moduleA/net.teaho.demo.java9.modular.a.Invoker echo: Invoke from module A   ","version":null,"tagName":"h3"},{"title":"作用及应用场景​","type":1,"pageTitle":"Java模块化","url":"/article/java-modular#作用及应用场景","content":" Java的百兆级JDK和JRE一直以来受人诟病。当时外界猜测跳票了这么多年的模块化特性是为了抢占嵌入式和物联网（IOT）的市场， 我个人觉得目的确实是这样的，当然它带来的好处不仅在IOT。  因为以前Java的lib的依赖关系是杂乱无章的。   而Java9引入模块化后，它的依赖关系清晰了很多。   这是因为它通过module-info.java文件来强制控制了模块中类的访问能力，这有别于以往只要是public的类都能访问的机制。  应用场景​  有助于嵌入式、物联网开发为基础平台（框架层面）的开发提供便利  对于一般的应用来说，帮助没有想象中大。 当然目前Java也是支持原来的非模块化的开发方式的。（就是我们可以选择无视module-info.java文件）  ","version":null,"tagName":"h3"},{"title":"module-info.java文件​","type":1,"pageTitle":"Java模块化","url":"/article/java-modular#module-infojava文件","content":" Java语言规范（The Java Language Specification）有如下例子：  open module com.example.foo { requires com.example.foo.http; requires java.logging; requires transitive com.example.foo.network; exports com.example.foo.bar; exports com.example.foo.internal to com.example.foo.probe; uses com.example.foo.spi.Intf; provides com.example.foo.spi.Intf with com.example.foo.Impl; }   各个关键字的意思如下：  module名  Module names, like package names, must not conflict. The recommended way to name a module is to use the reverse-domain-name pattern that has long been recommended for naming packages.  open关键字 声明在module前，说明该模块导出的功能可见度是最高的。exports关键字 语法： 导出某块exports &lt;package&gt;;导出某块到某些模块exports &lt;package&gt; to &lt;module1&gt;, &lt;module2&gt;...; opens关键字 opens类似于open module N { exports com.jdojo.claim.model; opens com.jdojo.claim.model; } requires关键字 表示当前模块依赖那些模块。  requires &lt;module&gt;; requires transitive &lt;module&gt;; //加了transitive的作用：https://stackoverflow.com/questions/46502453/whats-the-difference-between-requires-and-requires-transitive-statements-in-jav requires static &lt;module&gt;; //加了static的作用：https://stackoverflow.com/questions/46537294/whats-the-difference-between-requires-and-requires-static-in-module-declaration requires transitive static &lt;module&gt;; requires public &lt;module&gt;; //https://openjdk.java.net/projects/jigsaw/spec/sotms/#defining-modules 第2.2点   uses与provider关键字 Java允许使用服务提供者和服务使用者分离的服务提供者机制。 JDK 9允许使用语句（uses statement）和提供语句（provides statement）实现其服务。 使用语句可以指定服务接口的名字，当前模块就会发现它，使用 java.util.ServiceLoader类进行加载。 例子如下： java base的module-info有如下语句： uses sun.util.spi.CalendarProvider; provides java.nio.file.spi.FileSystemProvider with jdk.internal.jrtfs.JrtFileSystemProvider; //可以这样使用 ServiceLoader&lt;FileSystemProvider&gt; service = ServiceLoader.load(FileSystemProvider.class); service.xxxxx   ","version":null,"tagName":"h3"},{"title":"其他特点简单罗列​","type":1,"pageTitle":"Java模块化","url":"/article/java-modular#其他特点简单罗列","content":" 关于不加上版本控制的原因：  It is not a goal of the module system to solve the version-selection problem, which is best left to build tools and container applications.  一个模块化jar文件能够被识别为模块，同时也能被放置在以往的class path（此时module-info文件会被忽略）。module-info文件中的信息能够在编译和运行时通过模块的反射机制被读取、探测到。将模块声明文件（module-info.java）编译成类文件（.class）的一个优点是类文件已经具有精确定义和可扩展的格式。将从类路径加载的类型视为未命名模块的成员，这允许我们以增量、自底向上的方式将现有应用程序的组件从 JAR 文件迁移到模块。 例如，假设上面显示的应用程序最初是为 Java SE 8 构建的，作为放置在类路径上的一组名称相似的 JAR 文件。 如果我们在 Java SE 9 上按原样运行它，那么 JAR 文件中的类型将在未命名模块中定义。  ","version":null,"tagName":"h3"},{"title":"reference​","type":1,"pageTitle":"Java模块化","url":"/article/java-modular#reference","content":" [1]Java Platform, Standard Edition Tools Reference [2]Java9 模块化|darian1996 [3]The Java® Language Specification|Java SE 9 Edition [4]JEP 261: Module System [5]why-did-java-9-introduce-the-jmod-file-format|stackoverflow.com  其他参考：  真棒：使用Java 11实现应用的模块化|banq ","version":null,"tagName":"h2"},{"title":"Sentinel core原理分析","type":0,"sectionRef":"#","url":"/article/sentinel-core","content":"","keywords":"java","version":null},{"title":"简介​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#简介","content":" 提到Sentinel，相信大家都知道联想到熔断、服务间流量控制等。我之前也分析过Hystrix、Spring cloud的断路器设计，可看Spring Cloud的断路器--Spring Cloud Commons定义、Netflix Hystrix实现分析.  官网对Sentinel熔断总结和抽象的很好：  Sentinel 可以简单的分为 Sentinel 核心库和 Dashboard。 我们说的资源，可以是任何东西，服务，服务里的方法，甚至是一段代码。使用 Sentinel 来进行资源保护，主要分为几个步骤: 定义资源定义规则检验规则是否生效  想了解Sentinel就绕不开Sph，SphU，SphO，CtSph等。我想有人会好奇这名字代表什么意思， 官方说了Sph是一个魔法名(magic name)，原来指代信号量Semaphore，历史原因没法改。 U、O网上传闻代表Unit、Operation。  下面说下初始化和执行流程。  ","version":null,"tagName":"h2"},{"title":"初始化​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#初始化","content":" Sentinel初始化会调用InitExecutor.doInit()这个方法。进行如下初始化：   通过SPI加载InitFunc（Sentinel SPI类似Spring SPI，有兴趣可看下@SPI注解和SPILoader类）。排序调用InitFunc集合的init方法  我们看看这三个核心的InitFunc：  CommandCenterInitFuncHeartbeatSenderInitFuncMetricCallbackInit  ","version":null,"tagName":"h2"},{"title":"CommandCenter​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#commandcenter","content":" CommandCenterInitFunc能够初始化CommandCenter。  CommandCenter可以理解为提供服务，我们可以通过这个服务接口和Sentinel core通讯，具体接口由CommandHandler提供。  The simple command center provides service to exchange information.  围绕CommandCenter有这些工具类：  @CommandMappingCommandHandlerCommandHandlerInterceptor  CommandCenter有：  SimpleHttpCommandCenter 基于java ServerSocket的简单http实现NettyHttpCommandCenter netty实现SpringMvcHttpCommandCenter 基于Spring Boot的提供Spring MVC handlerMapping的实现。  简单说下常用的SimpleHttpCommandCenter实现：  启动单线程executor去执行server启动。bizExecutor是处理请求的executor。HttpEventTask读取HTTP报文，解析出CommandRequest，并执行CommandHandler。返回数据。  ","version":null,"tagName":"h3"},{"title":"HeartbeatSender​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#heartbeatsender","content":" HeartbeatSenderInitFunc通过SPI初始化HeartbeatSender。 HeartbeatSender是维持Sentinel core和Sentinel dashboard心跳的组件。   //通过SPI获取HeartbeatSender HeartbeatSender sender = HeartbeatSenderProvider.getHeartbeatSender(); if (sender == null) { RecordLog.warn(&quot;[HeartbeatSenderInitFunc] WARN: No HeartbeatSender loaded&quot;); return; } //初始化定时任务器 initSchedulerIfNeeded(); //获取心跳发送周期 1. 配置 2. 获取不到则用HeartbeatSender的interval long interval = retrieveInterval(sender); setIntervalIfNotExists(interval); //启动心跳任务 scheduleHeartbeatTask(sender, interval);   HeartbeatSender的实现有：  SimpleHttpHeartbeatSender 基于java Socket的http实现HttpHeartbeatSender 使用netty http发送心跳SpringMvcHttpHeartbeatSender 使用httpclient发送心跳  ","version":null,"tagName":"h3"},{"title":"MetricCallbackInit​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#metriccallbackinit","content":" MetricEntryCallback和MetricExitCallback通过MetricCallbackInit初始化。  public void init() throws Exception { StatisticSlotCallbackRegistry.addEntryCallback(MetricEntryCallback.class.getCanonicalName(), new MetricEntryCallback()); StatisticSlotCallbackRegistry.addExitCallback(MetricExitCallback.class.getCanonicalName(), new MetricExitCallback()); }   我们可以通过StatisticSlotCallbackRegistry.addEntryCallback和addExitCallback，增加Sentinel规则监控。 也可通过定义AdvancedMetricExtension接口SPI实现类来做到增加Sentinel规则监控。  ","version":null,"tagName":"h3"},{"title":"执行​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#执行","content":" 我们知道Sentinel一般使用SphU.entry作为入口。Sentinel core主流程可简单描述为：  定义资源 （目前有两种string资源和Method资源）定义规则（ProcessorSlot）检验规则是否生效  Do all Rules checking about the resource. Each distinct resource will use a ProcessorSlot to do rules checking. Same resource will use same ProcessorSlot globally.  SphU下面会执行如下语句：（Env.sph默认为CtSph。）   //SphU Env.sph.entry(name, trafficType, batchCount, args) //CtSph public Entry entry(String name, EntryType type, int count, Object... args) throws BlockException { StringResourceWrapper resource = new StringResourceWrapper(name, type); return entry(resource, count, args); }   我们接下来看下CtSph的核心流程：   private Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args) throws BlockException { //1. 获取当前线程的上下文 Context context = ContextUtil.getContext(); //2. 如果超过了最大context数(2000),直接返回 if (context instanceof NullContext) { // The {@link NullContext} indicates that the amount of context has exceeded the threshold, // so here init the entry only. No rule checking will be done. return new CtEntry(resourceWrapper, null, context); } //2. 如果是在最上层，初始化context if (context == null) { // Using default context. context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME); } // Global switch is close, no rule checking will do. if (!Constants.ON) { return new CtEntry(resourceWrapper, null, context); } //3. 获取slot调用链，以资源维度生成chain ProcessorSlot&lt;Object&gt; chain = lookProcessChain(resourceWrapper); /* * Means amount of resources (slot chain) exceeds {@link Constants.MAX_SLOT_CHAIN_SIZE}, * so no rule checking will be done. */ //4. 如果超过了MAX_SLOT_CHAIN_SIZE(6000)，则不执行rule检查 if (chain == null) { return new CtEntry(resourceWrapper, null, context); } // 5. 生成entry类（入口） Entry e = new CtEntry(resourceWrapper, chain, context); try { //6. 执行slot链 chain.entry(context, resourceWrapper, null, count, prioritized, args); } catch (BlockException e1) { // 规则检查，抛出sentiinel的block异常，调用exit做上下文处理和记录 e.exit(count, args); throw e1; } catch (Throwable e1) { // This should not happen, unless there are errors existing in Sentinel internal. RecordLog.info(&quot;Sentinel unexpected exception&quot;, e1); } return e; }   上面是核心流程，我们重点分析slot流程和Context的结构。  ","version":null,"tagName":"h2"},{"title":"Slot chain​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#slot-chain","content":" 引用官方文档的话，  在 Sentinel 里面，所有的资源都对应一个资源名称（resourceName），每次资源调用都会创建一个 Entry 对象。 Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 SphU API 显式创建。 Entry 创建的时候，同时也会创建一系列功能插槽（slot chain）。  slot chain是在上面第三步初始化的lookProcessChain(resourceWrapper);。   //CtSph ProcessorSlot&lt;Object&gt; lookProcessChain(ResourceWrapper resourceWrapper) { ProcessorSlotChain chain = chainMap.get(resourceWrapper); if (chain == null) { synchronized (LOCK) { chain = chainMap.get(resourceWrapper); if (chain == null) { // Entry size limit. if (chainMap.size() &gt;= Constants.MAX_SLOT_CHAIN_SIZE) { return null; } chain = SlotChainProvider.newSlotChain(); //省略 } } } return chain; } //SlotChainProvider slotChainBuilder = SpiLoader.of(SlotChainBuilder.class).loadFirstInstanceOrDefault(); //DefaultSlotChainBuilder List&lt;ProcessorSlot&gt; sortedSlotList = SpiLoader.of(ProcessorSlot.class).loadInstanceListSorted();   说说初始化步骤：  通过单例方式初始化resource的ProcessorSlotChain。通过SPI初始化SlotChainBuilder通过SPI初始化ProcessorSlot集合  ProcessorSlotChain的结构是一个单向链表，默认的链表元素有（按执行顺序）(部分描述取自wiki)：  NodeSelectorSlot 负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级；ClusterBuilderSlot 则用于存储资源的统计信息以及调用者信息，例如该资源的RT, QPS, thread count等等，这些信息将用作为多维度限流，降级的依据；LogSlot 打印一些block日志StatisticSlot 用于记录、统计不同纬度的runtime指标监控信息；AuthoritySlot 黑白名单控制，以资源名为缓存维度，以origin（app）为控制维度。SystemSlot 用于系统负载限制，可以对总体的应用数据qps、thread、rt达到某阈值做block, 也可以对系统load、cpu用量达到某阈值做block。FlowSlot 限流策略实现，基于阈值类型、流控模式、效果（fail fast、warm up、queue wait）这几个维度去做控制。DegradeSlot 降级策略实现，有基于rt、异常比例、异常次数三种方式降级。  以上slot是执行流程。  数据结构在Context中进行解读。  ","version":null,"tagName":"h3"},{"title":"Sentinel Context结构​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#sentinel-context结构","content":" 我们先看这段例子代码的：   // 配置规则. initFlowRules(); ContextUtil.enter(&quot;entrance1&quot;, &quot;appA&quot;); Entry nodeA = null; try { nodeA = SphU.entry(&quot;nodeA&quot;); } catch (BlockException e) { // 处理被流控的逻辑 System.out.println(&quot;1 blocked!&quot;); } if (nodeA != null) { nodeA.exit(); } ContextUtil.exit(); ContextUtil.enter(&quot;entrance2&quot;, &quot;appB&quot;); try { nodeA = SphU.entry(&quot;nodeB&quot;); } catch (BlockException e) { // 处理被流控的逻辑 System.out.println(&quot;node b blocked!&quot;); } if (nodeA != null) { nodeA.exit(); } ContextUtil.exit(); ContextUtil.enter(&quot;entrance2&quot;, &quot;appA&quot;); try { nodeA = SphU.entry(&quot;nodeA&quot;); } catch (BlockException e) { // 处理被流控的逻辑 System.out.println(&quot;nodeA 2 blocked!&quot;); } if (nodeA != null) { nodeA.exit(); } ContextUtil.exit(); try { nodeA = SphU.entry(&quot;nodeC&quot;); } catch (BlockException e) { // 处理被流控的逻辑 System.out.println(&quot;nodeC blocked!&quot;); } if (nodeA != null) { nodeA.exit(); }   这段代码执行时的整体数据依赖关系：   可看到Context的结构包含了：  nameentranceNodecurEntryorigin  CtEntry是当前Context中的一个链表结构，指代一个入口，包含：  父子entrycontextProcessSlotChaincurNode  StatisticNode和leapArray​  按照Sentinel的文档来看，是基于时间窗口，其实现算法是leapArray。  统计的相关数据都用到node我们来看下Node的继承关系：   我们看到顶级父类是StatisticNode里面核心的属性是：rollingCounterInSecond和rollingCounterInMinute。其实现的数据结构就是LeapArray&lt;MetricBucket&gt;。 （DegradeSlot熔断降级是额外新增了LeapArray去统计） LeapArray是基于时间窗口的实现，会把一段时间(intervalInMs)切分为取样个数(sampleCount)。  int windowLengthInMs 单窗格的毫秒int sampleCount 取样个数 sampleCount = intervalInMs / windowLengthInMsint intervalInMs 间隔时间(ms)double intervalInSecond 间隔的时间(s)AtomicReferenceArray &lt;WindowWrap&lt;MetricBucket&gt;&gt; array 存储窗格的接口。ReentrantLock updateLock 插入和替换窗格的锁  数组里取样位的数据结构是MetricBucket，MetricBucket存储以下几种类型的计数：  PASSBLOCKEXCEPTIONSUCCESSRT Response Time。OCCUPIED_PASS  结构整理如下：   分析下leapArray的核心方法：   // 用 当前时间 根据 窗格时长 计算出当前时间的滑动窗口的 数组下标 private int calculateTimeIdx(/*@Valid*/ long timeMillis) { long timeId = timeMillis / windowLengthInMs; return (int) (timeId % array.length()); } // 用 当前时间 根据 窗格时长 计算出当前滑动窗口的 开始时间 例如：12 - 12%2 = 10 protected long calculateWindowStart(/*@Valid*/ long timeMillis) { return timeMillis - timeMillis % windowLengthInMs; } public WindowWrap&lt;T&gt; currentWindow(long timeMillis) { if (timeMillis &lt; 0) { return null; } //窗口滑动方法 计算窗格下标 int idx = calculateTimeIdx(timeMillis); //窗口滑动方法 计算当前窗格bucket long windowStart = calculateWindowStart(timeMillis); /* * Get bucket item at given time from the array. * * (1) Bucket is absent, then just create a new bucket and CAS update to circular array. * (2) Bucket is up-to-date, then just return the bucket. * (3) Bucket is deprecated, then reset current bucket. 1. bucket不存在，则创建一个新并CAS更新。 2. bucket是当前最新的，返回。 3. bucket是过时并应该弃用，加锁并重置当前bucket. 4. windowStart&lt;窗口开始时间，意味着输入的时间超过了intervalInMs，是错误的输入，理论上不应该输入。 */ while (true) { WindowWrap&lt;T&gt; old = array.get(idx); if (old == null) { /* * B0 B1 B2 NULL B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * bucket is empty, so create new and update * * If the old bucket is absent, then we create a new bucket at {@code windowStart}, * then try to update circular array via a CAS operation. Only one thread can * succeed to update, while other threads yield its time slice. */ WindowWrap&lt;T&gt; window = new WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); if (array.compareAndSet(idx, null, window)) { // Successfully updated, return the created bucket. return window; } else { // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); } } else if (windowStart == old.windowStart()) { /* * B0 B1 B2 B3 B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * startTime of Bucket 3: 800, so it's up-to-date * * If current {@code windowStart} is equal to the start timestamp of old bucket, * that means the time is within the bucket, so directly return the bucket. */ return old; } else if (windowStart &gt; old.windowStart()) { /* * (old) * B0 B1 B2 NULL B4 * |_______||_______|_______|_______|_______|_______||___ * ... 1200 1400 1600 1800 2000 2200 timestamp * ^ * time=1676 * startTime of Bucket 2: 400, deprecated, should be reset * * If the start timestamp of old bucket is behind provided time, that means * the bucket is deprecated. We have to reset the bucket to current {@code windowStart}. * Note that the reset and clean-up operations are hard to be atomic, * so we need a update lock to guarantee the correctness of bucket update. * * The update lock is conditional (tiny scope) and will take effect only when * bucket is deprecated, so in most cases it won't lead to performance loss. */ if (updateLock.tryLock()) { try { // Successfully get the update lock, now we reset the bucket. return resetWindowTo(old, windowStart); } finally { updateLock.unlock(); } } else { // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); } } else if (windowStart &lt; old.windowStart()) { // Should not go through here, as the provided time is already behind. return new WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); } } }   ","version":null,"tagName":"h3"},{"title":"总结​","type":1,"pageTitle":"Sentinel core原理分析","url":"/article/sentinel-core#总结","content":"  上图取自sentinel的wiki。  以前对Sentinel有一些源码的阅读和理解，不得不感叹看过的东西又再忘记了，这次让团队中一位小伙伴基于Sentinel开发一个组件，我再捡起来顺便记录下。 本节主要聚焦于初始化和核心执行流程（非异步侧）。对基础数据结构也做了分析。  重点分析了Sentinel core的初始化，ProcessSlotChain执行流程，Context和LeapArray。 Sentinel经历过很多公司的线上大流量验证，我们也能在其中看到一些历史，学到一些质朴的清晰的可拓展的代码设计流程。 ","version":null,"tagName":"h2"},{"title":"Thrift传输原理","type":0,"sectionRef":"#","url":"/article/thrift-rpc","content":"","keywords":"thrift","version":null},{"title":"简介​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#简介","content":" Thrift作为一种接口定义语言（IDL）和二进制通信协议被应用在程序设计的服务创建和定义中，我们更常见称呼Thrift为RPC框架。 在使用Thrift中，我认为Thrift有如下特点：  支持语言众多。拥有自成一体的IDL，各种语言C++、Java、Python等都有实现。传输性能优秀。RPC性能对比不错，很多大公司，还有组件（Hadoop、Hive等）都使用它。    ","version":null,"tagName":"h2"},{"title":"组件职责和传输​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#组件职责和传输","content":" Thrift官网有介绍Thrift Server的网络层和各组件作用，我们跟着顺藤摸瓜：  +-------------------------------------------+ | Server | | (single-threaded, event-driven etc) | +-------------------------------------------+ | Processor | | (compiler generated) | +-------------------------------------------+ | Protocol | | (JSON, compact etc) | +-------------------------------------------+ | Transport | | (raw TCP, HTTP etc) | +-------------------------------------------+   上图给出整体流程图，我这里一一说下：  Transport 网络传输封装，TCP、HTTP之类。最终传输层协议实现有在类中生成socket，也有会抽象一层TSocket去做。 TFramedTransportTNonblockingTransportTHttpClient Protocol 传输序列化协议 TBinaryProtocolTCompactProtocolTJSONProtocol TProcessor thrift代码生成，传输及序列化流程处理TServer 处理网络流程执行，数据处理整个流程 TSimpleServerTThreadPoolServerTNonblockingCompleteServer Client和TServiceClient thrift生成的代码，client端调用使用  ","version":null,"tagName":"h2"},{"title":"协议分析​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#协议分析","content":" ","version":null,"tagName":"h2"},{"title":"Strict Binary协议​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#strict-binary协议","content":" 调用示例  enum TypeEnum { UNKNOWN = 0; ADMIN = 1; NORMAL = 2; } struct Req { 1:i32 id; 2:TypeEnum type; 3:string name; 4:map&lt;string, string&gt; parameters; 5:bool fill_info; } struct UserInfo { 1:i32 id; 2:TypeEnum type; 3:string name; 4:map&lt;string, string&gt; parameters; 5:bool status; } service SimpleThriftService { string knock(1:string msg); UserInfo getUserInfo(1:Req req); }   TTransport transport = new TSocket(&quot;localhost&quot;, 9090); TProtocol protocol = new TBinaryProtocol(transport); SimpleThriftService.Client client = new SimpleThriftService.Client(protocol); transport.open(); Req req = new Req(1, TypeEnum.NORMAL, &quot;test&quot;, new HashMap&lt;String, String&gt;() {{put(&quot;k&quot;, &quot;v&quot;);}}, false); UserInfo userInfo = client.getUserInfo(req);   分析字节码​  以使用最广的strict Binary协议为例，基于上面示例调用，进行了抓包，结合文档对字节码进行直观分析。 注：wireshark抓包的话自带了一些方便的标注。 这里只标注了client请求协议体，server reply返回的消息格式相同。  //Message 80 01// 10000000 00000001 首位1标识为strict binary protocol, 其余15位标识版本号 00 // 无用字节 01 // message type消息类型 1：CALL 00 00 00 0b // 方法名长度 11 67 65 74 55 73 65 72 49 6e 66 6f // 方法名：getUserInfo 00 00 00 01 // seq id顺序id，client用这个号去处理消息的失序响应 //Struct 0c // field类型：T_STRUCT 00 00// field id: 0 00 // 类型: T_STOP 0c // field类型：T_STRUCT 00 01 // field id: 1 08 // field类型：I32 00 01 // field id: 1 00 00 00 01 // int32值=1 08 // field类型：I32 00 02 // field id: 2 00 00 00 02 // int32值=2 0b // field类型：BINARY 00 03 // field id: 3 00 00 00 04 // BINARY field会带length，为4 74 65 73 74 //string值为test 0d // field类型：MAP 00 04 //field id: 4 0b //key type: BINARY 0b //value type: BINARY 00 00 00 01 //map的item数，该例子为1 00 00 00 01 //length：1 6b //值为 k 00 00 00 01 //value length：1 76 // 值为 v 02 // field类型：BOOL 00 05 //field id: 5 00 //值为FALSE 00 //T_STOP 标识STRUCT结束 00 //T_STOP 标识整体数据结束   协议格式​    1. 协议头​  分为这四种消息类型  Call: 1 client发送的消息类型，指代需要响应的消息。Reply: 2 server回复响应的消息。Exception: 3 server异常消息。Oneway: 4 client发送的单向消息，不需要返回。  2. 协议体​    一般定长数据：i32、i64、BOOL等，采用TV模式，字段类型（1字节）+ field id（2字节）+ 值变长数据：STRUCT、BINARY、MAP、LIST、SET等，采用TLV模式，字段类型（1字节）+ field id（2字节）+ field length (4字节) + 值  定长数据类型  数据类型\t字段类型（1个字节）\t类型尺寸（单位：字节）bool\t2\t1 byte\t3\t1 double\t4\t8 i16\t6\t2 i32\t8\t4 i64\t10\t8  变长数据类型  数据类型\t字段类型（1个字节）\t类型尺寸（长度 + 值）string\t11\t4 + N struct\t12\t嵌套数据 + 1个字节停止符STOP（00） map\t13\t1 + 1 + 4 + n*(k+v) set\t14\t1 + 4 + N 【val类型 + item数 + 值】 list\t15\t1 + 4 + N 【val类型 + item数 + 值】  ","version":null,"tagName":"h3"},{"title":"老（non-strict）Binary协议​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#老non-strictbinary协议","content":" 字段分析同上。  ","version":null,"tagName":"h3"},{"title":"Compact协议​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#compact协议","content":" 协议格式​    1. 协议头​  对比Binary协议，将消息类型和版本做了压缩，头字段排列做了优化。  2. 协议体​  协议体的压缩主要是通过zigzag和var int（protobuf也用到这两算法去做压缩），对数字类型和变长字段的length头做压缩。  Zigzag  作用：能够将有符号数压缩为无符号整数。从而减少存储和传输空间。 int32算法：(n &lt;&lt; 1) ^ (n &gt;&gt; 31) 举例：处理整数 1和-1。  原始：00000000 00000000 00000000 00000001 左移位n &lt;&lt; 1：00000000 00000000 00000000 00000010 右移位n &gt;&gt; 31：00000000 00000000 00000000 00000000 异或：00000000 00000000 00000000 00000010 原始：11111111 11111111 11111111 11111111 左移位n &lt;&lt; 1: 11111111 11111111 11111111 11111110 右移位n &gt;&gt; 31：11111111 11111111 11111111 11111111 异或：00000000 00000000 00000000 00000001   经过编码后，-1转换为无符号整数，方便压缩。  Var int 作用：能够将正整数压缩字节数，结合zigzag能够减少存储和传输空间。 例子：转换数字123456 -&gt; 结果10111001 01100000  //算法：复制自TCompactProtocol public static byte[] toVarint32(int n) { byte[] i32buf = new byte[5]; int idx = 0; while (true) { if ((n &amp; ~0x7F) == 0) { i32buf[idx++] = (byte)n; // writeByteDirect((byte)n); break; // return; } else { i32buf[idx++] = (byte)((n &amp; 0x7F) | 0x80); // writeByteDirect((byte)((n &amp; 0x7F) | 0x80)); n &gt;&gt;&gt;= 7; } } return i32buf; } 数字123456：00000000 00000000 00110000 00111001 1次循环:10111001 2次循环:10111001 01100000     需要注意：compact协议的对小数值数字，压缩能力好，但是对于大数，压缩能力有限。  ","version":null,"tagName":"h3"},{"title":"JSON协议​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#json协议","content":" json协议编码在Thrift不常用且不建议用，这里不打算说。  ","version":null,"tagName":"h3"},{"title":"Reference​","type":1,"pageTitle":"Thrift传输原理","url":"/article/thrift-rpc#reference","content":" [1]https://en.wikipedia.org/wiki/Apache_Thrift [2]https://thrift.apache.org/docs/concepts.html [3]https://developer.aliyun.com/article/643859 [4]Thrift spec https://github.com/apache/thrift/blob/master/doc/specs/thrift-rpc.md [5]https://github.com/apache/thrift/blob/master/doc/specs/thrift-binary-protocol.md [6]https://zhuanlan.zhihu.com/p/476213759 [7]https://www.linux88.com/zigzag/ ","version":null,"tagName":"h2"},{"title":"容器环境下的相关JVM参数","type":0,"sectionRef":"#","url":"/article/java-container-args","content":"","keywords":"java","version":null},{"title":"历史​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#历史","content":" JDK8u121加入了UseCGroupMemoryLimitForHeap这一参数，对容器内存设置做支持。(JDK-8170888)JDK8u191后加入了UseContainerSupport、MaxRAMPercentage、MinRAMPercentage、InitialRAMPercentage参数。 deprecate了UseCGroupMemoryLimitForHeap、MaxRAMFraction、MinRAMFraction、InitialRAMFraction参数。  ","version":null,"tagName":"h3"},{"title":"用法​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#用法","content":" 建议使用大于8u191版本的JAVA。  这里列举参数的默认值，方便下文说明。  java -XX:+PrintFlagsFinal -version | grep -Ei &quot;maxheapsize|maxram|initialram&quot; uintx DefaultMaxRAMFraction = 4 {product} //默认的堆内存系数 uintx InitialRAMFraction = 64 {product} //初始化堆内存系数，简单来说，机器（容器）内存/InitialRAMFraction=初始化堆内存内存 double InitialRAMPercentage = 1.562500 {product} //初始化堆内存百分比，简单来说，机器（容器）内存*InitialRAMPercentage/100=初始化堆内存大小 uintx MaxHeapSize := 4139778048 {product} //堆的默认最大值 uint64_t MaxRAM = 137438953472 {pd product} //和MaxHeapSize一起，用于运行时MaxHeapSize的计算 uintx MaxRAMFraction = 4 {product} //最大的堆内存系数，简单来说，机器（容器）内存/MaxRAMFraction=最大堆内存 double MaxRAMPercentage = 25.000000 {product} //最大的堆内存百分比，简单来说，机器（容器）内存*MaxRAMPercentage/100=最大堆内存   ","version":null,"tagName":"h2"},{"title":"java版本 < 8u121​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#java版本--8u121","content":" 不要在容器化环境使用。  ","version":null,"tagName":"h3"},{"title":"8u121 < java版本 < 8u191​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#8u121--java版本--8u191","content":" 如果是使用OracleJDK需要额外开启实验参数-XX:UnlockExperimentalVMOptions。  建议使用如下参数：  -XX:UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=2 -XX:MinRAMFraction=2   或自行设置  -Xmx:{用户自定义}   ","version":null,"tagName":"h3"},{"title":"java版本 >=8u191​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#java版本-8u191","content":" JDK8u191后新增了容器支持开关-XX:UseContainerSupport，并且默认开启。 并增加了这些参数：  MaxRAMPercentage 堆的最大值百分比。InitialRAMPercentage 堆的初始化的百分比。MinRAMPercentage 堆的最小值的百分比。  建议使用内存参数参数：  -XX:MaxRAMPercentage=70.0 -XX:InitialRAMPercentage=50.0   计算方法（这里做了简化，实际计算要复杂些）： 最大堆大小 = MaxRAM（默认为容器最大可使用内存） * MaxRAMPercentage / 100。  注意：如果使用了-Xmx参数，则不会进入上面的堆大小的计算逻辑，而直接将MaxHeapSize（最大堆大小）等同于我们设置的-Xmx。  ","version":null,"tagName":"h3"},{"title":"OpenJDK相关源码解读​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#openjdk相关源码解读","content":" 我对相关方法做了注释。  osContainer_linux.cpp是linux的容器信息的读取和计算的类。里面有如下方法：  /* init * * Initialize the container support and determine if * we are running under cgroup control. * * 容器环境下的初始化和判定 * */ void OSContainer::init() { int mountid; int parentid; int major; int minor; FILE *mntinfo = NULL; FILE *cgroup = NULL; char buf[MAXPATHLEN+1]; char tmproot[MAXPATHLEN+1]; char tmpmount[MAXPATHLEN+1]; char tmpbase[MAXPATHLEN+1]; char *p; //是否已经初始化 assert(!_is_initialized, &quot;Initializing OSContainer more than once&quot;); _is_initialized = true; _is_containerized = false; //修正_unlimited_memory _unlimited_memory = (LONG_MAX / os::vm_page_size()) * os::vm_page_size(); if (PrintContainerInfo) { tty-&gt;print_cr(&quot;OSContainer::init: Initializing Container Support&quot;); } //UseContainerSupport没有打开则跳出去 if (!UseContainerSupport) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Container Support not enabled&quot;); } return; } /* * * 找到cgroup的挂载点信息 * Find the cgroup mount point for memory and cpuset * by reading /proc/self/mountinfo * * Example for docker: * 219 214 0:29 /docker/7208cebd00fa5f2e342b1094f7bed87fa25661471a4637118e65f1c995be8a34 /sys/fs/cgroup/memory ro,nosuid,nodev,noexec,relatime - cgroup cgroup rw,memory * * Example for host: * 34 28 0:29 / /sys/fs/cgroup/memory rw,nosuid,nodev,noexec,relatime shared:16 - cgroup cgroup rw,memory */ mntinfo = fopen(&quot;/proc/self/mountinfo&quot;, &quot;r&quot;); if (mntinfo == NULL) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Can't open /proc/self/mountinfo, %s&quot;, strerror(errno)); } return; } while ( (p = fgets(buf, MAXPATHLEN, mntinfo)) != NULL) { // Look for the filesystem type and see if it's cgroup char fstype[MAXPATHLEN+1]; fstype[0] = '\\0'; char *s = strstr(p, &quot; - &quot;); if (s != NULL &amp;&amp; sscanf(s, &quot; - %s&quot;, fstype) == 1 &amp;&amp; strcmp(fstype, &quot;cgroup&quot;) == 0) { if (strstr(p, &quot;memory&quot;) != NULL) { int matched = sscanf(p, &quot;%d %d %d:%d %s %s&quot;, &amp;mountid, &amp;parentid, &amp;major, &amp;minor, tmproot, tmpmount); if (matched == 6) { //内存信息 memory = new CgroupSubsystem(tmproot, tmpmount); } else if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Incompatible str containing cgroup and memory: %s&quot;, p); } } else if (strstr(p, &quot;cpuset&quot;) != NULL) { int matched = sscanf(p, &quot;%d %d %d:%d %s %s&quot;, &amp;mountid, &amp;parentid, &amp;major, &amp;minor, tmproot, tmpmount); if (matched == 6) { //cpuset: 用来绑定cgroup到指定CPU的哪个核上和NUMA节点 cpuset = new CgroupSubsystem(tmproot, tmpmount); } else { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Incompatible str containing cgroup and cpuset: %s&quot;, p); } } } else if (strstr(p, &quot;cpu,cpuacct&quot;) != NULL || strstr(p, &quot;cpuacct,cpu&quot;) != NULL) { int matched = sscanf(p, &quot;%d %d %d:%d %s %s&quot;, &amp;mountid, &amp;parentid, &amp;major, &amp;minor, tmproot, tmpmount); if (matched == 6) { //cpu：用来限制cgroup的CPU使用率 cpu = new CgroupSubsystem(tmproot, tmpmount); //cpuacct: 用来统计cgroup的CPU的使用率 cpuacct = new CgroupSubsystem(tmproot, tmpmount); } else { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Incompatible str containing cgroup and cpu,cpuacct: %s&quot;, p); } } } else if (strstr(p, &quot;cpuacct&quot;) != NULL) { int matched = sscanf(p, &quot;%d %d %d:%d %s %s&quot;, &amp;mountid, &amp;parentid, &amp;major, &amp;minor, tmproot, tmpmount); if (matched == 6) { cpuacct = new CgroupSubsystem(tmproot, tmpmount); } else { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Incompatible str containing cgroup and cpuacct: %s&quot;, p); } } } else if (strstr(p, &quot;cpu&quot;) != NULL) { int matched = sscanf(p, &quot;%d %d %d:%d %s %s&quot;, &amp;mountid, &amp;parentid, &amp;major, &amp;minor, tmproot, tmpmount); if (matched == 6) { cpu = new CgroupSubsystem(tmproot, tmpmount); } else { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Incompatible str containing cgroup and cpu: %s&quot;, p); } } } } } fclose(mntinfo); if (memory == NULL) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Required cgroup memory subsystem not found&quot;); } return; } if (cpuset == NULL) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Required cgroup cpuset subsystem not found&quot;); } return; } if (cpu == NULL) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Required cgroup cpu subsystem not found&quot;); } return; } if (cpuacct == NULL) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Required cgroup cpuacct subsystem not found&quot;); } return; } /* * Read /proc/self/cgroup and map host mount point to * local one via /proc/self/mountinfo content above * * 读取 /proc/self/cgroup 并通过上面的 /proc/self/mountinfo 内容将本容器的各cgroup子系统的值映射到JVM变量上 * * Docker example: * 5:memory:/docker/6558aed8fc662b194323ceab5b964f69cf36b3e8af877a14b80256e93aecb044 * * Host example: * 5:memory:/user.slice * * Construct a path to the process specific memory and cpuset * cgroup directory. * * For a container running under Docker from memory example above * the paths would be: * * /sys/fs/cgroup/memory * * For a Host from memory example above the path would be: * * /sys/fs/cgroup/memory/user.slice * */ cgroup = fopen(&quot;/proc/self/cgroup&quot;, &quot;r&quot;); if (cgroup == NULL) { if (PrintContainerInfo) { tty-&gt;print_cr(&quot;Can't open /proc/self/cgroup, %s&quot;, strerror(errno)); } return; } while ( (p = fgets(buf, MAXPATHLEN, cgroup)) != NULL) { int cgno; int matched; char *controller; char *base; /* Skip cgroup number */ strsep(&amp;p, &quot;:&quot;); /* Get controller and base */ controller = strsep(&amp;p, &quot;:&quot;); base = strsep(&amp;p, &quot;\\n&quot;); if (controller != NULL) { if (strstr(controller, &quot;memory&quot;) != NULL) { memory-&gt;set_subsystem_path(base); } else if (strstr(controller, &quot;cpuset&quot;) != NULL) { cpuset-&gt;set_subsystem_path(base); } else if (strstr(controller, &quot;cpu,cpuacct&quot;) != NULL || strstr(controller, &quot;cpuacct,cpu&quot;) != NULL) { cpu-&gt;set_subsystem_path(base); cpuacct-&gt;set_subsystem_path(base); } else if (strstr(controller, &quot;cpuacct&quot;) != NULL) { cpuacct-&gt;set_subsystem_path(base); } else if (strstr(controller, &quot;cpu&quot;) != NULL) { cpu-&gt;set_subsystem_path(base); } } } fclose(cgroup); // We need to update the amount of physical memory now that // command line arguments have been processed. // 读取cgroup的内存绑定点(/memory.limit_in_bytes)的内存限制值，并设置到JVM全局的物理内存大小变量 if ((mem_limit = memory_limit_in_bytes()) &gt; 0) { os::Linux::set_physical_memory(mem_limit); } _is_containerized = true; }   arguments.cpp是对我们各种JVM参数做解析和设置的类，这里，我分析下set_heap_size（设置堆大小）这一方法。  void Arguments::set_heap_size() { if (!FLAG_IS_DEFAULT(DefaultMaxRAMFraction)) { // Deprecated flag FLAG_SET_CMDLINE(uintx, MaxRAMFraction, DefaultMaxRAMFraction); } //如果设置了MaxRAM，则使用 julong phys_mem = FLAG_IS_DEFAULT(MaxRAM) ? MIN2(os::physical_memory(), (julong)MaxRAM) : (julong)MaxRAM; // Experimental support for CGroup memory limits //如果开启了UseCGroupMemoryLimitForHeap，则读取cgroup的内存，此选项已是deprecate选项 if (UseCGroupMemoryLimitForHeap) { // This is a rough indicator that a CGroup limit may be in force // for this process const char* lim_file = &quot;/sys/fs/cgroup/memory/memory.limit_in_bytes&quot;; FILE *fp = fopen(lim_file, &quot;r&quot;); if (fp != NULL) { julong cgroup_max = 0; int ret = fscanf(fp, JULONG_FORMAT, &amp;cgroup_max); if (ret == 1 &amp;&amp; cgroup_max &gt; 0) { // If unlimited, cgroup_max will be a very large, but unspecified // value, so use initial phys_mem as a limit if (PrintGCDetails &amp;&amp; Verbose) { // Cannot use gclog_or_tty yet. tty-&gt;print_cr(&quot;Setting phys_mem to the min of cgroup limit (&quot; JULONG_FORMAT &quot;MB) and initial phys_mem (&quot; JULONG_FORMAT &quot;MB)&quot;, cgroup_max/M, phys_mem/M); } //取cpgroup_max（有可能没限制）和物理内存的最小值 phys_mem = MIN2(cgroup_max, phys_mem); } else { warning(&quot;Unable to read/parse cgroup memory limit from %s: %s&quot;, lim_file, errno != 0 ? strerror(errno) : &quot;unknown error&quot;); } fclose(fp); } else { warning(&quot;Unable to open cgroup memory limit file %s (%s)&quot;, lim_file, strerror(errno)); } } // Convert Fraction to Precentage values //注：MaxRAMFraction、MinRAMFraction、InitialRAMFraction皆为deprecate参数，不建议使用 if (FLAG_IS_DEFAULT(MaxRAMPercentage) &amp;&amp; !FLAG_IS_DEFAULT(MaxRAMFraction)) MaxRAMPercentage = 100.0 / MaxRAMFraction; if (FLAG_IS_DEFAULT(MinRAMPercentage) &amp;&amp; !FLAG_IS_DEFAULT(MinRAMFraction)) MinRAMPercentage = 100.0 / MinRAMFraction; if (FLAG_IS_DEFAULT(InitialRAMPercentage) &amp;&amp; !FLAG_IS_DEFAULT(InitialRAMFraction)) InitialRAMPercentage = 100.0 / InitialRAMFraction; // If the maximum heap size has not been set with -Xmx, // then set it as fraction of the size of physical memory, // respecting the maximum and minimum sizes of the heap. //如果没有设置Xmx，则进入MaxHeapSize计算逻辑 if (FLAG_IS_DEFAULT(MaxHeapSize)) { julong reasonable_max = (julong)((phys_mem * MaxRAMPercentage) / 100); const julong reasonable_min = (julong)((phys_mem * MinRAMPercentage) / 100); if (reasonable_min &lt; MaxHeapSize) { // Small physical memory, so use a minimum fraction of it for the heap reasonable_max = reasonable_min; } else { // Not-small physical memory, so require a heap at least // as large as MaxHeapSize reasonable_max = MAX2(reasonable_max, (julong)MaxHeapSize); } if (!FLAG_IS_DEFAULT(ErgoHeapSizeLimit) &amp;&amp; ErgoHeapSizeLimit != 0) { // Limit the heap size to ErgoHeapSizeLimit reasonable_max = MIN2(reasonable_max, (julong)ErgoHeapSizeLimit); } if (UseCompressedOops) { // Limit the heap size to the maximum possible when using compressed oops julong max_coop_heap = (julong)max_heap_for_compressed_oops(); if (HeapBaseMinAddress + MaxHeapSize &lt; max_coop_heap) { // Heap should be above HeapBaseMinAddress to get zero based compressed oops // but it should be not less than default MaxHeapSize. max_coop_heap -= HeapBaseMinAddress; } reasonable_max = MIN2(reasonable_max, max_coop_heap); } reasonable_max = limit_by_allocatable_memory(reasonable_max); if (!FLAG_IS_DEFAULT(InitialHeapSize)) { // An initial heap size was specified on the command line, // so be sure that the maximum size is consistent. Done // after call to limit_by_allocatable_memory because that // method might reduce the allocation size. reasonable_max = MAX2(reasonable_max, (julong)InitialHeapSize); } if (PrintGCDetails &amp;&amp; Verbose) { // Cannot use gclog_or_tty yet. tty-&gt;print_cr(&quot; Maximum heap size &quot; SIZE_FORMAT, (size_t) reasonable_max); } FLAG_SET_ERGO(uintx, MaxHeapSize, (uintx)reasonable_max); } // If the minimum or initial heap_size have not been set or requested to be set // ergonomically, set them accordingly. //如果InitialHeapSize或min_heap_size没有设置，则进入计算逻辑 if (InitialHeapSize == 0 || min_heap_size() == 0) { julong reasonable_minimum = (julong)(OldSize + NewSize); reasonable_minimum = MIN2(reasonable_minimum, (julong)MaxHeapSize); reasonable_minimum = limit_by_allocatable_memory(reasonable_minimum); if (InitialHeapSize == 0) { julong reasonable_initial = (julong)((phys_mem * InitialRAMPercentage) / 100); reasonable_initial = MAX3(reasonable_initial, reasonable_minimum, (julong)min_heap_size()); reasonable_initial = MIN2(reasonable_initial, (julong)MaxHeapSize); reasonable_initial = limit_by_allocatable_memory(reasonable_initial); if (PrintGCDetails &amp;&amp; Verbose) { // Cannot use gclog_or_tty yet. tty-&gt;print_cr(&quot; Initial heap size &quot; SIZE_FORMAT, (uintx)reasonable_initial); } FLAG_SET_ERGO(uintx, InitialHeapSize, (uintx)reasonable_initial); } // 没设置-Xms，最小heapSize使用InitialHeapSize if (min_heap_size() == 0) { set_min_heap_size(MIN2((uintx)reasonable_minimum, InitialHeapSize)); if (PrintGCDetails &amp;&amp; Verbose) { // Cannot use gclog_or_tty yet. tty-&gt;print_cr(&quot; Minimum heap size &quot; SIZE_FORMAT, min_heap_size()); } } } }   ","version":null,"tagName":"h2"},{"title":"reference​","type":1,"pageTitle":"容器环境下的相关JVM参数","url":"/article/java-container-args#reference","content":" [1]java11 arguments.cpp [2]java|Java Platform, Standard Edition Tools Reference [3]Cgroup - cpu, cpuacct, cpuset子系统|大彬 [4]JDK-8146115 [5]github-openjdk-jdk8u [6]proc(5) — Linux manual page [7]/proc FILESYSTEM [8]Linux资源管理之cgroups简介|大龙，志超 ","version":null,"tagName":"h2"},{"title":"算法架构与人工智能","type":0,"sectionRef":"#","url":"/docs/ai-arch","content":"算法架构与人工智能 这里有空会输出一些我工作中用到和平时了解到的搜推广算法架构、深度、AIGC相关知识点。","keywords":"","version":"Next"},{"title":"c++的基础知识梳理","type":0,"sectionRef":"#","url":"/docs/ai-arch/cpp","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#简介","content":" 前阵子学习了解了cpp，对其语法和基础库特点，结合自己在项目中的使用，做了常用知识点整理。 方便形成体系的去对c++的能力加深印象，平常我们也可按照这个树去查漏补缺。  ","version":"Next","tagName":"h2"},{"title":"特性梳理和总结​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#特性梳理和总结","content":" C++ 11    ","version":"Next","tagName":"h2"},{"title":"基本安装​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#基本安装","content":" sudo apt update sudo apt install aptitude sudo aptitude install gcc g++  vscode for linuxhttps://zhuanlan.zhihu.com/p/344940452https://zhuanlan.zhihu.com/p/618043511  C++跨linux发行版https://blog.csdn.net/wqfhenanxc/article/details/106191068  ","version":"Next","tagName":"h2"},{"title":"打包和部署​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#打包和部署","content":" 静态库和动态库：https://www.runoob.com/w3cnote/cpp-static-library-and-dynamic-library.html  包管理工具: conan  ","version":"Next","tagName":"h3"},{"title":"c++排查问题工具栈​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#c排查问题工具栈","content":" ","version":"Next","tagName":"h2"},{"title":"调试​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#调试","content":" 一般使用gdb或者gdbserver。  远程服务器编译时，记得加-g参数 g++ helloworld.cpp -g 或者cmake增加 cmake -DCMAKE_BUILD_TYPE=Debug标记。  用gdbserver启动：（gdb打断点命令查文档） gdbserver :12345 ./a.out  ","version":"Next","tagName":"h3"},{"title":"问题排查工具​","type":1,"pageTitle":"c++的基础知识梳理","url":"/docs/ai-arch/cpp#问题排查工具","content":" 工具\t作用Valgrind / heaptrack\t查看内存泄漏问题、越界访问 perf\t方法追踪 perf + FlameGraph\t可以查火焰图 GDB\t附加到运行进程，查线程栈也可 strace\t跟踪系统调用 ","version":"Next","tagName":"h3"},{"title":"Consul部署","type":0,"sectionRef":"#","url":"/docs/ai-arch/consul/consul-deploy","content":"","keywords":"","version":"Next"},{"title":"单节点部署运行​","type":1,"pageTitle":"Consul部署","url":"/docs/ai-arch/consul/consul-deploy#单节点部署运行","content":" ","version":"Next","tagName":"h2"},{"title":"源码安装​","type":1,"pageTitle":"Consul部署","url":"/docs/ai-arch/consul/consul-deploy#源码安装","content":" https://developer.hashicorp.com/consul/docs/install#compiling-from-source  首先执行，打包可执行文件。  export GOOS=linux GOARCH=amd64 make dev   两种方式启动consul server  快捷启动的方式  ./bin/consul agent -dev   指定参数启动服务  ./bin/consul agent -disable-host-node-id=true -bind=0.0.0.0 -client=0.0.0.0 -retry-join=${SERVER_NODE_LIST_FROM_DOMAIN[0]} -retry-join=${SERVER_NODE_LIST_FROM_DOMAIN[1]} -retry-join=${SERVER_NODE_LIST_FROM_DOMAIN[2]} -node=${HOST_NAME} -data-dir=/home/work/data/consul_${CLUSTER_NAME}_${DATA_CENTER_NAME}.d -datacenter=${DATA_CENTER_NAME} &gt; /home/work/log/feeds-consul/consul.stdout.log 2&gt;/home/work/log/feeds-consul/consul.stderr.log   -data-dir：数据目录 -datacenter：数据中心的名称 -bind：绑定ip  ","version":"Next","tagName":"h3"},{"title":"快捷启动​","type":1,"pageTitle":"Consul部署","url":"/docs/ai-arch/consul/consul-deploy#快捷启动","content":" ./bin/consul agent -dev  ","version":"Next","tagName":"h3"},{"title":"docker部署​","type":1,"pageTitle":"Consul部署","url":"/docs/ai-arch/consul/consul-deploy#docker部署","content":" ","version":"Next","tagName":"h2"},{"title":"Ppconsul 安装​","type":1,"pageTitle":"Consul部署","url":"/docs/ai-arch/consul/consul-deploy#ppconsul-安装","content":" github库：https://github.com/oliora/ppconsul?tab=readme-ov-file  cd ppconsul mkdir build &amp;&amp; cd build cmake .. make sudo make install   ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"Consul部署","url":"/docs/ai-arch/consul/consul-deploy#reference","content":" https://blog.csdn.net/weixin_50448879/article/details/136731875https://juejin.cn/post/7027839175793573918 ","version":"Next","tagName":"h2"},{"title":"ES搭建","type":0,"sectionRef":"#","url":"/docs/ai-arch/elasticsearch/es-deploy","content":"","keywords":"","version":"Next"},{"title":"本地单节点搭建(通过Docker)​","type":1,"pageTitle":"ES搭建","url":"/docs/ai-arch/elasticsearch/es-deploy#本地单节点搭建通过docker","content":" 简单的做法是，先安装好docker然后本地运行这个脚本。 github地址：https://github.com/elastic/start-local?tab=readme-ov-file#-try-elasticsearch-and-kibana-locally curl -fsSL https://elastic.co/start-local | sh  运行成功会生成如下信息：  🌐 Open your browser at http://localhost:5601 Username: elastic Password: FdSDFkf4 🔌 Elasticsearch API endpoint: http://localhost:9200 🔑 API key: dUJnWnI1SUJyT29jc0oxS3BET1E6Tk5lRXhqRDJRMXkwWWxUSXdiU201Zw==   ","version":"Next","tagName":"h2"},{"title":"本地节点搭建​","type":1,"pageTitle":"ES搭建","url":"/docs/ai-arch/elasticsearch/es-deploy#本地节点搭建","content":" ","version":"Next","tagName":"h2"},{"title":"elasticsearch安装​","type":1,"pageTitle":"ES搭建","url":"/docs/ai-arch/elasticsearch/es-deploy#elasticsearch安装","content":" 下载elasticsearch-8.15.2，修改config目录的elasticsearch.yml。 # 设置端口号： # 外网访问地址 network.host: 0.0.0.0 # 修改日志目录 path.logs: /home/teawork2/soft/es/elasticsearch-8.15.2/logs 使用-d后台启动./bin/elasticsearch -d如何启动启动报错，mmap内存配置不足，修改vm.max_map_count参数。 再次启动，启动成功。修改密码： ./bin/elasticsearch-reset-password -i -uelastic。访问localhost:9200访问成功。  ","version":"Next","tagName":"h3"},{"title":"kibana安装​","type":1,"pageTitle":"ES搭建","url":"/docs/ai-arch/elasticsearch/es-deploy#kibana安装","content":" 下载kibana-8.15.2。  重置kibana账号密码： ./bin/elasticsearch-reset-password -u kibana_system --auto 自动生成密码：gkNYDSc-Of3KnddXw5 修改config目录的kibana.yml。 server.port: 5601 server.host: &quot;0.0.0.0&quot; elasticsearch.hosts: [&quot;https://localhost:9200&quot;] elasticsearch.ssl.verificationMode: none elasticsearch.username: &quot;kibana_system&quot; elasticsearch.password: &quot;gkNYDSc-*Of3*KnddXw5&quot; 启动kibana./bin/kibana一键点亮。  ","version":"Next","tagName":"h3"},{"title":"源码构建​","type":1,"pageTitle":"ES搭建","url":"/docs/ai-arch/elasticsearch/es-deploy#源码构建","content":" 方法一：gradle 在elasticsearch的根目录执行：  ./gradlew run -Dxpack.security.enabled=true -Dxpack.security.authc.api_key.enabled=true   ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"ES搭建","url":"/docs/ai-arch/elasticsearch/es-deploy#reference","content":" 官方文档： https://www.elastic.co/guide/en/elasticsearch/reference/current/targz.html#install-macos本地docker安装： https://www.elastic.co/guide/en/elasticsearch/reference/current/run-elasticsearch-locally.html ","version":"Next","tagName":"h2"},{"title":"ES查询流程","type":0,"sectionRef":"#","url":"/docs/ai-arch/elasticsearch/es-search-phase","content":"","keywords":"","version":"Next"},{"title":"es集群查询流程​","type":1,"pageTitle":"ES查询流程","url":"/docs/ai-arch/elasticsearch/es-search-phase#es集群查询流程","content":"   ","version":"Next","tagName":"h2"},{"title":"search处理流程​","type":1,"pageTitle":"ES查询流程","url":"/docs/ai-arch/elasticsearch/es-search-phase#search处理流程","content":"   Get Remote Cluster Shard 判断是否需要集群访问Get Search Shard Iterator 获取要访问的shardFor Every Shard:Perform 判断shard情况，执行后面流程Send Request To Query Shard 将query阶段的查询发给shardmerge doc 合并策略是维护一个Top N大小的优先级队列，每当收到一个shard的返回，就把结果放入优先级队列做一次排序，直到所有的Shard都返回后做翻页逻辑。Send Request To Fetch Shard 执行fetch阶段  query阶段  Create Search ContextParse Query 解析queryGet From Cache 查询缓存Add Collectors 组装collector，collectors是收集查询结果，实现排序，对自定义结果集过滤和收集等lucene::search 执行lucene查询rescoresuggest::execute()aggregation::execute()  fetch阶段  通过docid获取完成的doc文档。 一般搜索系统都有query和fetch两阶段。  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"ES查询流程","url":"/docs/ai-arch/elasticsearch/es-search-phase#reference","content":" 读源码：https://blog.csdn.net/qq_42801937/article/details/140446384https://lanffy.github.io/2019/04/08/Elasticsearch-Compile-Source-And-Debughttps://www.itshujia.com/read/elasticsearch/368.html ","version":"Next","tagName":"h2"},{"title":"Consul能力下探和同类型中间件对比","type":0,"sectionRef":"#","url":"/docs/ai-arch/consul/consul-feature","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#简介","content":" 基于consul 1.5.1  上一篇我们部署完Consul。 但是究竟Consul有什么功能，我们能把它因应我们的业务技术架构做一个怎样的迭代， 还是未知数。 这一篇我们对Consul的能力进行罗列，并比对同类型中间件的能力。  单集群架构：  ","version":"Next","tagName":"h2"},{"title":"核心功能​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#核心功能","content":" ","version":"Next","tagName":"h2"},{"title":"文档代码​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#文档代码","content":" Consul的官方文档https://developer.hashicorp.com/consul/docs  我写的C++和Java的Demo，基于ppconsul和Spring cloud consul库。 https://github.com/teaho-infra/consul-demo  ","version":"Next","tagName":"h3"},{"title":"注册发现和销毁​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#注册发现和销毁","content":" 这是一个注册和销毁的例子。  agent.registerService( ppconsul::agent::kw::name = serviceId, ppconsul::agent::kw::address = &quot;127.0.0.1&quot;, ppconsul::agent::kw::id = serviceId, ppconsul::agent::kw::port = port, ppconsul::agent::kw::tags = {&quot;cpp-consul-demo&quot;, &quot;v1&quot;}, ppconsul::agent::kw::meta = {{&quot;meta1&quot;, &quot;cpp-consul-demo&quot;}}, ppconsul::agent::kw::check = ppconsul::agent::TcpCheck{ &quot;127.0.0.1:&quot; + std::to_string(port), std::chrono::seconds(10)} // 只做模拟操作，用的consul本身的地址 ); agent.deregisterService(serviceId);   consul支持设置service name和id，注册发现时候通过name去找service。同时能够配置一些标签和简单的元数据。 Consul提供多种健康检查（health check）机制。  Script check 脚本检查Http check 向指定地址发送http请求的检查Tcp check 向指定地址建立tcp连接检查Ttl check 被动等待client上传状态的检查……  服务发现 Consul client通过services API获取所有服务或者指定服务状态信息（c++的ppconsul不支持指定服务），完成注册发现。  auto services = std::make_shared&lt;std::map&lt;std::string, ppconsul::ServiceInfo&gt;&gt;(agent.services()); if (services) { std::cout &lt;&lt; &quot;Registered Services:&quot; &lt;&lt; std::endl; for (const auto&amp; service : *services) { std::cout &lt;&lt; &quot;Service ID: &quot; &lt;&lt; service.second.id &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Service Name: &quot; &lt;&lt; service.second.name &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Service Address: &quot; &lt;&lt; service.second.address &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Service Port: &quot; &lt;&lt; service.second.port &lt;&lt; std::endl; std::cout &lt;&lt; &quot;-------------------------&quot; &lt;&lt; std::endl; } } else { std::cerr &lt;&lt; &quot;Failed to retrieve services.&quot; &lt;&lt; std::endl; }   ","version":"Next","tagName":"h3"},{"title":"配置中心​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#配置中心","content":" Consul支持kv配置。一般可通过该项做到配置中心等能力。比如例子里，从指定路径（apps/kvMain::dev/configuration）获取YAML信息。  ppconsul::Consul consul(&quot;127.0.0.1:8500&quot;,ppconsul::kw::dc = &quot;dc1&quot;); // We need the 'kv' endpoint ppconsul::kv::Kv kv(consul); // Read the value of a key from the storage std::string configuration = kv.get(&quot;apps/kvMain::dev/configuration&quot;, &quot;default-value&quot;); // Erase a key from the storage kv.erase(&quot;apps/kvMain::dev/configuration2&quot;); // Set the value of a key kv.set(&quot;apps/kvMain::dev/configuration2&quot;, &quot;new-value&quot;);   ","version":"Next","tagName":"h3"},{"title":"Session​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#session","content":" Consul提供了一个叫做 Session的功能，我们可以创建并持有一个session，通过这个session去创建并抢占kv，或者监听kv变化，能够实现如分布式锁、集群选主等功能。 如下是一个分布式锁实现：   ppconsul::sessions::Sessions sessions(consul); ppconsul::kv::Kv kv(consul); // kw::groups::put, kw::name, kw::node, kw::lock_delay, kw::behavior, kw::ttl auto sessionId = sessions.create(name = checkId, ttl = std::chrono::seconds(600)); std::cout &lt;&lt; &quot;Session created!&quot; &lt;&lt; std::endl; // 获取当前时间 time_t now = time(0); char* dt = ctime(&amp;now); kv.lock(lockKey, sessionId, dt); getchar(); sessions.destroy(sessionId);   ","version":"Next","tagName":"h3"},{"title":"Acl​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#acl","content":" acl功能，可以允许我们调用consul server、proxy等增加基于access token、role等去控制节点访问。  ","version":"Next","tagName":"h3"},{"title":"Intention​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#intention","content":" 从文档和代码看出Consul在设计时就面向了ServiceMesh，有一些比较方便的能力（服务间的Intention等）。  ","version":"Next","tagName":"h3"},{"title":"同类型中间件对比​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#同类型中间件对比","content":" 我们列举下主流的注册中心中间件：  Consul , github stars: 28k，项目框架中使用Zookeeper, github stars: 12.3k，我司统一使用Etcd, github stars: 47k，作为K8s的kv数据库，间接使用频率高Nacos, github stars: 30k，较少使用Eureka, github stars: 12k，没有  我会选择目前工作中直接接触到：Consul、zookeeper、nacos 作对比。 对比将分为 三大类：  作为注册中心的关键能力：什么是关键能力？就是基于CAP原则考察一致性、存活检查能力、更新通知即时性、多语言或协议适配性。丰富的核心功能和适配能力：事务控制、kv能力、多数据中心。性能和安全性：能够存储多少数据、能够支持多少服务注册、是否支持服务流量安全传输和鉴权模型。  ​能力\tConsul\tZookeeper\tNacos\t备注CAP和一致性协议\tCP（raft协议）\tCP（Paxos协议）\tAP（Distro协议）+ CP(raft协议 用的JRaft实现) 存活检测\t支持自定义脚本、ttl、http、tcp端口检测\tClient tcp定期发送心跳包\tsdk集成，http定时心跳接口 更新通知即时性\t通过阻塞查询\t一次性watch机制，轻便设计\t数据发生更改，udp通知服务节点更新情况 通信协议\thttp/dns\ttcp\tHttp api\t三者常见语言都有sdk kv数据\t支持\t支持\t支持\t说明都具备一定的配置能力 事务控制\tkv+session机制，可以对某一kv键启动session并加锁\t通过临时节点+watch机制，对某一path加锁\t-\tnacos可参考去年glcc自实现https://github.com/alibaba/nacos/issues/10378 多数据中心管理\t支持\t支持，我司自实现\t支持 数据存储性能\tGB级数据存储\tGB级数据存储\tGB级数据存储\t数据取自网络，三者皆为分布式中间件，能随扩容承担更多流量。不同业务和服务属性所存储的数据量和使用功能不一而足，这两块性能最终根据服务属性优化为佳。 请求处理性能\t3节点万级tps\t3节点万级tps\t3节点万级tps\t同上 鉴权\tAcl\tAcl\tRBAC\t  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"Consul能力下探和同类型中间件对比","url":"/docs/ai-arch/consul/consul-feature#reference","content":" [1]Spring Cloud Consul文档|spring.io [2]Nacos分析 · Spring Learning|teaho.net [3]ZooKeeper doc [4]https://nacos.io/zh-cn/docs/nacos-config-benchmark.html [5]https://cloud.tencent.com/developer/article/1491107 ","version":"Next","tagName":"h2"},{"title":"ES向量搜索和Lucene执行原理","type":0,"sectionRef":"#","url":"/docs/ai-arch/elasticsearch/es-knn","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#简介","content":" 2019年Elasticsearch 7.0 版本发布，正式开始增加对向量字段的支持，字段类型新增了 dense_vector 类型。 2022年Elasticsearch发布8.0版本，增加knn_search接口和KNN搜索功能。 Elasticsearch 8.7版本后将该查询方式融入_search里，key为knn。  k近邻查找三要素：距离度量、k值的选择和分类决策规则。 在ES的knn搜索中，我们可以控制前两项。那么我们看一下ES向量检索有什么能力，以及它是怎么做的。  ","version":"Next","tagName":"h2"},{"title":"创建向量索引​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#创建向量索引","content":" 我们通过在ES索引中增加dense_vector类型字段，支持向量的存储和查询。  我们看下dense_vector字段的重要属性：  element_type：float（每维度4字节），byte（每维度1字节），bit（每维度1位，维数必须8的倍数）Dims 维度similarity 距离度量，默认为cosine，有这几个选项l2_norm、dot_product、cosine、max_inner_product。index_options.type 有几种选择：hnsw、int8_hnsw、int4_hnsw、bbq_hnsw、flat、int8_flat、int4_flat、bbq_flat。 分为hnsw(层次化可导航小世界)和flat（暴力查找）两种索引类型。int8相当于把向量每一维度压缩到1字节，int4压缩到半个字节，bbq压缩到1位精度。 index_options.m，HNSW 图中每个节点将连接到的邻居数量。默认16。index_options.ef_construction，组装每个新节点的近邻列表时要trace的候选者数量。  如下是一个创建ES向量字段的方式。  PUT test-vector-index { &quot;mappings&quot;: { &quot;properties&quot;: { &quot;content&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;embedding&quot;: { &quot;type&quot;: &quot;dense_vector&quot;, &quot;dims&quot;: 3, &quot;index&quot;: true, &quot;similarity&quot;: &quot;cosine&quot;, &quot;index_options&quot;: { &quot;type&quot;: &quot;int8_hnsw&quot;, &quot;m&quot;: 16, &quot;ef_construction&quot;: 100 } }, &quot;id&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } } } } }   ","version":"Next","tagName":"h2"},{"title":"执行搜索​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#执行搜索","content":" // 插入测试数据 POST test-vector-index/_bulk?refresh=true { &quot;index&quot;: { &quot;_id&quot;: &quot;1&quot; } } { &quot;embedding&quot;: [1, 5, -20], &quot;content&quot;: &quot;moose family&quot;, &quot;id&quot;: &quot;1&quot; } { &quot;index&quot;: { &quot;_id&quot;: &quot;2&quot; } } { &quot;embedding&quot;: [42, 8, -15], &quot;content&quot;: &quot;alpine lake&quot;, &quot;id&quot;: &quot;2&quot; } { &quot;index&quot;: { &quot;_id&quot;: &quot;3&quot; } } { &quot;embedding&quot;: [15, 11, 23], &quot;content&quot;: &quot;full moon&quot;, &quot;id&quot;: &quot;3&quot; }   es支持两种knn搜索方式：  使用knn选项，进行ANN近似近邻搜索。用带了向量函数的script_score查询，进行精确KNN查询。  ","version":"Next","tagName":"h2"},{"title":"knn选项查询​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#knn选项查询","content":" Elasticsearch在_search API的knn项中支持Approxiate knn搜索。 重要属性：  filter： 过滤匹配文档，语法同一般query.filter。k：topk，返回多少个近邻。num_candidates：每个分片的候选数。query_vector：查询向量。similarity: 距离度量的方法，l2_norm（欧几里德距离）、cosine余弦相似、dot_product点积、max_inner_product。 POST test-vector-index/_search { &quot;knn&quot;: { &quot;field&quot;: &quot;embedding&quot;, &quot;query_vector&quot;: [-5, 9, -12], &quot;k&quot;: 1, &quot;num_candidates&quot;: 100 } }   注：ES将knn搜索放在_search下，其实我们可以进行knn搜索同时通过query搜索去做交集搜索。  ","version":"Next","tagName":"h3"},{"title":"script_score进行精确查询​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#script_score进行精确查询","content":" https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-script-score-query.html#vector-functions   GET test-vector-index/_search { &quot;query&quot;: { &quot;script_score&quot;: { &quot;query&quot; : { &quot;match_all&quot;: {} }, &quot;script&quot;: { &quot;source&quot;: &quot;cosineSimilarity(params.query_vector, 'embedding') + 1.0&quot;, &quot;params&quot;: { &quot;query_vector&quot;: [4, 3.4, -0.2] } } } } }   ","version":"Next","tagName":"h3"},{"title":"能力总结​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#能力总结","content":" ES作为搜索引擎，密锣紧鼓的网罗了业界各类流行搜索能力。比如除了knn搜索能力，我发现ES还支持Time Serial的索引。 我们谈谈ES的Knn能力，首先在其公布的官博上。他们只支持HNSW相似搜索索引算法(层次化可导航小世界)和暴力搜索。  首先，HNSW在ANN-Benchmarks中展示了优秀的基准测试能力。HNSW在工业界广泛使用。  同时它，支持了一些调节参数，使我们可以在内存压缩、性能和相似度中做权衡。 但要说的是，8.0只支持HNSW和暴力精确搜索，我认为是有待加强的。因为LSH、IVF等都有其优势。  ","version":"Next","tagName":"h2"},{"title":"执行源码分析​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#执行源码分析","content":" ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"ES向量搜索和Lucene执行原理","url":"/docs/ai-arch/elasticsearch/es-knn#reference","content":" [1]dense-vector：https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html [2]knn-search：https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html [3]Introducing approximate nearest neighbor search in Elasticsearch 8.0 [4]HNSW论文：https://arxiv.org/abs/1603.09320 ","version":"Next","tagName":"h2"},{"title":"Java11特性分析","type":0,"sectionRef":"#","url":"/article/java11-feature","content":"","keywords":"java","version":null},{"title":"简介​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#简介","content":" 以下是Java11的特性清单：  181: Nest-Based Access Control（基于嵌套的访问控制）309: Dynamic Class-File Constants（动态的类文件常量）315: Improve Aarch64 Intrinsics（优化Aarch64内在函数）318: Epsilon: A No-Op Garbage Collector（一个无操作垃圾收集器）320: Remove the Java EE and CORBA Modules（移除Java EE和CORBA模块）321: HTTP Client (Standard) （HTTP Client API）323: Local-Variable Syntax for Lambda Parameters (lambda参数的局部变量语法)324: Key Agreement with Curve25519 and Curve448327: Unicode 10 (对unicode10的支持)328: Flight Recorder(飞行记录器)329: ChaCha20 and Poly1305 Cryptographic Algorithms330: Launch Single-File Source-Code Programs （运行单文件程序）331: Low-Overhead Heap Profiling332: Transport Layer Security (TLS) 1.3333: ZGC: A Scalable Low-Latency Garbage Collector (Experimental)335: Deprecate the Nashorn JavaScript Engine (弃用Nashron)336: Deprecate the Pack200 Tools and API  提出问题：  那些是日常会用到的？重点是？  代码及完整文件地址： https://github.com/teaho2015-blog/java11-feature-learning  ","version":null,"tagName":"h2"},{"title":"181: Nest-Based Access Control（基于嵌套的访问控制）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#181-nest-based-access-control基于嵌套的访问控制","content":" 我们先看一个例子：   public class JEP181 { public static class Nest1 { private int varNest1; public void f() throws Exception { final Nest2 nest2 = new Nest2(); //这里没问题 nest2.varNest2 = 2; final Field f2 = Nest2.class.getDeclaredField(&quot;varNest2&quot;); //这里在java8环境下会报错，在java11中是没问题的 f2.setInt(nest2, 2); System.out.println(nest2.varNest2); } } public static class Nest2 { private int varNest2; } public static void main(String[] args) throws Exception { new Nest1().f(); } }   该改动要解决的问题：  Java语言规范允许在同一个源文件中编写多个类。对于用户的角度来说，在同一个类文件里的class应该共享同样的访问控制体系。 为了达到目的，编译器需要经常需要通过附加的access bridge扩大private成员的访问权限到package。 这种bridge和封装相违背，并且轻微的增加程序的大小，会干扰用户和工具。 还有一个问题是反射与源码调用不一致。当使用java.lang.reflect.Method.invoke从一个nestmate调用另一个nestmate私有方法时会报IllegalAccessError错误。 这个是让人不能理解的，因为反射应该和源码级访问拥有相同权限。  现有情况： 现有的类文件格式定义了 InnerClasses 和 EnclosureMethod 属性（JVMS 4.7.6 和 4.7.7），以允许 Java 源代码编译器（如 javac）具体化源级嵌套关系。 每个嵌套类型都编译为它自己的类文件，不同的类文件通过这些属性的值“链接”。 虽然这些属性足以让 JVM 确定嵌套关系，但它们并不直接适用于访问控制，并且本质上与单个 Java 语言概念相关联。  ","version":null,"tagName":"h2"},{"title":"JVM对嵌套成员的访问控制改动​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#jvm对嵌套成员的访问控制改动","content":" 为了允许更广泛、更通用的嵌套概念，而不是简单的 Java 语言嵌套类型，并且为了有效的访问控制检查，建议修改类文件格式以定义两个新属性。 一个嵌套成员（通常是顶级类）被指定为嵌套主机，并包含一个属性 (NestMembers) 来标识其他静态已知的嵌套成员。 每个其他嵌套成员都有一个属性 (NestHost) 来标识其嵌套主机。  我们调整了JVM访问规则，增加了如下条目（to JVMS 5.4.4）： 一个field或method R可以被class或interface D访问，当且仅当如下任一条件为真：  ……R是私有的，并且声明在另一个class或interface C中，并且C和D是nestmates  ","version":null,"tagName":"h3"},{"title":"嵌套成员反射API​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#嵌套成员反射api","content":" 正因Java引入了新的类文件属性，那么惯常地Java会提供新的反射机制来检查或查询这些属性。  引入了三个方法java.lang.Class: getNestHost, getNestMembers, and isNestmateOf。  ","version":null,"tagName":"h3"},{"title":"309: Dynamic Class-File Constants（动态的类文件常量）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#309-dynamic-class-file-constants动态的类文件常量","content":" 扩展 Java 类文件格式以支持新的常量池形式 CONSTANT_Dynamic。 Loading a CONSTANT_Dynamic will delegate creation to a bootstrap method, just as linking an invokedynamic call site delegates linkage to a bootstrap method.  invokedynamic的协议设计者（例如 Java 8 中添加的 LambdaMetafactory）经常需要根据现有常量集对行为进行编码， 这反过来又需要在引导程序本身中进行额外的容易出错的验证和提取逻辑。 更丰富、更灵活、更高度类型化的常量消除了invokedynamic协议开发中的挣扎，并促进和简化了编译器逻辑。  CONSTANT_Dynamic还在发展，未来还有一些工作需要做。  ","version":null,"tagName":"h2"},{"title":"315: Improve Aarch64 Intrinsics（优化Aarch64内在函数）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#315-improve-aarch64-intrinsics优化aarch64内在函数","content":" 改进现有的字符串和数组内在函数，并在 AArch64 处理器上为 java.lang.Math 包下的 sin，cos 和 log 函数实现新的内在函数。  ","version":null,"tagName":"h2"},{"title":"318: Epsilon: A No-Op Garbage Collector（一个无操作垃圾收集器）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#318-epsilon-a-no-op-garbage-collector一个无操作垃圾收集器","content":" Epsilon是一个不收集垃圾的垃圾收集器，开启参数-XX:+UseEpsilonGC。 他的工作是在已分配内存的单个连续块中实现线性分配来工作。 System.gc()对Epsilon是不起作用的。  应用场景：  性能测试内存压力测试VM interface测试。寿命极短的工作Last-drop latency improvements（最后一滴延迟改进）Last-drop throughput improvements（最后一滴吞吐量改进）  ","version":null,"tagName":"h2"},{"title":"320: Remove the Java EE and CORBA Modules（移除Java EE和CORBA模块）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#320-remove-the-java-ee-and-corba-modules移除java-ee和corba模块","content":" 在Java se 9，如下Java EE和CORBA相关模块被标记为deprecated，在Java11如何模块被正式移除  java.xml.ws (JAX-WS, plus the related technologies SAAJ and Web Services Metadata)java.xml.bind (JAXB)java.activation (JAF)java.xml.ws.annotation (Common Annotations)java.corba (CORBA)java.transaction (JTA)  ","version":null,"tagName":"h2"},{"title":"移除原因​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#移除原因","content":" Java se 6包含了一个完整的Web Service技术栈，为Java开发者提供便利。不过随着发展：  这些技术块获得了和Java SE本身并不相关的特性。这些技术由上游java.net维护。由于必须将 OpenJDK 存储库中的 Java SE 版本与上游存储库中的 Java EE 版本同步，这使得维护存在问题。开发者可以从上游Java EE自行获取独立版本并通过Endorsed Standards Override Mechanism 部署它们。  ","version":null,"tagName":"h3"},{"title":"321: HTTP Client (Standard) （HTTP Client API）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#321-http-client-standard-http-client-api","content":" 该特性在Java9（jEP110）中是处于孵化状态，Java11正式标准化。  该特性支持HTTP/1.1和HTTP/2。  如下是Http client同步、异步、http2调用的简单demo。   /** * 同步调用 GET * @param uri * @throws Exception */ public static void syncGet(String uri) throws Exception { HttpClient client = HttpClient.newHttpClient(); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(uri)) .build(); HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString()); System.out.println(response.statusCode()); System.out.println(response.body()); } /** * 异步调用 GET * @param uri * @throws Exception */ public static void asyncGet(String uri) throws Exception { HttpClient client = HttpClient.newHttpClient(); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(uri)) .build(); CompletableFuture&lt;HttpResponse&lt;String&gt;&gt; responseCompletableFuture = client.sendAsync(request, HttpResponse.BodyHandlers.ofString()); responseCompletableFuture.whenComplete((resp, t) -&gt; { if (t != null) { t.printStackTrace(); } else { System.out.println(resp.body()); System.out.println(resp.statusCode()); } }).join(); } /** * 访问 HTTP2 网址 * @throws Exception */ public static void http2() throws Exception { HttpClient.newBuilder() .followRedirects(HttpClient.Redirect.NORMAL) .version(HttpClient.Version.HTTP_2) .build() .sendAsync(HttpRequest.newBuilder() .uri(new URI(&quot;https://http2.akamai.com/demo&quot;)) .GET() .build(), HttpResponse.BodyHandlers.ofString()) .whenComplete((resp, t) -&gt; { if (t != null) { t.printStackTrace(); } else { System.out.println(resp.body()); System.out.println(resp.statusCode()); } }).join(); }   ","version":null,"tagName":"h2"},{"title":"323: Local-Variable Syntax for Lambda Parameters (lambda参数的局部变量语法)​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#323-local-variable-syntax-for-lambda-parameters-lambda参数的局部变量语法","content":" 这是Java11唯一的语言改动。  这里搭配Java10的新特性JEP 286: Local-Variable Type Inference（局部变量类型推断）一起食用。  请看代码 java11目录-&gt;jep323.class 中的demo。  局部变量推断：使用指引|jdk.java.net  Java11增加了一点，允许在声明lambda表达式时在表达式的参数使用var。   (var x) -&gt; System.out.println(x);   作用是什么呢？ 为了统一并为了支持lambda参数使用注解  (@NotNull var x) -&gt; System.out.println(x); (@Number var x) -&gt; System.out.println(x);   ","version":null,"tagName":"h2"},{"title":"324: Key Agreement with Curve25519 and Curve448​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#324-key-agreement-with-curve25519-and-curve448","content":" 实现RFC 7748 [link]中所述，使用 Curve25519 和 Curve448 实现密钥协议。  这是一个密码学相关（ECDH密钥合意协议）的变更，更改是java.security包。  ","version":null,"tagName":"h2"},{"title":"327: Unicode 10 (对unicode10的支持)​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#327-unicode-10-对unicode10的支持","content":" Java11实现了9.0，增加了7500字符和六个脚本(Unicode文本集合)，实现了Unicode10因此增加了8518个字符和四个脚本（Unicode文本集合）。    ","version":null,"tagName":"h2"},{"title":"328: Flight Recorder(飞行记录器)​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#328-flight-recorder飞行记录器","content":" JDK Flight Recorder 是一个用于收集有关正在运行的 Java 应用程序的诊断和分析数据的系统。 它本身对运行期系统的侵入性很小，同时又能提供相对准确和丰富的运行期信息，以极低的性能开销集成到 Java 虚拟机 (JVM) 中，专为分析重负载的生产环境而设计。  在Java11前Flight Recorder和Java mission Control（JMC）都是商业产品，仅在Oracle JDK可用。那时候可以这样开启：  java -XX:+UnlockCommercialFeatures -XX:+FlightRecorder MyHelloWorldApp   现在，JFR在OpenJDK 11中是开源的，并且在OpenJDK11/bin文件夹中可用。  指标测量：  只有最多1%的性能损耗未启用时没有可衡量的性能开销  ","version":null,"tagName":"h2"},{"title":"功能使用​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#功能使用","content":" 相关模块：  jdk.jfr：相关APIjdk.management.jfr： for JMX管理  飞行记录器在Java11的启动方式： java -XX:StartFlightRecording ...或通过jcmd的JFR命令来按需产生profiling。  jmc分析jfr文件​    我们能够通过jcmd来生成.jfr文件，并通过JMC分析。 现在Java11不提供JMC了，可以自行安装：jmc release|java.net  自定义事件及分析​  我们可以通过API记录和消费自定义事件：  //继承并定义事件 @Label(&quot;Hello World&quot;) @Description(&quot;Helps the programmer getting started&quot;) class HelloWorld extends Event { @Label(&quot;Message&quot;) String message; } //提交事件 HelloWorld event = new HelloWorld(); event.message = &quot;hello, world!&quot;; event.commit(); //消费并输出 Path p = Paths.get(&quot;/home/teaho/IdeaProjects/java11-feature-learning/java11/recording.jfr&quot;); for (RecordedEvent e : RecordingFile.readAllEvents(p)) { try { System.out.println(e.getStartTime() + &quot; : &quot; + e.getValue(&quot;message&quot;)); } catch (Exception ex) { //do nothing } } &gt; 2021-08-31T08:29:38.948915253Z : hello, world!   ","version":null,"tagName":"h3"},{"title":"330: Launch Single-File Source-Code Programs （运行单文件程序）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#330-launch-single-file-source-code-programs-运行单文件程序","content":" 对于如下该代码，  public class Main { public static void main(String[] args) { System.out.println(&quot;hey yo! This is JEP 330 represented.&quot;); } }   以往我们需要如此执行该文件   javac Main.java java Main   现在如此即可执行：  btw,通过shebang执行：   #!/home/teaho/Env/jdk-11/bin/java --source 11 public class SheBang { public static void main(String[] args) { System.out.println(&quot;hey yo! This is JEP 330 represented.&quot;); } }   ","version":null,"tagName":"h2"},{"title":"329: ChaCha20 and Poly1305 Cryptographic Algorithms​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#329-chacha20-and-poly1305-cryptographic-algorithms","content":" Java 11 提供了 ChaCha20 和 ChaCha20-Poly1305 加密实现。  ","version":null,"tagName":"h2"},{"title":"331: Low-Overhead Heap Profiling（低开销的堆profiling）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#331-low-overhead-heap-profiling低开销的堆profiling","content":" 提供一种低开销的Java堆分配采样(Profiling)方式，可通过JVMTI(Java Tool Interface)访问。  用户非常需要了解其堆的内容。所以有很多工具被开发出来，比如JFR，jmap，VisualVM Tool。 但大多数现有工具都缺少的一种信息是对于特定或指定内存分配的调用路径（call site）。堆dump是没有携带这一类信息的。 这种信息对于开发者来说有为重要，尤其是在定位在一个糟糕的分配在代码中的指定位置。  现在我们可以这样获取到这些信息：  您可以使用字节码重写器（例如 Allocation Instrumenter|github ）来检测应用程序中的所有分配。通过Java飞行收集器。  ","version":null,"tagName":"h2"},{"title":"333: ZGC: A Scalable Low-Latency Garbage Collector (Experimental)​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#333-zgc-a-scalable-low-latency-garbage-collector-experimental","content":" 万众期待的ZGC出来了～当然目前是实验性特性，Java15才最终为生产就绪。  ZGC是一个低延迟可拓展垃圾收集器。  设计目标：  GC暂停时间不超过10ms处理从相对较小（几百兆字节）到非常大（许多 TB）(8mb~16TB)的堆与使用 G1 相比，应用程序吞吐量降低不超过 15%利用colored pointers和load barriers为未来的 GC 功能和优化奠定基础  咋一看，ZGC是一个并发、单代、基于区域（region-base）、NUMA感知的压缩收集器。STW仅限于跟扫描， 因此GC暂停时间不会随着堆或live set的大小而增加。  ","version":null,"tagName":"h2"},{"title":"功能使用​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#功能使用-1","content":" 通过如下JVM参数启用：  -XX:+UnlockExperimentalVMOptions -XX:+UseZGC   ","version":null,"tagName":"h3"},{"title":"性能表现​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#性能表现","content":" 这是JDK项目组使用SPECjbb® 2015做的性能测试，用的128G堆。  第一个是吞吐量测试数据，max jops为纯吞吐量量，critical jops为限制响应时间下的吞吐量量。  ZGC max-jOPS: 100% critical-jOPS: 76.1%G1 max-jOPS: 91.2% critical-jOPS: 54.7%  下面是延时测试  ZGC avg: 1.091ms (+/-0.215ms) 95th percentile: 1.380ms 99th percentile: 1.512ms 99.9th percentile: 1.663ms 99.99th percentile: 1.681ms max: 1.681msG1 avg: 156.806ms (+/-71.126ms) 95th percentile: 316.672ms 99th percentile: 428.095ms 99.9th percentile: 543.846ms 99.99th percentile: 543.846ms max: 543.846ms  ","version":null,"tagName":"h3"},{"title":"缺点（局限性）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#缺点局限性","content":" 目前ZGC为实验版本，该版本不支持类卸载。不支持JVMCI（Java-Level JVM Compiler Interface）  这些将在后续版本的开发中支持。  ","version":null,"tagName":"h3"},{"title":"运行原理​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#运行原理","content":"   ZGC只有三个STW阶段：初始标记，再标记，初始转移。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短； 再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。 与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。  解决转移期间对象访问的两个核心技术：  着色指针 对于 64bit 的系统，高位 bit 中拿出 4 个 bit 来指示不同的处理状态，两个 Mark 位表明该对象指针是否已经被标记，采用两个 Mark bit 可以在前后不同的 GC 时使用不同的 Mark bit； Remapped 位表示当前对象指针是否已经调整为搬移之后的对象指针；Finalizable 位主要是为 Finalizable 对象服务，用来表示该对象指针是否仅经 Finalize 对象标记，主要供 Mark 阶段和弱引用处理阶段使用。读屏障 读屏障是JVM向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。需要注意的是，仅“从堆中读取对象引用”才会触发这段代码。  Object o = obj.FieldA // 从堆中读取引用，需要加入屏障 &lt;Load barrier&gt; Object p = o // 无需加入屏障，因为不是从堆中读取引用   ","version":null,"tagName":"h3"},{"title":"配置参数​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#配置参数","content":" 重要参数配置样例： -Xms10G -Xmx10G -XX:ReservedCodeCacheSize=256m -XX:InitialCodeCacheSize=256m -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:ConcGCThreads=2 -XX:ParallelGCThreads=6 -XX:ZCollectionInterval=120 -XX:ZAllocationSpikeTolerance=5 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive -Xlog:safepoint,classhisto*=trace,age*,gc*=info:file=/opt/logs/logs/gc-%t.log:time,tid,tags:filecount=5,filesize=50m   -Xms -Xmx：堆的最大内存和最小内存，这里都设置为10G，程序的堆内存将保持10G不变。-XX:ReservedCodeCacheSize -XX:InitialCodeCacheSize：设置CodeCache的大小， JIT编译的代码都放在CodeCache中，一般服务64m或128m就已经足够。-XX:+UnlockExperimentalVMOptions -XX:+UseZGC：启用ZGC的配置。-XX:ConcGCThreads：并发回收垃圾的线程。默认是总核数的12.5%，8核CPU默认是1。调大后GC变快，但会占用程序运行时的CPU资源，吞吐会受到影响。-XX:ParallelGCThreads：STW阶段使用线程数，默认是总核数的60%。-XX:ZCollectionInterval：ZGC发生的最小时间间隔，单位秒。-XX:ZAllocationSpikeTolerance：ZGC触发自适应算法的修正系数，默认2，数值越大，越早的触发ZGC。-XX:+UnlockDiagnosticVMOptions -XX:-ZProactive：是否启用主动回收，默认开启，这里的配置表示关闭。-Xlog：设置GC日志中的内容、格式、位置以及每个日志的大小。  ","version":null,"tagName":"h3"},{"title":"332: Transport Layer Security (TLS) 1.3​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#332-transport-layer-security-tls-13","content":" 实现传输层安全 (TLS) 协议 RFC 8446 的 1.3 版。  ","version":null,"tagName":"h2"},{"title":"335: Deprecate the Nashorn JavaScript Engine​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#335-deprecate-the-nashorn-javascript-engine","content":" Nashorn是Java引入的JavaScript引擎。 由于ECMAScript的语言结构和APi快速发展，使得该引擎难以维护。  ","version":null,"tagName":"h2"},{"title":"336: Deprecate the Pack200 Tools and API​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#336-deprecate-the-pack200-tools-and-api","content":" 一个打包压缩工具，因为各种历史原因和发展原因弃用。  ","version":null,"tagName":"h2"},{"title":"API变更​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#api变更","content":" Java11的API弃用和移除清单可以在这里看到:API removed|Java SE 11 Final Release Spec  Java11的API变动（更改、增加、删除）：Diff between Java 10 and Java11 API|Java.net  下面看看一些常用更改。  ","version":null,"tagName":"h2"},{"title":"java.lang.String​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#javalangstring","content":"  /** * for java.lang.String */ @Test public void testStringNewAPI() { assertThat(&quot;&quot;.isBlank(), equalTo(true)); assertThat(&quot; &quot;.isBlank(), equalTo(true)); assertThat(&quot;11&quot;.isBlank(), equalTo(false)); assertThat((&quot;abc\\n&quot; + &quot;abc\\n&quot;) .lines() .count(), equalTo(2L)); assertThat(&quot;abc&quot;.repeat(2), equalTo(&quot;abcabc&quot;)); assertThat(&quot; a b c &quot;.strip(), equalTo(&quot;a b c&quot;)); assertThat(&quot; a b c &quot;.stripLeading(), equalTo(&quot;a b c &quot;)); assertThat(&quot; a b c &quot;.stripTrailing(), equalTo(&quot; a b c&quot;)); }   ","version":null,"tagName":"h3"},{"title":"简单的文件读取​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#简单的文件读取","content":"  @Test public void testFilesIOString() throws IOException { String content = &quot;Hey this is tmp file!&quot;; Path path = Files.writeString(Files.createTempFile(&quot;tmp&quot; + LocalTime.now(), &quot;.txt&quot;), content); String fileContent = Files.readString(path); assertThat(&quot;Str not eq!&quot;, fileContent, equalTo(content)); }   ","version":null,"tagName":"h3"},{"title":"JAVA10同场加映​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#java10同场加映","content":" 286: Local-Variable Type Inference（本地变量类型推断）  ","version":null,"tagName":"h2"},{"title":"286: Local-Variable Type Inference（本地变量类型推断）​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#286-local-variable-type-inference本地变量类型推断","content":" 在上面JEP323一节已对该特性做了陈述。  ","version":null,"tagName":"h3"},{"title":"API变更​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#api变更-1","content":"  /** * java.util.List、java.util.Map 和 java.util.Set 都有了一个新的静态方法 copyOf(Collection)。 * * copyOf */ @Test public void testCopyOf() { { var list = new ArrayList&lt;Item&gt;(); list.add(new Item(1)); list.add(new Item(2)); var copyList = List.copyOf(list); assertThat(copyList.get(0), equalTo(list.get(0))); assertThat(copyList.get(1), equalTo(list.get(1))); assertThat(Utils.exceptionOf(() -&gt; copyList.add(new Item(3))), instanceOf(UnsupportedOperationException.class)); } { var list = new ArrayList&lt;Item&gt;(); list.add(new Item(1)); list.add(new Item(2)); List copyList = List.copyOf(list); assertThat(copyList.get(0), equalTo(list.get(0))); assertThat(copyList.get(1), equalTo(list.get(1))); } { var map = Map.of(new Item(1), 1, new Item(2), 2, new Item(3), 3); var copyMap = Map.copyOf(map); assertThat(map.equals(copyMap), equalTo(true)); assertThat(Utils.exceptionOf(()-&gt; copyMap.put(new Item(Integer.MAX_VALUE), Integer.MAX_VALUE)), instanceOf(UnsupportedOperationException.class)); } { var set = Set.of(new Item(1), new Item(2), new Item(3)); var copySet = Set.copyOf(set); assertThat(set.equals(copySet), equalTo(true)); assertThat(Utils.exceptionOf(()-&gt; copySet.add(new Item(4))), instanceOf(UnsupportedOperationException.class)); } } /** * Collectors加了一个转换为不可变列表的API * * stream toUnmodifiableList */ @Test(expected = UnsupportedOperationException.class) public void whenModifyToUnmodifiableList_thenThrowsException() { List&lt;Integer&gt; list = Stream.of(1, 2, 3) .filter(i -&gt; i % 2 == 0) .collect(Collectors.toUnmodifiableList()); } /** * optional 增加了 空的orElseThrow 方法 */ @Test public void testOptional_orElseThrow() { Optional.of(1).orElseThrow(); assertThat(Utils.exceptionOf(() -&gt; Optional.empty().orElseThrow()), instanceOf(NoSuchElementException.class)); }   ","version":null,"tagName":"h3"},{"title":"JAVA9同场加映(未完成)​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#java9同场加映未完成","content":" 222: jshell: The Java Shell (Read-Eval-Print Loop)261: Module System(模块系统)  ","version":null,"tagName":"h2"},{"title":"222: jshell: The Java Shell (Read-Eval-Print Loop)​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#222-jshell-the-java-shell-read-eval-print-loop","content":" Java9提供交互式工具来评估使用Java编程语言的声明、语句和表达式， 以及提供了JShell API以便其他应用程序可以利用此功能。  JShell Tutorial jshell|Java Platform, Standard Edition Tools Reference  一般使用​   jshell&gt; /list 2 : a instanceof java.lang.String 3 : a instanceof java.lang.String 5 : String getStr() { return &quot;abc&quot;; } 6 : String a = &quot;abc&quot;; jshell&gt; /imports | import java.io.* | import java.math.* | import java.net.* | import java.nio.file.* | import java.util.* | import java.util.concurrent.* | import java.util.function.* | import java.util.prefs.* | import java.util.regex.* | import java.util.stream.* jshell&gt; /vars | boolean $2 = true | boolean $3 = true | String a = &quot;abc&quot; jshell&gt; String getStr() { ...&gt; return &quot;a&quot;; ...&gt; } | 已修改 方法 getStr() jshell&gt; System.out.println(getStr()); a   API使用​  JShell shell = JShell.create(); shell.onShutdown(jShell -&gt; System.out.println(&quot;bye bye&quot;)); BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); while (true) { System.out.print(&quot;\\n&gt; &quot;); try { String cmd = reader.readLine(); List&lt;SnippetEvent&gt; results = shell.eval(cmd); for (SnippetEvent e : results) { if (!e.status().isActive() &amp;&amp; !e.status().isDefined()) { shell.diagnostics(e.snippet()).forEach(diag -&gt; System.out.println(diag.getMessage(Locale.CHINA))); System.out.println(e.status()); } else if (e.exception() != null) { System.out.println(&quot;&lt; &quot; + e.exception()); } else { System.out.println(e.value()); } } } catch (IOException e) { e.printStackTrace(); } }   输出：   &gt; String s = &quot;abc&quot;; &quot;abc&quot; &gt; var a = &quot;a&quot;; 找不到符号 符号: 类 var 位置: 类 REJECTED &gt; System.out.println(s); abc   ","version":null,"tagName":"h3"},{"title":"其他变更​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#其他变更","content":" Flow API​  以前有写过一篇Project Reactor的原理剖析[24]，原理上二者是相通的。  ","version":null,"tagName":"h3"},{"title":"reference​","type":1,"pageTitle":"Java11特性分析","url":"/article/java11-feature#reference","content":" [1]JDK 11|java.net [2]【是时候升级java11了】 jdk11优势和jdk选择 [3]JAVA11到底有多强，不看你就out了|zhihu [4]unicode10|unicode.org [5]Proposed Update Unicode® Technical Standard #51 [6]Script(Unicode)|wikipedia [7]Java11版本特性详解 [8]JDK 11 Documentation|oracle [9]Java9版本特性详解 [10]java11新特性---Nest-Based Access Control(嵌套访问控制)|宋兵甲 [11]JDK11 - Introduction to JDK Flight Recorder|Java Community and Oracle|youtube [12]ZGC: The Next Generation Low-Latency Garbage Collector|Java Community and Oracle|youtube [13]JVMTI 参考|javase8 jvmti文档翻译 [14]JVMTM Tool Interface|oracle [15]新一代垃圾回收器ZGC的探索与实践|美团技术团队 [16]The Design of ZGC|Per Lidén (@perliden)Consulting Member of Technical Staff,Java Platform Group, Oracle [17]openjdk wiki [18]ZGC-OracleDevLive-2020.pdf|Java Platform Group [19]Tencent Kona JDK11 无暂停内存管理 -ZGC 生产实践|InfoQ [20]JDK 9|java.net [21]Java 9 新特性之核心库（上）|darian1996 [22]Java9 模块化|darian1996 [23]The Java® Language Specification|Java SE 9 Edition [24]Project Reactor原理|teaho.net  其他参考：  真棒：使用Java 11实现应用的模块化|banq 本文将帮助你如何将应用程序从Java 8迁移到java11（纯干货分享）|程序猿阿洐 JDK8升级JDK11过程记录|cdmana.com ","version":null,"tagName":"h2"},{"title":"通过Llama和Dify搭建一套RAG","type":0,"sectionRef":"#","url":"/docs/ai-arch/llm/dify-rag","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#简介","content":" 尝试用开箱即用的两个工具，Ollama和Dify搭建一个知识库。  ","version":"Next","tagName":"h2"},{"title":"Ollama搭建​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#ollama搭建","content":" https://ollama.com/download 安装完成后，运行大模型。Ollama很方便，命令类似Docker。 我这里使用llama 3.2 3B  ollama run llama3.2   运行成功，可以对话：  ","version":"Next","tagName":"h2"},{"title":"Dify搭建​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#dify搭建","content":" 下载 https://github.com/langgenius/dify 代码。  执行命令  cd dify cd docker cp .env.example .env docker compose up -d   执行成功，可以打开界面。接入llama 3.2模型  ","version":"Next","tagName":"h2"},{"title":"创建RAG对话​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#创建rag对话","content":" ","version":"Next","tagName":"h2"},{"title":"创建知识库​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#创建知识库","content":" 首先基于文档创建知识库，  上传文档 配置分段方式和embedding模型，还有混合查询模式。  ","version":"Next","tagName":"h3"},{"title":"创建Dify的聊天应用​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#创建dify的聊天应用","content":" 增加context，  链接上已经执行完分段和向量化的知识库。（可选，链接上rerank模型）增加前置prompt。  ","version":"Next","tagName":"h3"},{"title":"运行​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#运行","content":"   大功告成！  ","version":"Next","tagName":"h3"},{"title":"Reference​","type":1,"pageTitle":"通过Llama和Dify搭建一套RAG","url":"/docs/ai-arch/llm/dify-rag#reference","content":" [1]Ollama https://ollama.com/ [2]在应用内集成知识库https://docs.dify.ai/zh-hans/guides/knowledge-base/integrate-knowledge-within-application ","version":"Next","tagName":"h2"},{"title":"了解GPU","type":0,"sectionRef":"#","url":"/docs/ai-arch/head-first-gpu","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#简介","content":" 本文更关注Nivida GPU做讨论。  ","version":"Next","tagName":"h2"},{"title":"GPU的历史​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#gpu的历史","content":" 说说历史，从历史看，不仅知道GPU的前世今生，还能看到有哪些组件有历史的影子。  ​时间\t事件\t​影响1999\tNVIDIA GeForce 256（首款GPU）\t定义GPU概念，硬件T&amp;L加速 2006\tCUDA发布\tGPU通用计算时代开启 2012\tGPU加速AlexNet训练\t推动深度学习革命 2018\tNVIDIA RTX 20系列（光追）\t游戏画质进入实时光追时代 2022\tChatGPT引爆AI需求\tGPU成为AI基础设施核心  上面是GPU关键里程碑，我会在下面章节说说发展，可自行对应这些里程碑看分别革新了哪些流程。  ","version":"Next","tagName":"h2"},{"title":"从图形流水线看GPU发展​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#从图形流水线看gpu发展","content":" ","version":"Next","tagName":"h2"},{"title":"红白机PPU​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#红白机ppu","content":" 最初级的图像处理单元，只能将一张图的所有像素做一个处理，这就是任天堂红白机的PPU的结构。  ","version":"Next","tagName":"h3"},{"title":"首款GPU​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#首款gpu","content":" 1999年8月Nvidia推出的GeoForce256，是第一款问世的GPU。我们从它的结构能了解2000s年代的图形流水线。  ","version":"Next","tagName":"h3"},{"title":"现今图形流水线雏形和GPGPU​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#现今图形流水线雏形和gpgpu","content":"   随着GPU的强大计算能力逐步被带到市面（举例现在RTX4090是16384个CUDA core），研发和科研人员就像能否把GPU的计算能力使用在非图形计算上呢？还真有人琢磨出来了：通过Compute Shader去做并行计算。这是一条和图形流水线不相干的路线，整个流水线只有计算Shader。（也衍生出只有计算流水线的GPU）  这里说到计算流水线，GPU在后来的发展会有一些相互独立的流水线：  图形流水线计算光线追踪视频解码  ","version":"Next","tagName":"h3"},{"title":"硬软件层看CUDA​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#硬软件层看cuda","content":" ","version":"Next","tagName":"h2"},{"title":"CPU和GPU​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#cpu和gpu","content":" 在CUDA C++ Programming Guide里有这样一张图，我用这张图来说说CPU和GPU为什么不一样    简单来说，Nvidia这张图展示了两种处理单元的芯片资源分配差异。  CPU每个core分配控制器CPU有更多级缓存  这些差异，是为了这些功能特性开路：  CPU擅长在小数据量的复杂运算，GPU擅长大数据量下的简单计算 正如CUDA guice里说的，将更多的晶体管用于数据处理，有利于高度并行计算。具有高并行度的应用程序可以利用 GPU 的这种大规模并行特性来实现比 CPU 更高的性能。  ","version":"Next","tagName":"h3"},{"title":"CUDA调用链​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#cuda调用链","content":" CUDA是跨平台兼容，但不是开放接口（跨平台不跨厂商）。 调用链：APP -&gt; CUDA API -&gt; CUDA Runtime -&gt; 硬件  ","version":"Next","tagName":"h3"},{"title":"CUDA的SIMT架构​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#cuda的simt架构","content":" 从上图中可以看到 CUDA GPU 有许许多多的 SM 组成，SM 全称为 Streaming Multiprocessor 流式多处理器，是 NVIDIA GPU 架构中的重要组成部分，也是 GPU 的基本计算单元。每个 SM 由多个 CUDA 核心、纹理单元、Tensor Core、流控制器和存储器等辅助单元组成，可以同时执行多个计算任务，并具有高度的灵活性和性能。 多处理器以 32 个并行线程（称为 warp）为一组创建、管理、调度和执行线程。 当一个多处理器被赋予一个或多个线程block来执行时，它会将它们划分为 warp（CUDA软件术语），每个 warp 都由warp调度器调度执行。 在warp的整个生命周期，由multiprocessor处理的每个 warp 的执行上下文（程序计数器、寄存器等）都保留在芯片上。因此执行上下文的切换没有成本。 每个Multiprocessor有最大常驻block数和最大常驻warp数限制。  ","version":"Next","tagName":"h3"},{"title":"写个CUDA Hello world程序​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#写个cuda-hello-world程序","content":" 程序结构： CUDA 程序一般使用 .cu 后缀，编译 CUDA 程序则使用nvcc编译器。一般而言，一个CUDA程序的结构如下：  int main() { 主机代码; 核函数调用; 主机代码; 核函数调用; ...... return 0; } __global__ void 核函数1(parameters) { ...... } __global__ void 核函数2(parameters) { ...... }   来个Helloworld  找元宝拉了个helloworld，自己手敲下  #include &lt;stdio.h&gt; // GPU 内核函数：每个线程打印 &quot;Hello World from GPU!&quot; __global__ void helloFromGPU() { printf(&quot;Hello World from GPU! (Thread %d)\\n&quot;, threadIdx.x); } int main() { // 调用 GPU 内核：启动 1 个 Block，包含 5 个线程 helloFromGPU&lt;&lt;&lt;1, 5&gt;&gt;&gt;(); // 等待 GPU 执行完成（同步） cudaError_t cudaerr = cudaDeviceSynchronize(); if (cudaerr != cudaSuccess) printf(&quot;kernel launch failed with error \\&quot;%s\\&quot;.\\n&quot;, cudaGetErrorString(cudaerr)); // 主机端打印 printf(&quot;Hello World from CPU!\\n&quot;); return 0; }   编译和运行：  nvcc hellow.cu -o hellow ./hellow   运行输出：  ","version":"Next","tagName":"h2"},{"title":"附录​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#附录","content":" Geoforce256 vs RTX 4090  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"了解GPU","url":"/docs/ai-arch/head-first-gpu#reference","content":" [1]龚敏敏-从上帝视角看GPU [2]zhihu|浅谈 NES 图像技术 [3]youtube|Understanding NVIDIA GPU Hardware as a CUDA C Programmer | Episode 2: GPU Compute Architecture [4]https://zhuanlan.zhihu.com/p/680075822 [5]CUDA C++ Programming Guide: https://docs.nvidia.com/cuda/cuda-c-programming-guide/ [6]https://zhuanlan.zhihu.com/p/394352476 [7]https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/ [8]Nvidia|What Is The Relation Between Warp And SM Processing Block? ","version":"Next","tagName":"h3"},{"title":"LLM","type":0,"sectionRef":"#","url":"/docs/ai-arch/llm","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"LLM","url":"/docs/ai-arch/llm#简介","content":" agi知识库： AGI掘金知识库：https://agijuejin.feishu.cn/wiki/UvJPwhfkiitMzhkhEfycUnS9nAmwaytoAGI：https://www.waytoagi.com/zhAI工具榜单https://www.toolify.ai/zh/  数字人：https://developer.aliyun.com/article/1637714  AI动画制作流程：阿里云部署flux https://developer.aliyun.com/article/1598625 ","version":"Next","tagName":"h2"},{"title":"introduction","type":0,"sectionRef":"#","url":"/docs/introduction","content":"introduction","keywords":"","version":"Next"},{"title":"巴别塔之旅","type":0,"sectionRef":"#","url":"/docs/babel","content":"巴别塔之旅 在土星上飞了一圈回来的开始学习和别人沟通。","keywords":"","version":"Next"},{"title":"容器和Kubernetes","type":0,"sectionRef":"#","url":"/docs/k8s","content":"容器和Kubernetes 近段时间，写一些k8s的总结，温故以往了解的知识并分享。","keywords":"","version":"Next"},{"title":"ChatGLM3-6b微调","type":0,"sectionRef":"#","url":"/docs/ai-arch/llm/chatglm-tuning","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#简介","content":" 略。  ","version":"Next","tagName":"h2"},{"title":"运行ChatGLM-6B​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#运行chatglm-6b","content":" 首先，我们需要熟悉先跑起来。  ","version":"Next","tagName":"h2"},{"title":"命令行​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#命令行","content":" 准备有13G显存以上机器。将github代码下载到机器上，并用python3(&gt;=3.9)安装好依赖。 git clone https://github.com/THUDM/ChatGLM3 pip install -r requirements.txt 我是本地加载模型 确保git安装了git lfs，不然模型文件下载不全。（这里睬了坑）从huggingface下载模型git clone https://huggingface.co/THUDM/chatglm3-6b 修改basic_demo/cli_demo.py下的MODEL_PATH，为第3步下载模型的文件夹，比如 xxx/xxx/model/python3 cli_demo.py运行    ","version":"Next","tagName":"h3"},{"title":"运行composite web demo​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#运行composite-web-demo","content":" https://github.com/THUDM/ChatGLM3/tree/main/composite_demo  安装依赖cd composite_demo &amp; pip install -r requirements.txt执行export MODEL_PATH=../model执行python -m streamlit run main.py，启动浏览器打开页面  截至2024.12.27拉的代码会报这个错误ModuleNotFoundError: No module named 'huggingface_hub.inference._text_generation，需要将huggingface_hub包降级版本 huggingface_hub==0.21.0 。  再次运行成功。这个composite demo能够调整token length、top_p（采样策略）、temperature（调整单词概率分布）。也能体验对话、代码提示能力等。  智谱AI的参数推荐  Use Case\ttemperature\ttop_p\t任务描述代码生成\t0.2\t0.1\t生成符合既定模式和惯例的代码。 输出更确定、更集中。有助于生成语法正确的代码 创意写作\t0.7\t0.8\t生成具有创造性和多样性的文本，用于讲故事。输出更具探索性，受模式限制较少。 聊天机器人回复\t0.5\t0.5\t生成兼顾一致性和多样性的对话回复。输出更自然、更吸引人。 调用工具并根据工具的内容回复\t0.0\t0.7\t根据提供的内容，简洁回复用户的问题。 代码注释生成\t0.1\t0.2\t生成的代码注释更简洁、更相关。输出更具有确定性，更符合惯例。 数据分析脚本\t0.2\t0.1\t生成的数据分析脚本更有可能正确、高效。输出更确定，重点更突出。 探索性代码编写\t0.6\t0.7\t生成的代码可探索其他解决方案和创造性方法。输出较少受到既定模式的限制。  ","version":"Next","tagName":"h3"},{"title":"微调的方式​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#微调的方式","content":" 列举一些常见微调方式：  全参数微调 可以针对特定任务和数据进行优化，但需要大量计算资源。PEFT，参数高效微调 LoRA 通过低秩适应显著减少了需要微调的参数数量，有时候不如全量微调。Prefix Tuning 和 Prompt Tuning 资源需求低（只修改少量参数），在某些任务效果不如其他微调方式。 RLHF  ","version":"Next","tagName":"h2"},{"title":"微调实录​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#微调实录","content":" 我希望使用LoRA微调一个法律法规的大模型。  ChatGLM在官方代码库里有一个finetune_demo文件夹，里面有lora.yaml配置。基于这个我们来微调一下。 注：我这里使用官方代码里的微调demo来做，也可使用一些业界主流微调框架LLama Factoryhttps://github.com/hiyouga/LLaMA-Factory来微调。  执行pip3 install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple 会报错：  note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for mpi4py Failed to build mpi4py ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (mpi4py)   安装系统依赖：  yum install openmpi-devel export CC=/usr/lib64/openmpi/bin/mpicc pip install mpi4py   调整lora.yaml参数： 将微调的训练数据和验证数据数据按格式放置在data目录的train.json和test.json中。修改lora.yaml的train_file、val_file和test_file。  执行微调：  CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=&quot;1&quot; NCCL_IB_DISABLE=&quot;1&quot; python3 finetune_hf.py data ../model configs/lora.yaml   初次执行报没有nltk包。  Traceback (most recent call last): File &quot;/home/work/hetingleong/ChatGLM3/finetune_demo/finetune_hf.py&quot;, line 14, in &lt;module&gt; from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu ModuleNotFoundError: No module named 'nltk' pip3 install nltk   再次执行报错：  ImportError: cannot import name 'EncoderDecoderCache' from 'transformers'，按照stackoverflow和github，继续安装peft包。 pip install peft==0.10.0 pip install transformers=4.40.2     参数含义：  loss 损失值。grad_norm 梯度范数。关注梯度爆炸和梯度消失问题。learning_rate 学习率，学习率展示了反向传播时参数更新步长大小。epoch 周期 每个 epoch 后，通常会评估模型在验证集上的表现，以监控和调整训练过程。  完成微调。  运行微调后模型：  python3 inference_hf.py output/checkpoint-3000/ --prompt &quot;第二百六十六条刑法，金额九万多，四个人平分，但金额全部退回，还得 到对方谅解，像这类情节严重吗&quot;   微调前：  用户：第二百六十六条刑法，金额九万多，四个人平分，但金额全部退回，还得 到对方谅解，像这类情节严重吗 ChatGLM：根据我国刑法第二百六十六条规定，盗窃数额较大或者有其他严重情节的，处三年以下有期徒刑、拘役或者管制，并处或者单处罚金；数额巨大或者有其他特别严重情节的，处三年以上七年以下有期徒刑，并处罚金。 您描述的情况，四个人平分九万多元的盗窃金额，虽然最终金额全部退回并得到对方谅解，但这种行为仍然构成盗窃罪。具体情节是否严重，需要根据具体情况和法院审理结果来判断。如果他们能够积极认错并采取措施挽回损失，可能会得到从轻或者减轻处罚。请他们尽快向有关部门自首，并积极采取措施挽回损失。   微调后：  python3 inference_hf.py output/checkpoint-3000/ --prompt &quot;第二百六十六条刑法，金额九万多，四个人平分，但金额全部退回，还得 到对方谅解，像这类情节严重吗&quot; Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04&lt;00:00, 1.65it/s] 只要金额达到三万以上，就属于数额巨大了。   微调有一定效果，但是实际工作需要再根据实际业务调优训练轮次、微调数据集、效果比对。  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"ChatGLM3-6b微调","url":"/docs/ai-arch/llm/chatglm-tuning#reference","content":" [1]ChatGLM3|github https://github.com/THUDM/ChatGLM3/tree/main?tab=readme-ov-file[2]https://www.analyticsvidhya.com/blog/2024/12/fine-tuning-llama-3-2-3b-for-rag/[3]https://time.geekbang.org/column/article/781435 [4] 智谱AI技术文档 ","version":"Next","tagName":"h2"},{"title":"transformer","type":0,"sectionRef":"#","url":"/docs/ai-arch/transformer","content":"","keywords":"","version":"Next"},{"title":"注意力机制（Attention）​","type":1,"pageTitle":"transformer","url":"/docs/ai-arch/transformer#注意力机制attention","content":" encoder与decoder框架  这种框架描述一种输入输出的关系。 比如将 我(x1)是(x2)超(x3)人(x4)输入，输出是 i(y1) am(y2) superman(y3) 常见的应用场景是，比如google翻译。  Self attention  在上面的c上做工夫。  简单来说，通过同一输入生成 Q/K/V，计算每个位置对其他位置的权重，捕捉长距离依赖。 多头注意力其实就是多个self-atention（权重矩阵不同）组装起来。  每层复杂度对比（摘录自论文）：  Layer Type\tComplexity per Layer\tSequential Operations\tMaximum Path LengthSelf-Attention\tO⁢(n2⋅d)\tO⁢(1)\tO⁢(1) Recurrent\tO⁢(n⋅d2)\tO⁢(n)\tO⁢(n) Convolutional\tO⁢(k⋅n⋅d2)\tO⁢(1)\tO⁢(l⁢o⁢gk⁢(n)) Self-Attention (restricted)\tO⁢(r⋅n⋅d)\tO⁢(1)\tO⁢(n/r)  ","version":"Next","tagName":"h2"},{"title":"Transformer模型结构​","type":1,"pageTitle":"transformer","url":"/docs/ai-arch/transformer#transformer模型结构","content":" 这是论文的结构图片：  这里根据我整体的理解画一下transformer模型干了什么：  ","version":"Next","tagName":"h2"},{"title":"思考​","type":1,"pageTitle":"transformer","url":"/docs/ai-arch/transformer#思考","content":" 经过LLM的实践，大概transformer已经证明了其模型结构的价值。和人比起来，很多时候真的”真假难辨“。说不定它还有那么几分像人的认知模型。那么他有没优化的地方呢？ 在我看来，除了技术上怎么优化KV缓存、怎么解决online learning等，类比起人，个人觉得结构依然有这些问题需要处理：  不是真的具有逻辑推演能力。基于长期记忆的灵光一现（直觉）。  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"transformer","url":"/docs/ai-arch/transformer#reference","content":" [5]https://arxiv.org/html/1706.03762v7/#S2[6]https://zhuanlan.zhihu.com/p/379722366[7]CoThttps://www.zhihu.com/tardis/zm/art/629087587?source_id=1003 ","version":"Next","tagName":"h2"},{"title":"Kubernetes基本概念集","type":0,"sectionRef":"#","url":"/docs/k8s/concept","content":"Kubernetes基本概念集 控制面： apiserver：负责提供kubernetes API的服务。etcd：高可用键值存储，类似将zk作为配置中心。scheduler: 调度组件。负责基于调度策略将pod调度到指定节点。controller-manager：负责运行控制器。 节点组件： kubelet：kubelet 会在集群中每个节点（node）上运行。保证pod的运行。 pod：是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。 管理一个/多个pod的工作集： DeploymentStatefulSetDaemonSetcronjob","keywords":"","version":"Next"},{"title":"RAG应用探索","type":0,"sectionRef":"#","url":"/docs/ai-arch/llm/rag-application","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#简介","content":" RAG应用搭建探索，并对一两篇最佳实践论文进行分析。  ","version":"Next","tagName":"h2"},{"title":"需求​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#需求","content":" 针对一个需求去做探索: 希望用RAG重塑和聚合我每日看的商业新闻源（36k、虎嗅）。  资讯聚合：通过LLM去做碎片化提炼，得出每日重点简报。生成式聚合：输出带溯源标注的行业简报。  ","version":"Next","tagName":"h3"},{"title":"技术栈​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#技术栈","content":" Spring AI 在线引擎框架Llama3.2 大模型nomic-embed-text:v1.5 embedding模型Elasticsearch/pgector 向量数据库Apache Tika pdf、doc等文件的处理库  ","version":"Next","tagName":"h2"},{"title":"搭建向量数据库​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#搭建向量数据库","content":" 向量数据库benchmark：https://ann-benchmarks.com/index.html  ","version":"Next","tagName":"h2"},{"title":"Elasticsearch​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#elasticsearch","content":" 搭建，略，请看Elasticsearch一节。  ","version":"Next","tagName":"h3"},{"title":"Pgvector​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#pgvector","content":" Ubuntu安装https://blog.csdn.net/p1g2c32006/article/details/136371175  创建apt仓库文件 sudo sh -c 'echo &quot;deb https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&quot; &gt; /etc/apt/sources.list.d/pgdg.list' 导入仓库签名 wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - 更新仓库列表 sudo apt update 安装pg(自己选择合适的版本) sudo apt -y install postgresql-14 安装pgvector sudo apt -y install postgresql-14-pgvector   创建用户和数据库  postgres=# create user pv with password '22222222'; CREATE ROLE postgres=# create database pv owner=pv; CREATE DATABASE postgres=# grant all privileges on database pv to pv; GRANT   建表交给Spring-ai自动建。  ","version":"Next","tagName":"h3"},{"title":"Embedding模型和LLM​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#embedding模型和llm","content":" 模型我直接用Ollama去管理：安装教程通过Llama和Dify搭建一套RAG  因为是在本地电脑运行，所以选用的是性价比高、占用资源相对一般的模型。  embedding模型选型：nomic-embed-text:v1.5。LLM选型：llama3.2:3b | qwen2:latest  ","version":"Next","tagName":"h2"},{"title":"服务构建​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#服务构建","content":" 本文代码在 https://github.com/teaho-infra/spring-ai-rag-demo 。项目里有es http demo、 es-ollama-rag-demo和pgvector-ollama-rag-demo三个。  代码主要包括：  ETL pipeline数据处理 pdf解析rss解析文档切片和chunk处理调用文本模型knn数据生成 RAG查询处理 knn查询prompt构造，LLM请求后置处理  ","version":"Next","tagName":"h2"},{"title":"ETL pipeline数据处理​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#etl-pipeline数据处理","content":" 下面说下ETL数据处理流程：  Rss下载进行chunk处理。采用简单的1000token做chunk调用向量模型，生成向量。保存到向量数据库 ContentFormatTransformer contentFormatTransformer = new ContentFormatTransformer(DefaultContentFormatter.defaultConfig()); TokenTextSplitter tokenTextSplitter = new TokenTextSplitter(1000, 400, 10, 5000, true); docs = tokenTextSplitter.split(contentFormatTransformer.transform(docs));   ","version":"Next","tagName":"h3"},{"title":"在线流程​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#在线流程","content":" 在线流程，在接收到请求后，  先查询向量数据库，然后让LLM整合和润饰。 List&lt;Document&gt; documents = searchVectorDB(query, 4); //……省略转换代码 String prompt = &quot;&quot;&quot; 请基于下面的内容，回答这个问题&quot;%s&quot;: %s &quot;&quot;&quot;; String reply = ollamaChatModel.call(String.format(prompt, query, similarDoc.toString()));   ","version":"Next","tagName":"h3"},{"title":"结果​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#结果","content":" 搜索“今天有什么新闻”  ","version":"Next","tagName":"h3"},{"title":"方案优化​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#方案优化","content":" 论文：https://arxiv.org/abs/2407.01219  我基于《Searching for Best Practices in Retrieval-Augmented Generation》（RAG最佳实践）去看看一个RAG系统（我搭建的这个简陋系统）有什么优化的空间。  ","version":"Next","tagName":"h2"},{"title":"一个RAG应用的组成部分​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#一个rag应用的组成部分","content":" 查询分类：将查询划分为是否需要RAG检索。Chunk向量转换和存储Retrieal：检索。Rerankrepackingsummarization大模型微调  ","version":"Next","tagName":"h3"},{"title":"查询分类 Query classification​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#查询分类-query-classification","content":" 通常我们通过查询分类，能够大大提升频繁检索的性能。对于一些完全是基于用户输入生成结果的query，不需要走检索。例如，对文字做总结的查询。  论文中提出使用BERT-base-multilingual-cased 作为分类器。  ","version":"Next","tagName":"h3"},{"title":"文本分块​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#文本分块","content":" 有这几种方式：  基于token的分块：优点：简单分块缺点：可能截断句子语义级分块：使用LLM进行分块。优点：保留上下文缺点：耗时高，实现麻烦。句子级分块平衡token和语义保留  ","version":"Next","tagName":"h3"},{"title":"块大小：评估​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#块大小评估","content":"  faithfulness指标表示：衡量响应是幻觉还是与检索到文本相匹配。 relevancy指标表示：衡量检索到的文本和响应，与query的相关性。  分块技术：  Originalsmall2big：从小块文本开始，逐步合并成更大的语义单元滑动窗口  源数据添加：目前没有优化手段。（我认为暂时常见场景也不需要）  ","version":"Next","tagName":"h3"},{"title":"向量数据库​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#向量数据库","content":"  论文中评估的向量数据库中，认为Milvus最优。  ","version":"Next","tagName":"h3"},{"title":"检索​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#检索","content":" query改写query分解假设文档生成（Pseudo-documents Generation）HyDE： 使用LLM生成假设查询并转化成embedding去查询，在Perplexity.ai等产品中已有类似思想的实践。  建议使用 HyDE 的混合搜索作为默认检索方法。即将HyDE的结果分解成如下：  稀疏检索（BM25）密集检索（HyDE的结果embedding）  ","version":"Next","tagName":"h3"},{"title":"重排​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#重排","content":" DLM重排TILDE重排  推荐monoT5作为平衡性能和效率的综合方法。  ","version":"Next","tagName":"h3"},{"title":"打包（document Repacking）​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#打包document-repacking","content":" 重排完，后续的LLM生成的性能也会受重排后的顺序影响。而论文引用，将相关文档放在最头或者最尾性能最优。  ","version":"Next","tagName":"h3"},{"title":"总结（Summarization）​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#总结summarization","content":" 经过上面步骤后，得到的结果可能包含不相关的冗余文档，从而  影响LLM的生成结果。降低LLM查询性能。  而总结这一步有两种方法：  提取式 分割成句子排序，摘除不重要的。抽象式 重新表述，生成连贯的摘要。  工具：  RecompLongLLMLinguaSelective Context  推荐Recomp ，因为它具有出色的性能。  ","version":"Next","tagName":"h3"},{"title":"测评​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#测评","content":" 深度测评 RAG 应用评估框架：指标最全面的 RAGas 评估与优化RAG指南：提高准确性与质量的最佳实践  ","version":"Next","tagName":"h3"},{"title":"应用场景​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#应用场景","content":" 就目前来看，企业数据库，垂类查询都是很好的应用场景。有实时诉求的搜索和查询也是。 它，能够结合工程，做一个随时换库的RAG搜索。微调LLM、LLM agent、RAG放在各行业链路里，依然有广阔的想象空间。  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"RAG应用探索","url":"/docs/ai-arch/llm/rag-application#reference","content":" [1]https://arxiv.org/abs/2407.01219 [2]RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation https://arxiv.org/abs/2310.04408 [3]Spring AI doc |spring.io [4]Pgvector|github [5]From Local to Global: A Graph RAG Approach to Query-Focused Summarization https://arxiv.org/pdf/2404.16130 [6]https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/ ","version":"Next","tagName":"h2"},{"title":"容器运行时","type":0,"sectionRef":"#","url":"/docs/k8s/cri","content":"容器运行时 SIG-Node团队支持的：kubelet 与 CRI。 kubelet调用下层容器运行时，通过一组CRI的gRPC接口来做错。","keywords":"","version":"Next"},{"title":"拓展Kubernetes","type":0,"sectionRef":"#","url":"/docs/k8s/extend","content":"","keywords":"","version":"Next"},{"title":"自定义声明式API和自定义控制器​","type":1,"pageTitle":"拓展Kubernetes","url":"/docs/k8s/extend#自定义声明式api和自定义控制器","content":"   自定义API和controller https://github.com/resouer/k8s-controller-custom-resource  ","version":"Next","tagName":"h2"},{"title":"Operator工作原理解读​","type":1,"pageTitle":"拓展Kubernetes","url":"/docs/k8s/extend#operator工作原理解读","content":" operator相当于一个自定义控制器。  业界有名的Operator：Etcd Operator、Prometheus Operator， 可以方便的建立和运维集群。 Operator和pod、StatefulSet、cronJob可以相互结合使用。  ","version":"Next","tagName":"h2"},{"title":"CNI、CSI、Device Plugin​","type":1,"pageTitle":"拓展Kubernetes","url":"/docs/k8s/extend#cnicsidevice-plugin","content":" 这几个拓展形式，不在本doc讨论范围，略过。 ","version":"Next","tagName":"h2"},{"title":"容器和k8s历史","type":0,"sectionRef":"#","url":"/docs/k8s/history","content":"","keywords":"","version":"Next"},{"title":"简介​","type":1,"pageTitle":"容器和k8s历史","url":"/docs/k8s/history#简介","content":" 了解了背景和发展，对理解为什么这么设计其实帮助很大。  ","version":"Next","tagName":"h2"},{"title":"历史​","type":1,"pageTitle":"容器和k8s历史","url":"/docs/k8s/history#历史","content":" 发展过程中市场有这些技术的抉择，我们一起来对比：    2013-2014的容器的解决方案，最开始Cloud Foundry为代表的Paas，通过cgroup和namespace去做隔离， 但Docker创新的提出”镜像“，我们只需要在任意地方解压这个包含操作系统文件和目录的压缩包，就可以运行程序。  所以，namespace、cgroup这些玩意并不新，Docker创造性在于，缔造了镜像的概念， 并推出了fs layer分层，成功解决了镜像分发效率。  接下来说说，2015-2017的容器编排之争，以及K8s如何脱颖而出。 以Mesos为例子，其实当时有些有大规模集群管理能力的项目，但是都没有Docker的声势浩大，社区庞大。 Docker乘着自己的用户和社区搞商业化，成立公司搞解决方案，在Docker搞内置Swarm。使得很多人有怨言。 Kubernetes横空出世，我认为做对两件事：  借助Google和Red Hat本身的成熟云经验，一开始就是站在上层做平台。积极拥抱开源生态（而彼时Docker越发自顾自玩耍）。推出了CNCF，囊括了很多好项目（Prometheus等）， 同时，插件化、API可拓展性让Kubernetes生态百花齐放。  最终K8s做到了最终王座。。 从技术上看，我认为Kubernetes提出的Pod作为最小组织单元都是很领先的，Docker Swarm还是停留在容器的组织上。  ","version":"Next","tagName":"h2"},{"title":"时间线总结​","type":1,"pageTitle":"容器和k8s历史","url":"/docs/k8s/history#时间线总结","content":"  ","version":"Next","tagName":"h2"},{"title":"容器网络","type":0,"sectionRef":"#","url":"/docs/k8s/network","content":"容器网络 Network Namespace包含： 网卡（network interface）回环设备（Loopback Device）路由表（Routing Table）iptables 规则 网桥（Bridge），支持两台主机之间通信。 比如docker0网桥，是容器与外界网络通信的关键。而k8s集群能够相互通信是因为通过软件手段 构建了整个集群的公共网桥。Veth Pair，虚拟网卡对，相当于网线。 我们在进行系统级编程的时候，有一个非常重要的优化原则，就是要减少用户态到内核态的切换次数，并且把核心的处理逻辑都放在内核态进行。 Flannel及其支持的三种模式： VXLANhost-gwUDP Calico使用BGP（在大规模网络中实现节点路由信息共享的一种协议）分发路由信息。","keywords":"","version":"Next"},{"title":"Prometheus和k8s日志","type":0,"sectionRef":"#","url":"/docs/k8s/metric-and-log","content":"","keywords":"","version":"Next"},{"title":"Prometheus​","type":1,"pageTitle":"Prometheus和k8s日志","url":"/docs/k8s/metric-and-log#prometheus","content":" Prometheus架构：  k8s监控指标体系  宿主机监控指标。kubernetes的API server、kuberlet等组件的/metrics 指标。kubernetes的核心监控，pod、node、容器、service的指标。  具体的监控指标规划上，建议遵循业界通用的 USE 原则和 RED 原则。  其中，USE 原则指的是，按照如下三个维度来规划资源监控指标：  利用率（Utilization），资源被有效利用起来提供服务的平均时间占比饱和度（Saturation），资源拥挤的程度，比如工作队列的长度错误率（Errors），错误的数量。  而 RED 原则指的是，按照如下三个维度来规划服务监控指标：  每秒请求数量（Rate）每秒错误数量（Errors）服务响应时间（Duration）  ","version":"Next","tagName":"h2"},{"title":"优缺点​","type":1,"pageTitle":"Prometheus和k8s日志","url":"/docs/k8s/metric-and-log#优缺点","content":" 优点：  Prometheus已经是业界验证的，各方面（性能、存储优化、可用性）能力做到比较好的指标监控中间件。背靠CNCF的开源组织优势。  缺点：  不适合特别准确和详细的监控。比如广告请求计费这一类。  ","version":"Next","tagName":"h3"},{"title":"custom metrics和auto scaling​","type":1,"pageTitle":"Prometheus和k8s日志","url":"/docs/k8s/metric-and-log#custom-metrics和auto-scaling","content":" 利用HorizontalPodAutoscaler（HPA）和Custom Metrics APIServer，通过自定义metric的动态扩缩。  ","version":"Next","tagName":"h2"},{"title":"日志收集​","type":1,"pageTitle":"Prometheus和k8s日志","url":"/docs/k8s/metric-and-log#日志收集","content":" k8s常用日志收集方法：  收集stdout和stderr，并保存在Node上，在node上部署DaemonSet进行收集分发。每个pod建立sidecar容器，通过sidecar容器收集日志。应用容器直接发送给日志存储服务。 ","version":"Next","tagName":"h2"},{"title":"容器持久化存储","type":0,"sectionRef":"#","url":"/docs/k8s/persistence","content":"容器持久化存储 Persistent Volume（PV）：持久化存储卷。 Persistent Volume Claim（PVC）：Pod 所希望使用的持久化存储的属性。 容器的 Volume，其实就是将一个宿主机上的目录，跟一个容器里的目录绑定挂载在了一起。 分两步： Attach 虚拟机挂载远程磁盘的操作mount 将磁盘设备格式化并挂载到 Volume 宿主机目录的操作（远程文件存储一般只有mount） k8s自动创建pv的机制：Dynamic Provisioning和StorageClass。 从图中我们可以看到，在这个体系中： PVC 描述的，是 Pod 想要使用的持久化存储的属性，比如存储的大小、读写权限等。PV 描述的，则是一个具体的 Volume 的属性，比如 Volume 的类型、挂载目录、远程存储服务器地址等。而 StorageClass 的作用，则是充当 PV 的模板。并且，只有同属于一个 StorageClass 的 PV 和 PVC，才可以绑定在一起。","keywords":"","version":"Next"},{"title":"Kubernetes安装","type":0,"sectionRef":"#","url":"/docs/k8s/install","content":"","keywords":"","version":"Next"},{"title":"minikube​","type":1,"pageTitle":"Kubernetes安装","url":"/docs/k8s/install#minikube","content":" ubuntu22.04环境  安装kubelet和kuberctl  sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl   安装minikube  curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64   启动minikube和dashboard  最理想是有全局的代理，直接minikube start和minikube dashboard。  其次使用指定代理，采用官网FAQ的指定镜像库方式。minikube start --image-repository='registry.cn-hangzhou.aliyuncs.com/google_containers' --image-mirror-country=cn \\， minikube dashboard。  ","version":"Next","tagName":"h2"},{"title":"查看状态​","type":1,"pageTitle":"Kubernetes安装","url":"/docs/k8s/install#查看状态","content":" kubectl get pods --all-namespaces  kubectl logs --namespace=kubernetes-dashboard dashboard-metrics-scraper-b5fc48f67-m5v96  ","version":"Next","tagName":"h3"},{"title":"查看日志​","type":1,"pageTitle":"Kubernetes安装","url":"/docs/k8s/install#查看日志","content":" minikube logs  ","version":"Next","tagName":"h3"},{"title":"ImagePullBackOff错误处理​","type":1,"pageTitle":"Kubernetes安装","url":"/docs/k8s/install#imagepullbackoff错误处理","content":" 我用指定代理踩了很多坑， 首先尝试改仓库。minikube start --registry-mirror=https://registry.docker-cn.com \\ --image-mirror-country=cn \\。 不行的话，指定minikube的docker代理环境变量。 minikube start --docker-env HTTP_PROXY=http://127.0.0.1:7890 \\ --docker-env HTTPS_PROXY=http://127.0.0.1:7890 \\ --docker-env NO_PROXY=localhost,127.0.0.1,10.96.0.0/12,192.168.99.0/24,192.168.39.0/24 \\ --docker-env ALL_PROXY=socks5://127.0.0.1:7890 \\ --registry-mirror=https://registry.docker-cn.com \\ --image-mirror-country=cn \\ --driver=docker 再不行，曲线救国， 使用docker命令把缺失的镜像拉下来，比如 docker pull docker.io/kubernetesui/metrics-scraper:v1.0.8docker pull docker.io/kubernetesui/dashboard:v2.7.0 使用minikube image load让minikube加载镜像重新启动minikube  题外话，docker代理可用指定环境变量http_proxy、https_proxy 或者更改/etc/docker/daemon.json的仓库源。  ","version":"Next","tagName":"h3"},{"title":"实用命令参数​","type":1,"pageTitle":"Kubernetes安装","url":"/docs/k8s/install#实用命令参数","content":" minikube logs：查看运行日志。minikube image： minikube内拉/推镜像的方式。minikube options: 有一些使用的指定日志目录等参数。minikube start: --network-plugin指定cni插件--kubernetes-version指定版本-p 指定profile，minikube可以启动多集群。--driver=docker 指定minikube的部署驱动。--docker-env 指定docker的环境变量。 ","version":"Next","tagName":"h3"},{"title":"reference","type":0,"sectionRef":"#","url":"/docs/k8s/reference","content":"reference [1]Kubernetes doc|kubernetes.io [2]张磊.深入剖析Kubernetes[M].中国:人民邮电出版社，2021 [3]minikube doc [4]版本对比|csdn [5]doc|prometheus.io [6]Containers From Scratch • Liz Rice • GOTO 2018 [7]Tmpfs|The Linux Kernel [8]namespaces(7) — Linux manual page [9]cgroup 2参数设置|zorrozou.github.io","keywords":"","version":"Next"},{"title":"pod","type":0,"sectionRef":"#","url":"/docs/k8s/pod","content":"","keywords":"","version":"Next"},{"title":"生命周期​","type":1,"pageTitle":"pod","url":"/docs/k8s/pod#生命周期","content":" Pod生命周期状态：（关注非running和非succeeded状态）  PendingRunningSucceededFailedUnknown    ","version":"Next","tagName":"h2"},{"title":"Projected Volume​","type":1,"pageTitle":"pod","url":"/docs/k8s/pod#projected-volume","content":" Kubernetes 支持的 Projected Volume 一共有四种：  Secret，比如用来调用k8s api的Service Account Token就是一个secret。 //向k8s添加secret kubectl create secret generic pass --from-file=./password.txt // pod配置使用secret volumes: - name: xxx projected: sources: - secret: name: pass ConfigMap: 类似.properties文件。可以通过多种方式使用configMap ConfigMap|k8sDownward APIServiceAccountToken。  ","version":"Next","tagName":"h2"},{"title":"配置容器健康检查、恢复机制、启动检查​","type":1,"pageTitle":"pod","url":"/docs/k8s/pod#配置容器健康检查恢复机制启动检查","content":" Configure Liveness, Readiness and Startup Probes  存活检测：配置容器的存活检测，检测失败则重启容器。 livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 5 就绪检测：检测容器就绪状态，是否可接受流量。k8s检测成功则挂到相应Services，可接受kube-proxy的流量。 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 5 启动检测：为了给那些启动慢的程序的额外配置。 startupProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 30 periodSeconds: 10   ","version":"Next","tagName":"h2"},{"title":"控制器​","type":1,"pageTitle":"pod","url":"/docs/k8s/pod#控制器","content":" kube-controller-manager  总的来说，k8s通过控制器模式去循环比对不同类型的容器的实际状态和期望状态并执行，达到容器编排能力。    ","version":"Next","tagName":"h2"},{"title":"部署副本和扩容​","type":1,"pageTitle":"pod","url":"/docs/k8s/pod#部署副本和扩容","content":"   扩容方式： kubectl scale deployment ${deployment} --replicas=10查看deployment的状态和副本： kubectl get deployments DESIREDCURRENTUP-TO-DATEAVAILABLE 滚动更新 修改deployment会触发滚动更新滚动更新策略 strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 1 回滚kubectl rollout undo   ","version":"Next","tagName":"h2"},{"title":"调度","type":0,"sectionRef":"#","url":"/docs/k8s/schedule","content":"调度 资源模型 可压缩资源，cpu等不可压缩资源，mem、磁盘空间等 qos模型 GuaranteedBurstableBestEffort 在线上服务部署中，通过cpuset方式绑核是比较常见的。 k8s中，将request和limit设置相同数值即可实现。 spec: containers: - name: nginx image: nginx resources: limits: memory: &quot;200Mi&quot; cpu: &quot;2&quot; requests: memory: &quot;200Mi&quot; cpu: &quot;2&quot; 在 Kubernetes 项目中，默认调度器的主要职责，就是为一个新创建出来的 Pod，寻找一个最合适的节点（Node）。 从集群所有的节点中，根据调度算法挑选出所有可以运行该 Pod 的节点，称为Predicate。从第一步的结果中，再根据调度算法挑选一个最符合条件的节点作为最终结果，称为Priority。","keywords":"","version":"Next"},{"title":"容器基本知识和GO实现基本容器原理","type":0,"sectionRef":"#","url":"/docs/k8s/container","content":"","keywords":"","version":"Next"},{"title":"什么是容器​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#什么是容器","content":" 基于 Linux 内核的 Cgroup，Namespace，以及 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术，由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 容器的本质是一种特殊的进程。  ","version":"Next","tagName":"h2"},{"title":"为什么用容器​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#为什么用容器","content":" 更高效地利用系统资源更快速的启动时间一致的运行环境更轻松地迁移更轻松地维护和扩展  下面介绍容器涉及的核心技术。  ","version":"Next","tagName":"h2"},{"title":"Namespace​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#namespace","content":" Linux Namespace 是一种 Linux 内核提供的资源隔离方案：  系统可以为进程分配不同的Namespace；并保证不同的Namespace资源独立分配、进程彼此隔离，即不同的 Namespace下的进程互不干扰。    内核源码（v5.15.52）的namespace数据结构： /linux/nsproxy.h https://elixir.bootlin.com/linux/v5.15.52/source/include/linux/nsproxy.h  ","version":"Next","tagName":"h2"},{"title":"cgroup 2​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#cgroup-2","content":" Cgroups （Control Groups）是 Linux 下用于对一个或一组进程进行资源控制和监控的机制；可以对诸如 CPU 使用时间、内存、磁盘 I/O 等进程所需的资源进行限制；cgroup-v2.txt    ","version":"Next","tagName":"h2"},{"title":"网络​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#网络","content":" 容器,以docker网络为例子通过：  在宿主机建立网桥（docker0）。veth-pair建立对宿主机网桥的联通（相当于网线），达到与宿主机内其他容器或者外部通信的能力。  ","version":"Next","tagName":"h2"},{"title":"镜像分层​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#镜像分层","content":" 我们都看到过容器大小，一般几GB的大小，如果每次发布拉取这么大镜像，一定会造成空间和网络浪费， 而且服务上线和扩缩容时间极长。如何解决这个问题？  通过容器的镜像分层，我们可复用基础的可读层。 我们平常编写的Dockerfile，每条命令就是一层。容器运行时会复用相应可读层，最终将不同层bind到我们的容器进程目录。    ","version":"Next","tagName":"h2"},{"title":"完整代码示例​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#完整代码示例","content":" /* * 完整范例版注释版 */ package main import ( &quot;fmt&quot; &quot;os&quot; &quot;os/exec&quot; &quot;path/filepath&quot; &quot;strconv&quot; &quot;syscall&quot; ) var cgroups = &quot;/sys/fs/cgroup&quot; var custom_cgroup = filepath.Join(cgroups, &quot;work&quot;) // go run mainTest.go run &lt;cmd&gt; &lt;args&gt; func main() { switch os.Args[1] { case &quot;run&quot;: run() // Removes the instantiated cgroup after container exit cgCleanup() case &quot;child&quot;: child() default: panic(&quot;help&quot;) } } func run() { fmt.Printf(&quot;Running %v \\n&quot;, os.Args[2:]) cmd := exec.Command(&quot;/proc/self/exe&quot;, append([]string{&quot;child&quot;}, os.Args[2:]...)...) cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr //Mount namespaces\tCLONE_NEWNS //UTS namespaces\tCLONE_NEWUTS //IPC namespaces\tCLONE_NEWIPC //PID namespaces\tCLONE_NEWPID //Network namespaces\tCLONE_NEWNET //User namespaces\tCLONE_NEWUSER cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS, Unshareflags: syscall.CLONE_NEWNS, } must(cmd.Run()) } func child() { fmt.Printf(&quot;Running %v \\n&quot;, os.Args[2:]) cg() cmd := exec.Command(os.Args[2], os.Args[3:]...) cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr must(syscall.Sethostname([]byte(&quot;container&quot;))) // cd /tmp/containers-from-scratch // skopeo copy docker://ubuntu oci:ubuntu // mkdir ubuntufs // tar -xf ../ubuntu/blobs/sha256/somesha.... -C ubuntufs &amp;&amp; rm -rf ubuntu // mkdir ubuntufs/mytemp must(syscall.Chroot(&quot;/home/work/centosfs/&quot;)) must(os.Chdir(&quot;/&quot;)) must(syscall.Mount(&quot;proc&quot;, &quot;proc&quot;, &quot;proc&quot;, 0, &quot;&quot;)) //must(syscall.Mount(&quot;thing&quot;, &quot;mytemp&quot;, &quot;tmpfs&quot;, 0, &quot;&quot;)) must(syscall.Mount(&quot;tmp&quot;, &quot;mytemp&quot;, &quot;tmpfs&quot;, 0, &quot;size=100M,mode=0755&quot;)) must(cmd.Run()) must(syscall.Unmount(&quot;/proc&quot;, 0)) must(syscall.Unmount(&quot;/mytemp&quot;, 0)) } func cg() { os.Mkdir(custom_cgroup, 0755) must(os.WriteFile(filepath.Join(custom_cgroup, &quot;pids.max&quot;), []byte(&quot;20&quot;), 0644)) must(os.WriteFile(filepath.Join(custom_cgroup, &quot;cgroup.procs&quot;), []byte(strconv.Itoa(os.Getpid())), 0644)) must(os.WriteFile(filepath.Join(custom_cgroup, &quot;memory.max&quot;), []byte(&quot;50m&quot;), 0644)) must(os.WriteFile(filepath.Join(custom_cgroup, &quot;cpu.max&quot;), []byte(&quot;50000 100000&quot;), 0644)) //if err := setupVirtualEthOnHost(&quot;tea&quot;); err != nil { //\tlog.Fatalf(&quot;Unable to setup Veth0 on host: %v&quot;, err) //} } func cgCleanup() error { alive, err := os.ReadFile(filepath.Join(custom_cgroup, &quot;pids.current&quot;)) if err != nil { // or must(err).. but then it'll look weird.. panic(err) } if alive[0] != uint8(48) { must(os.WriteFile(filepath.Join(custom_cgroup, &quot;cgroup.kill&quot;), []byte(&quot;1&quot;), 0644)) } must(os.Remove(custom_cgroup)) return nil } func must(err error) { if err != nil { panic(err) } } func mustWithMsg(err error, msg string) { if err != nil { fmt.Println(msg) panic(err) } }   ","version":"Next","tagName":"h2"},{"title":"总结​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#总结","content":" 这是我在工作中的一个团队分享。 通过写代码并在我的电脑上比对docker命令去演示容器的本质（容器进程、docker shim和进程）和容器的核心原理。  下面是总结的思维导图。  ","version":"Next","tagName":"h2"},{"title":"附录​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#附录","content":" ","version":"Next","tagName":"h2"},{"title":"系统调用​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#系统调用","content":" 系统命令调用内核的机制：    ","version":"Next","tagName":"h3"},{"title":"proc​","type":1,"pageTitle":"容器基本知识和GO实现基本容器原理","url":"/docs/k8s/container#proc","content":" 在linux的根目录下存在一个/proc目录，/proc文件系统是一种虚拟文件系统,以文件系统目录和文件形式,提供一个指向内核数据结构的接口，通过它能够查看和改变各种系统属性。 proc目录通常情况下是由系统自动挂载在/proc目录下，但是我们也可以自行手动挂载。 mount -t proc proc /proc/ ","version":"Next","tagName":"h3"},{"title":"工作负载管理","type":0,"sectionRef":"#","url":"/docs/k8s/workload-manager","content":"","keywords":"","version":"Next"},{"title":"Deployment​","type":1,"pageTitle":"工作负载管理","url":"/docs/k8s/workload-manager#deployment","content":" ","version":"Next","tagName":"h2"},{"title":"StatefulSet​","type":1,"pageTitle":"工作负载管理","url":"/docs/k8s/workload-manager#statefulset","content":" ","version":"Next","tagName":"h2"},{"title":"DaemonSet​","type":1,"pageTitle":"工作负载管理","url":"/docs/k8s/workload-manager#daemonset","content":" DaemonSet，Daemon Pod，每个节点都有，新节点加入进k8s集群会自动创建一个，旧节点退出会被回收掉。  ","version":"Next","tagName":"h2"},{"title":"撬动离线业务：Job与CronJob​","type":1,"pageTitle":"工作负载管理","url":"/docs/k8s/workload-manager#撬动离线业务job与cronjob","content":"","version":"Next","tagName":"h2"},{"title":"深度基础","type":0,"sectionRef":"#","url":"/docs/ai-arch/dl-base","content":"","keywords":"","version":"Next"},{"title":"边界划分​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#边界划分","content":" 典型训练流程：  ","version":"Next","tagName":"h2"},{"title":"机器学习中的关键组件​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#机��器学习中的关键组件","content":" 无论什么类型的机器学习问题，都会遇到这些组件：  可以用来学习的数据（data） 每个数据集由一个个样本(sample)组成，通常每个样本由一组称为特征（features）的属性组成。当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数（di‐mensionality）。 如何转换数据的模型（model）一个目标函数（objective function），用来量化模型的有效性  因为是要看距离目标差距多少，所以也称为，损失函数（loss function）  调整模型参数以优化目标函数的算法（algorithm）  大多流行的优化算法通常基于一种基本方法-梯度下降（gradient descent）。  ","version":"Next","tagName":"h2"},{"title":"监督学习​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#监督学习","content":" 监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。每个“特征‐标签”对都称为一个样本（example）。有时，即使标签是未知的，样本也可以指代输入特征。我们的目标是生成一个模型， 能够将任何输入特征映射到标签（即预测）。 监督学习三个步骤：  从已知数据算出一个子集，为每个样本获取真实标签。这些输入和相应的标签一起构成了训练数据集。选择有监督的学习算法，将训练数据作为输入，输出一个“已完成学习的模型”将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型输出作为相应标签的预测。  经典监督学习应用：  回归分类标记问题搜索推荐系统序列学习  ","version":"Next","tagName":"h2"},{"title":"无监督学习​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#无监督学习","content":" 聚类（clustering），经典实现：Faiss的K-means算法实现。主成分分析因果关系生成对抗性网络  ","version":"Next","tagName":"h2"},{"title":"与环境互动​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#与环境互动","content":"   ","version":"Next","tagName":"h2"},{"title":"强化学习​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#强化学习","content":" 如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么最终可能会专注于强化学习（reinforcement learning）。  ","version":"Next","tagName":"h2"},{"title":"历史​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#历史","content":" ","version":"Next","tagName":"h2"},{"title":"起源​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#起源","content":" 最初的起源，其实几个世纪前已有痕迹，自然科学的应用手段--分析数据。香农的信息论和图灵的计算理论神经网络得名源于生物灵感，而我们可从当今看到延续的两个原则 • 线性和非线性处理单元的交替，通常称为层（layers）； • 使用链式规则（也称为反向传播（backpropagation））一次性调整网络中的全部参数。  ","version":"Next","tagName":"h3"},{"title":"深度学习的发展​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#深度学习的发展","content":" 最近十年，在统计模型、应用和算法方面的进展可谓大爆发。列举一些：  新的容量控制方法，如dropout注意力机制：解决了困扰统计学一个多世纪的问题：如何在不增加可学习参数的情况下增加系统的记忆 和复杂性。多阶段设计，例如，存储器网络 (Sukhbaatar et al., 2015) 和神经编程器‐解释器 (Reed and De Freitas, 2015)。生成对抗网络并性和分布式训练的能力提升。深度学习框架的发展  无可否认，现在我们生活中遍布了人工智能应用，但我们离一个能够控制人类创造者的有知觉的人工智能系统还很远。 首先，人工智能系统是以一种特定的、面向目标的方式设计、训练和部署的。虽然他们的行为可能会给人一种通用智能的错觉，但设计的 基础是规则、启发式和统计模型的结合。其次，目前还不存在能够自我改进、自我推理、能够在试图解决一 般任务的同时，修改、扩展和改进自己的架构的“人工通用智能”工具。  ","version":"Next","tagName":"h3"},{"title":"特点​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#特点","content":" 深度学习是深度的，模型学习了很多层的转换。 深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的 特征工程过程。此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、 自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。 发展趋势从参数统计描述到非参数模型。  ","version":"Next","tagName":"h3"},{"title":"数理知识​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#数理知识","content":" python的dirs和help可以查看包里有哪些方法和用法。  ","version":"Next","tagName":"h2"},{"title":"线代、微分​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#线代微分","content":" 张量：张量表示一个由数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。  通常定义张量的物理学或传统数学方法，是把张量看成一个多维数组，当变换坐标或变换基底时，其分量会按照一定变换的规则https://zh.wikipedia.org/wiki/%E5%BC%B5%E9%87%8F  # 四维张量例子 import tensorflow as tf four_d_tensor = tf.constant([ [ [[1, 2], [3, 4], [5, 6], [7, 8]], [[11, 12], [13, 14], [15, 16], [17, 18]], [[21, 22], [23, 24], [25, 26], [27, 28]] ], [ [[31, 32], [33, 34], [35, 36], [37, 38]], [[41, 42], [43, 44], [45, 46], [47, 48]], [[51, 52], [53, 54], [55, 56], [57, 58]] ] ], dtype=tf.float16) print(four_d_tensor)   深度学习存储和操作数据的主要接口是张量（nn维数组）。 点积（Dot Product）： 给定两个向量x,y∈Rd\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^dx,y∈Rd， 它们的点积（dot product）x⊤y\\mathbf{x}^\\top\\mathbf{y}x⊤y （或⟨x,y⟩\\langle\\mathbf{x},\\mathbf{y}\\rangle⟨x,y⟩ ） 是相同位置的按元素乘积的和： x⊤y=∑i=1dxiyi\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_ix⊤y=∑i=1d​xi​yi​  范数：L1L_1L1​范数L2L_2L2​范数 Frobenius范数  范数作用： 在深度学习中，我们经常试图解决优化问题： 最大化分配给观测数据的概率;最小化预测和真实观测之间的距离。 用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。  微积分：  我们可以将拟合模型的任务分解为两个关键问题：  优化(optimization)：拟合观察数据的过程。泛化(generalization)：有效性超出已有训练数据集的能力。  偏导数：  梯度： 我们链接一个多元函数对其所有变量的偏导数，以得到该函数的梯度(gradient)向量。 梯度是一个向量，其分量是多变量函数相对于其所有变量的偏导数。  链式法则： 链式法则可以用来微分复合函数。  自动微分： 深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上，然后记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。  例如：对函数 y=2x⊤xy=2\\mathbf{x}^{\\top}\\mathbf{x}y=2x⊤x 关于列向量 x\\mathbf{x}x 求导。  import tensorflow as tf x = tf.range(4, dtype=tf.float32) x // 存储梯度 x = tf.Variable(x) # 把所有计算记录在磁带上 with tf.GradientTape() as t: y = 2 * tf.tensordot(x, x, axes=1) //通过调用反向传播函数来自动计算`y`关于`x`每个分量的梯度，x_grad为梯度 x_grad = t.gradient(y, x) //验证梯度 x_grad == 4 * x   ","version":"Next","tagName":"h3"},{"title":"概率​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#概率","content":" 从概率分布中抽取样本的过程称为抽样（sampling）。  概率论公理：  概率（probability）可以被认为是将集合映射到真实值的函数。 在给定的样本空间S\\mathcal{S}S中，事件A\\mathcal{A}A的概率， 表示为P(A)P(\\mathcal{A})P(A)，满足以下属性：  对于任意事件A\\mathcal{A}A，其概率从不会是负数，即P(A)≥0P(\\mathcal{A}) \\geq 0P(A)≥0；整个样本空间的概率为111，即P(S)=1P(\\mathcal{S}) = 1P(S)=1；对于互斥（mutually exclusive）事件（对于所有i≠ji \\neq ji=j都有Ai∩Aj=∅\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptysetAi​∩Aj​=∅）的任意一个可数序列A1,A2,…\\mathcal{A}_1, \\mathcal{A}_2, \\ldotsA1​,A2​,…，序列中任意一个事件发生的概率等于它们各自发生的概率之和，即P(⋃i=1∞Ai)=∑i=1∞P(Ai)P(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)P(⋃i=1∞​Ai​)=∑i=1∞​P(Ai​)。  以上也是概率论的公理，由科尔莫戈罗夫于1933年提出。 有了这个公理系统，我们可以避免任何关于随机性的哲学争论；相反，我们可以用数学语言严格地推理。 例如，假设事件A1\\mathcal{A}_1A1​为整个样本空间，且当所有i&gt;1i &gt; 1i&gt;1时的Ai=∅\\mathcal{A}_i = \\emptysetAi​=∅， 那么我们可以证明P(∅)=0P(\\emptyset) = 0P(∅)=0，即不可能发生事件的概率是000。  ","version":"Next","tagName":"h3"},{"title":"总结​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#总结","content":" 从概率分布中找样本从联合分布、Bayes定理等来分析多个随机变量。期望和方差为概率分布的概括和特征描述提供了度量方式。&lt;{感觉概率论还了，跳过，不懂再翻书}&gt;  ","version":"Next","tagName":"h3"},{"title":"线性神经网络​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#线性神经网络","content":" 线性回归：  线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和：price=warea⋅area+wage⋅age+b.\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b.price=warea​⋅area+wage​⋅age+b.  数据行是样本，试图预测的目标称为标签或者目标，自变量称为特征。  可用点积简洁表达模型。y^=w⊤x+b.\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b.y^​=w⊤x+b.  损失函数--模型质量度量方法  回归问题中最常用的损失函数是平方误差函数。l(i)(w,b)=12(y^(i)−y(i))2.l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.l(i)(w,b)=21​(y^​(i)−y(i))2.  梯度下降（gradient descent）这种方法几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向上更新参数来降低误差。 梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值） 关于模型参数的导数（在这里也可以称为梯度）。  随机梯度下降  ","version":"Next","tagName":"h2"},{"title":"tensorflow实现线性回归​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#tensorflow实现线性回归","content":" import random import tensorflow as tf from d2l import tensorflow as d2l from numpy import number # generate data def synthetic_data(w, b, num_examples): X = tf.zeros((num_examples, w.shape[0])) X += tf.random.normal(shape=X.shape) # y = tf.matmul(X, w) + b y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b y += tf.random.normal(shape=y.shape, stddev=0.1) y = tf.reshape(y, (-1, 1)) return X, y true_w = tf.constant([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) print('features:', features[0],'\\nlabel:', labels[0]) d2l.set_figsize() d2l.plt.scatter(features[:, 1].numpy(), labels.numpy(), 1); def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 样本随机 random.shuffle(indices) for start_idx in range(0, num_examples, batch_size): j = tf.constant(indices[start_idx: min(start_idx + batch_size, num_examples)]) print(j) yield tf.gather(features, j), tf.gather(labels, j) batch_size = 10 for X, y in data_iter(batch_size, features, labels): print(X, '\\n', y) break # 模型参数 w = tf.Variable(tf.random.normal(shape=(2, 1), mean=0, stddev=0.01), trainable=True) b = tf.Variable(tf.zeros(1), trainable=True) # 模型 def linreg(X, w, b): return tf.matmul(X, w) + b def squared_loss(y_hat, y): #@save &quot;&quot;&quot;均方损失&quot;&quot;&quot; return (y_hat - tf.reshape(y, y_hat.shape)) ** 2 / 2 def sgd(params, grads, lr, batch_size): #@save &quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot; for param, grad in zip(params, grads): param.assign_sub(lr*grad/batch_size) lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): with tf.GradientTape() as g: l = loss(net(X, w, b), y) # X和y的小批量损失 # 计算l关于[w,b]的梯度 dw, db = g.gradient(l, [w, b]) # 使用参数的梯度更新参数 sgd([w, b], [dw, db], lr, batch_size) train_l = loss(net(features, w, b), labels) print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_l)):f}') print(f'w的估计误差: {true_w - tf.reshape(w, true_w.shape)}') print(f'b的估计误差: {true_b - b}')   ","version":"Next","tagName":"h3"},{"title":"多层感知机MLP​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#多层感知机mlp","content":" ","version":"Next","tagName":"h2"},{"title":"模型选择、欠拟合和过拟合​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#模型选择欠拟合和过拟合","content":" 如何发现可以泛化的模式是机器学习的根本问题。  训练误差（training error）是指， 模型在训练数据集上计算得到的误差。 泛化误差（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。  欠拟合和过拟合：（以这样一个多项式举例：y^=∑i=0dxiwi\\hat{y}= \\sum_{i=0}^d x^i w_iy^​=∑i=0d​xiwi​）  ","version":"Next","tagName":"h3"},{"title":"权重衰减​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#权重衰减","content":" 权重衰减通过限制模型权重的增长，有效平衡了模型的拟合能力和泛化能力，是训练多层感知机等神经网络时的重要技巧。  ","version":"Next","tagName":"h3"},{"title":"dropout​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#dropout","content":" 核心思想是在训练过程中随机“关闭”网络中的一部分神经元，从而减少神经元之间的复杂共适应关系，增强模型的泛化能力。  ","version":"Next","tagName":"h3"},{"title":"前向传播、反向传播和计算图​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#前向传播反向传播和计算图","content":" 前向传播（forward propagation或forward pass） 指的是：按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。 反向传播（backward propagation或backpropagation）指的是计算神经网络参数梯度的方法。  ","version":"Next","tagName":"h3"},{"title":"预测房价 手搓​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#预测房价-手搓","content":" kaggle的预测房价照着《动手学深度学习》手搓一遍。  import hashlib import os import tarfile import zipfile import requests import numpy as np import pandas as pd import tensorflow as tf from d2l import tensorflow as d2l DATA_HUB = dict() DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/' def download(name, cache_dir=os.path.join('..', 'data')): #@save assert name in DATA_HUB, f&quot;{name} not in -&gt; {DATA_HUB}&quot; url, sha1_hash = DATA_HUB[name] os.makedirs(cache_dir, exist_ok=True) fname = os.path.join(cache_dir, url.split('/')[-1]) if os.path.exists(fname): sha1 = hashlib.sha1() with open(fname, 'rb') as f: while True: data = f.read(1048576) if not data: break sha1.update(data) if sha1.hexdigest() == sha1_hash: return fname # 命中缓存 print(f'downloading{url} -- {fname}...') r = requests.get(url, stream=True, verify=True) with open(fname, 'wb') as f: f.write(r.content) return fname def download_extract(name, folder=None): fname = download(name) base_dir = os.path.dirname(fname) data_dir, ext = os.path.splitext(fname) if ext == '.zip': fp = zipfile.ZipFile(fname, 'r') elif ext in ('.tar', '.gz'): fp = tarfile.open(fname, 'r') else: assert False, '只有zip/tar文件可以被解压缩' fp.extractall(base_dir) return os.path.join(base_dir, folder) if folder else data_dir def download_all(): for name in DATA_HUB: download(name) DATA_HUB['kaggle_house_train'] = ( #@save DATA_URL + 'kaggle_house_pred_train.csv', '585e9cc93e70b39160e7921475f9bcd7d31219ce') DATA_HUB['kaggle_house_test'] = ( #@save DATA_URL + 'kaggle_house_pred_test.csv', 'fa19780a7b011d9b009e8bff8e99922a8ee2eb90') train_data = pd.read_csv(download('kaggle_house_train')) test_data = pd.read_csv(download('kaggle_house_test')) print(train_data.shape) print(test_data.shape) print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]) all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:])) # 若无法获得测试数据，则可根据训练数据计算均值和标准差 numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index all_features[numeric_features] = all_features[numeric_features].apply( lambda x: (x - x.mean()) / (x.std())) # 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0 all_features[numeric_features] = all_features[numeric_features].fillna(0) all_features = pd.get_dummies(all_features, dummy_na=True) all_features.shape n_train = train_data.shape[0] train_features = tf.constant(all_features[:n_train].values, dtype=tf.float32) test_features = tf.constant(all_features[n_train:].values, dtype=tf.float32) train_labels = tf.constant( train_data.SalePrice.values.reshape(-1, 1), dtype=tf.float32) loss = tf.keras.losses.MeanSquaredError() def get_net(): net = tf.keras.models.Sequential() net.add(tf.keras.layers.Dense( 1, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))) return net def log_rmse(y_true, y_pred): # 为了在取对数时进一步稳定该值，将小于1的值设置为1 clipped_preds = tf.clip_by_value(y_pred, 1, float('inf')) return tf.sqrt(tf.reduce_mean(loss( tf.math.log(y_true), tf.math.log(clipped_preds)))) def train(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size): train_ls, test_ls = [], [] train_iter = d2l.load_array((train_features, train_labels), batch_size) # 这里使用的是Adam优化算法 optimizer = tf.keras.optimizers.Adam(learning_rate) net.compile(loss=loss, optimizer=optimizer) for epoch in range(num_epochs): for X, y in train_iter: with tf.GradientTape() as tape: y_hat = net(X) l = loss(y, y_hat) params = net.trainable_variables grads = tape.gradient(l, params) optimizer.apply_gradients(zip(grads, params)) train_ls.append(log_rmse(train_labels, net(train_features))) if test_labels is not None: test_ls.append(log_rmse(test_labels, net(test_features))) return train_ls, test_ls # k 折交叉炎症 def get_k_fold_data(k, i, X, y): assert k &gt; 1 fold_size = X.shape[0] // k X_train, y_train = None, None for j in range(k): idx = slice(j * fold_size, (j + 1) * fold_size) X_part, y_part = X[idx, :], y[idx] if j == i: X_valid, y_valid = X_part, y_part elif X_train is None: X_train, y_train = X_part, y_part else: X_train = tf.concat([X_train, X_part], 0) y_train = tf.concat([y_train, y_part], 0) return X_train, y_train, X_valid, y_valid def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size): train_l_sum, valid_l_sum = 0, 0 for i in range(k): data = get_k_fold_data(k, i, X_train, y_train) net = get_net() train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size) train_l_sum += train_ls[-1] valid_l_sum += valid_ls[-1] if i == 0: d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls], xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs], legend=['train', 'valid'], yscale='log') print(f'折{i + 1}，训练log rmse{float(train_ls[-1]):f}, ' f'验证log rmse{float(valid_ls[-1]):f}') return train_l_sum / k, valid_l_sum / k k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64 train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size) print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, ' f'平均验证log rmse: {float(valid_l):f}') def train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size): net = get_net() train_ls, _ = train(net, train_features, train_labels, None, None, num_epochs, lr, weight_decay, batch_size) d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel='epoch', ylabel='log rmse', xlim=[1, num_epochs], yscale='log') print(f'训练log rmse：{float(train_ls[-1]):f}') # 将网络应用于测试集。 preds = net(test_features).numpy() # 将其重新格式化以导出到Kaggle test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0]) submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1) submission.to_csv('submission.csv', index=False) train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size)   ","version":"Next","tagName":"h3"},{"title":"CNN（卷积神经网络）​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#cnn卷积神经网络","content":" 图来自google    CNN的理解重点是  卷积核 卷积层，我理解作用是想方法降低处理的数据量，ps一般用relu激活函数池化层 进一步降低数据维度  两个历史节点：  LeNet 杨立昆AlexNet 性顿  ","version":"Next","tagName":"h2"},{"title":"RNN（循环神经网络）​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#rnn循环神经网络","content":" 图来自知乎  RNN理解重点：  将上一次隐藏层的值作为下一次的权重输入，这样隐层就在不同时刻建立了关系（也就是有了&quot;记忆&quot;）。  ","version":"Next","tagName":"h2"},{"title":"LSTM​","type":1,"pageTitle":"深度基础","url":"/docs/ai-arch/dl-base#lstm","content":" 图片来自google    LSTM理解重点：  增加了长期记忆线 C作为输入 ","version":"Next","tagName":"h3"}],"options":{"languages":["en","zh"],"id":"default"}}